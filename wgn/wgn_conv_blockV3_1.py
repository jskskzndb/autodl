"""
wgn_conv_block.py - V3.1 (Spatially Adaptive Thresholding Version)

Upgrades from V3:
1.  [Pixel-wise Denoising]: Replaced global LearnableSoftThresholding with
    SpatiallyAdaptiveThresholding. Now the threshold is dynamic per pixel.
2.  [Direction-Aware]: Retains independent LH/HL/HH processing from V3.
"""

import torch
import torch.nn as nn
from pytorch_wavelets import DWTForward, DWTInverse


# =====================================================================================
# åŸºç¡€ç»„ä»¶ 1: ç©ºé—´è‡ªé€‚åº”è½¯é˜ˆå€¼å»å™ª (ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ç‚¹)
# =====================================================================================
class SpatiallyAdaptiveThresholding(nn.Module):
    """
    åƒç´ çº§è‡ªé€‚åº”è½¯é˜ˆå€¼ã€‚
    ä¸å†ä½¿ç”¨å•ä¸€çš„é˜ˆå€¼å‚æ•°ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªå°å‹çš„å·ç§¯ç½‘ç»œï¼Œ
    æ ¹æ®å½“å‰çš„ç‰¹å¾å›¾å†…å®¹ï¼Œä¸ºæ¯ä¸€ä¸ªåƒç´ ç‚¹é¢„æµ‹ä¸€ä¸ªä¸“å±çš„å™ªå£°é˜ˆå€¼ã€‚
    """

    def __init__(self, channels, reduction=4):
        super().__init__()
        # ä¸€ä¸ªè½»é‡çº§çš„é¢„æµ‹ç½‘ç»œ
        # input -> é™ç»´ -> ReLU -> 3x3å·ç§¯çœ‹é‚»åŸŸ -> Sigmoid -> é˜ˆå€¼å›¾
        self.threshold_net = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, kernel_size=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // reduction, channels, kernel_size=3, padding=1, bias=False),
            nn.Sigmoid()  # è¾“å‡º 0~1 ä¹‹é—´çš„ç³»æ•°
        )
        # ä¸€ä¸ªå¯å­¦ä¹ çš„åŸºå‡†ç¼©æ”¾å› å­ (æ§åˆ¶æ•´ä½“å»å™ªåŠ›åº¦)
        self.scale = nn.Parameter(torch.tensor(0.5))

    def forward(self, x):
        # 1. ç”Ÿæˆåƒç´ çº§é˜ˆå€¼å›¾ [B, C, H, W]
        # è¾¹ç¼˜å¤„é˜ˆå€¼ä¼šè‡ªåŠ¨å˜å°(ä¿ç•™)ï¼Œå¹³å¦å¤„é˜ˆå€¼å˜å¤§(æŠ‘åˆ¶)
        thresh_map = self.threshold_net(x) * self.scale

        # 2. æ‰§è¡Œè½¯é˜ˆå€¼å…¬å¼: sign(x) * max(|x| - thresh, 0)
        return torch.sign(x) * torch.relu(torch.abs(x) - thresh_map)


# =====================================================================================
# åŸºç¡€ç»„ä»¶ 2: GnConv (ä¿æŒåŸæ ·)
# =====================================================================================
def get_dwconv(dim, kernel, bias):
    return nn.Conv2d(dim, dim, kernel_size=kernel, padding=(kernel - 1) // 2, bias=bias, groups=dim)


class GnConv(nn.Module):
    def __init__(self, dim, order=5, s=1.0):
        super().__init__()
        self.order = order
        self.dims = [dim // 2 ** i for i in range(order)]
        self.dims.reverse()
        self.proj_in = nn.Conv2d(dim, 2 * dim, 1)
        self.dwconv = get_dwconv(sum(self.dims), 7, True)
        self.proj_out = nn.Conv2d(dim, dim, 1)
        self.pws = nn.ModuleList(
            [nn.Conv2d(self.dims[i], self.dims[i + 1], 1) for i in range(order - 1)]
        )
        self.scale = s

    def forward(self, x):
        fused_x = self.proj_in(x)
        pwa, abc = torch.split(fused_x, (self.dims[0], sum(self.dims)), dim=1)
        dw_abc = self.dwconv(abc) * self.scale
        dw_list = torch.split(dw_abc, self.dims, dim=1)
        x = pwa * dw_list[0]
        for i in range(self.order - 1):
            x = self.pws[i](x) * dw_list[i + 1]
        x = self.proj_out(x)
        return x


# =====================================================================================
# ä¸»æ¨¡å—: Wg_nConv_Block V3.1
# =====================================================================================
class Wg_nConv_Block(nn.Module):
    def __init__(self, channels, order_low=4, order_high=3):
        super().__init__()

        # å°æ³¢å·¥å…·
        self.dwt = DWTForward(J=1, wave='haar', mode='zero')
        self.idwt = DWTInverse(wave='haar', mode='zero')

        # --- 1. ä½é¢‘è·¯å¾„ (ä¸»å¯¼) ---
        self.gnconv_low_freq = GnConv(dim=channels, order=order_low)

        # å¼•å¯¼æ©ç ç”Ÿæˆå™¨
        self.guidance_conv = nn.Sequential(
            nn.Conv2d(channels, channels, kernel_size=1),
            nn.Sigmoid()
        )

        # --- 2. é«˜é¢‘è·¯å¾„ (ä¸‰è·¯ç‹¬ç«‹ + è‡ªé€‚åº”å»å™ª) ---

        # A. æ°´å¹³è¾¹ç¼˜ (LH)
        self.branch_lh = nn.Sequential(
            # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
            SpatiallyAdaptiveThresholding(channels),
            nn.Dropout(p=0.2),
            GnConv(dim=channels, order=order_high)
        )

        # B. å‚ç›´è¾¹ç¼˜ (HL)
        self.branch_hl = nn.Sequential(
            # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
            SpatiallyAdaptiveThresholding(channels),
            nn.Dropout(p=0.2),
            GnConv(dim=channels, order=order_high)
        )

        # C. å¯¹è§’è¾¹ç¼˜ (HH)
        self.branch_hh = nn.Sequential(
            # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
            SpatiallyAdaptiveThresholding(channels),
            nn.Dropout(p=0.2),
            GnConv(dim=channels, order=order_high)
        )

        # æœ€åçš„èåˆæŠ•å½± (3C -> 3C)
        self.high_freq_proj_out = nn.Conv2d(channels * 3, channels * 3, 1)

    def forward(self, x):
        identity = x
        b, c, h, w = x.shape

        # 1. åˆ†è§£
        ll, high_freq_list = self.dwt(x)
        high_freq = high_freq_list[0].view(b, c * 3, h // 2, w // 2)

        # 2. ä½é¢‘å¤„ç†
        ll_enhanced = self.gnconv_low_freq(ll)
        guidance_mask = self.guidance_conv(ll_enhanced)

        # 3. é«˜é¢‘å¤„ç† (æ‹†åˆ† -> ç‹¬ç«‹å¤„ç† -> åˆå¹¶)
        lh, hl, hh = torch.chunk(high_freq, 3, dim=1)

        # ç‹¬ç«‹å¤„ç† (å†…éƒ¨åŒ…å«è‡ªé€‚åº”å»å™ª)
        lh_out = self.branch_lh(lh)
        hl_out = self.branch_hl(hl)
        hh_out = self.branch_hh(hh)

        # å¼•å¯¼äº¤äº’
        lh_out = lh_out * guidance_mask
        hl_out = hl_out * guidance_mask
        hh_out = hh_out * guidance_mask

        # æ‹¼æ¥å›å» (3C é€šé“)
        high_feat_combined = torch.cat([lh_out, hl_out, hh_out], dim=1)

        # æœ€ç»ˆèåˆ
        high_feat_final = self.high_freq_proj_out(high_feat_combined)

        # 4. é‡æ„
        high_freq_out_list = [high_feat_final.view(b, c, 3, h // 2, w // 2)]
        y = self.idwt((ll_enhanced, high_freq_out_list))

        # 5. è¿”å›åŒç»“æœ
        return identity + y, high_feat_final


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    print("Testing WGN V3.1 (Adaptive Threshold)...")
    x = torch.randn(2, 64, 32, 32)
    block = Wg_nConv_Block(64)

    out, high_feat = block(x)

    print(f"Input: {x.shape}")
    print(f"Fused Output: {out.shape}")
    print(f"High-Freq Feature: {high_feat.shape}")

    assert out.shape == x.shape
    assert high_feat.shape == (2, 64 * 3, 16, 16)

    print("âœ… V3.1 Upgrade Successful!")