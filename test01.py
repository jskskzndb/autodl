# test01.py (é€‚é… DCNv3 / D-UBM)
from utils.metrics_distance import compute_hd95, compute_asd
import argparse
import logging
import os
import sys
import torch
import torch.nn.functional as F
from tqdm import tqdm
from PIL import Image
import numpy as np

# ğŸ”¥ å¯¼å…¥ç»Ÿä¸€ç‰ˆ UNet (ç¡®ä¿è·¯å¾„æ­£ç¡®)
from unet import UNet
from utils.data_loading import BasicDataset

# è¿™é‡Œçš„ Dice è®¡ç®—å‡½æ•°ï¼Œå¦‚æœä½  utils é‡Œæ²¡æœ‰ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
# from utils.dice_score import dice_coeff 

_EPS = 1e-6

def test_model(
        net, device, test_loader, threshold, amp=False, save_predictions=False, output_dir='data/test/predictions'
):
    net.eval()
    num_test_batches = len(test_loader)
    
    # è®¡æ•°å™¨
    total_tp = 0; total_fp = 0; total_fn = 0
    
    # ğŸ”¥ æ–°å¢ï¼šç”¨äºå­˜å‚¨æ¯å¼ å›¾çš„è·ç¦»æŒ‡æ ‡
    hd95_scores = []
    asd_scores = []

    if save_predictions:
        os.makedirs(output_dir, exist_ok=True)
        logging.info(f'Prediction masks will be saved to {output_dir}')

    with torch.no_grad():
        with torch.cuda.amp.autocast(enabled=amp):
            # æ³¨æ„ï¼štqdm æ˜¾ç¤ºè¿›åº¦æ¡
            for i, batch in enumerate(tqdm(test_loader, total=num_test_batches, desc='Testing', unit='batch')):
                images, true_masks = batch['image'], batch['mask']
                images = images.to(device, dtype=torch.float32, memory_format=torch.channels_last)
                true_masks = true_masks.to(device, dtype=torch.long)

                # --- æ¨¡å‹æ¨ç† ---
                output = net(images)
                
                # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ¨¡å‹è¿”å› tuple (logits, edges)ï¼Œåªå– logits
                if isinstance(output, tuple):
                    masks_pred = output[0]
                else:
                    masks_pred = output

                # é’³åˆ¶æ•°å€¼é˜²æ­¢æº¢å‡º
                masks_pred = torch.clamp(masks_pred, min=-50, max=50)

                if net.n_classes == 1:
                    pred_probs = torch.sigmoid(masks_pred)
                    pred_binary = (pred_probs > threshold).float()
                    true_binary = true_masks.float()

                    # --- 1. è®¡ç®— Dice/IoU (åŸºäºæ•´ä¸ª Batch ç´¯åŠ ) ---
                    p_flat = pred_binary.view(-1)
                    t_flat = true_binary.view(-1)
                    
                    total_tp += (p_flat * t_flat).sum()
                    total_fp += (p_flat * (1 - t_flat)).sum()
                    total_fn += ((1 - p_flat) * t_flat).sum()

                    # --- 2. ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šé€å¼ è®¡ç®— HD95 å’Œ ASD ğŸ”¥ğŸ”¥ğŸ”¥ ---
                    # å¿…é¡»æŠŠ Batch æ‹†å¼€ï¼Œä¸€å¼ å¼ è½¬æˆ numpy ç®—
                    batch_size = pred_binary.shape[0]
                    for b in range(batch_size):
                        # è½¬ä¸º numpy uint8 (0, 1) [H, W]
                        # .cpu().numpy() ä¼šæŠŠæ•°æ®ä» GPU æ‹‰å› CPU
                        pred_np = pred_binary[b].squeeze().cpu().numpy().astype(np.uint8)
                        gt_np = true_binary[b].squeeze().cpu().numpy().astype(np.uint8)
                        
                        # è®¡ç®—è·ç¦»æŒ‡æ ‡
                        hd95_val = compute_hd95(pred_np, gt_np)
                        asd_val = compute_asd(pred_np, gt_np)
                        
                        # æ’é™¤è®¡ç®—å¤±è´¥çš„æƒ…å†µ (np.nan)
                        if not np.isnan(hd95_val):
                            hd95_scores.append(hd95_val)
                        if not np.isnan(asd_val):
                            asd_scores.append(asd_val)

                    # --- 3. ä¿å­˜å›¾ç‰‡ ---
                    if save_predictions:
                        start_idx = i * test_loader.batch_size
                        for j in range(pred_binary.shape[0]):
                            idx = start_idx + j
                            if idx < len(test_loader.dataset.ids):
                                file_id = test_loader.dataset.ids[idx]
                                pred_mask_np = pred_binary[j].squeeze().cpu().numpy().astype(np.uint8) * 255
                                pred_mask_img = Image.fromarray(pred_mask_np)
                                pred_mask_img.save(os.path.join(output_dir, f'{file_id}_pred.png'))

    # --- æ±‡æ€»ç»“æœ ---
    dice = (2 * total_tp + _EPS) / (2 * total_tp + total_fp + total_fn + _EPS)
    iou = (total_tp + _EPS) / (total_tp + total_fp + total_fn + _EPS)
    precision = (total_tp + _EPS) / (total_tp + total_fp + _EPS)
    recall = (total_tp + _EPS) / (total_tp + total_fn + _EPS)
    f1 = (2 * precision * recall + _EPS) / (precision + recall + _EPS)

    # ğŸ”¥ è®¡ç®—è·ç¦»æŒ‡æ ‡çš„å¹³å‡å€¼
    avg_hd95 = np.mean(hd95_scores) if len(hd95_scores) > 0 else 0.0
    avg_asd = np.mean(asd_scores) if len(asd_scores) > 0 else 0.0

    # è¿”å›å­—å…¸ä¸­åŠ å…¥æ–°æŒ‡æ ‡
    return {
        'dice': float(dice), 
        'iou': float(iou), 
        'precision': float(precision), 
        'recall': float(recall), 
        'f1': float(f1),
        'hd95': float(avg_hd95),  # è¶Šä½è¶Šå¥½
        'asd': float(avg_asd)     # è¶Šä½è¶Šå¥½
    }

def get_args():
    parser = argparse.ArgumentParser(description='Test Unified UNet')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--model', '-m', type=str, required=True, help='Path to .pth file')
    parser.add_argument('--test-img-dir', type=str, default='data/test/imgs/')
    parser.add_argument('--test-mask-dir', type=str, default='data/test/masks/')
    parser.add_argument('--scale', '-s', type=float, default=1.0)
    parser.add_argument('--threshold', '-t', type=float, default=None)
    parser.add_argument('--batch-size', '-b', type=int, default=1)
    parser.add_argument('--save-preds', action='store_true', default=False)
    parser.add_argument('--output-dir', type=str, default='data/test/predictions')
    
    # æ¶æ„å‚æ•° (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
    parser.add_argument('--encoder', type=str, default='resnet', choices=['resnet', 'cnextv2', 'standard'])
    parser.add_argument('--decoder', type=str, default='phd', choices=['phd', 'standard'])
    parser.add_argument('--cnext-type', type=str, default='convnextv2_base')
    parser.add_argument('--bilinear', action='store_true', default=False)
    parser.add_argument('--classes', '-c', type=int, default=1)
    
    # åŠŸèƒ½å¼€å…³
    parser.add_argument('--use-wgn-enhancement', action='store_true', default=False)
    parser.add_argument('--use-cafm', action='store_true', default=False)
    parser.add_argument('--use-edge-loss', action='store_true', default=False)
    # åœ¨ test01.py çš„ get_args() å‡½æ•°ä¸­æ·»åŠ ï¼š
    parser.add_argument('--use-wavelet-denoise', action='store_true', default=False, help='Enable Wavelet Denoising on Skip Connections')
    # ğŸ”¥ğŸ”¥ğŸ”¥ [å…³é”®ä¿®æ”¹ 1] æ–°å¢ DCN/D-UBM å¼€å…³ ğŸ”¥ğŸ”¥ğŸ”¥
    parser.add_argument('--use-dcn', action='store_true', default=False, help='Enable DCNv3')
    parser.add_argument('--use-dubm', action='store_true', default=False, help='Enable D-UBM (SOTA)')
    parser.add_argument('--use-strg', action='store_true', default=False)
    parser.add_argument('--use-dual-stream', action='store_true', default=False) # ğŸ”¥ ä¿®å¤æŠ¥é”™çš„å…³é”®
    parser.add_argument('--use-dsis', action='store_true', default=False, help='Enable Dual-Stream Interactive Skip Module')
    # ğŸ”¥ğŸ”¥ğŸ”¥ [ä¿®å¤ç‚¹ 1] æ·»åŠ  Deep Supervision å‚æ•° ğŸ”¥ğŸ”¥ğŸ”¥
    parser.add_argument('--use-deep-supervision', action='store_true', default=False, help='Enable Deep Supervision (matches training)')
    parser.add_argument('--use-unet3p', action='store_true', default=False, help='Enable UNet 3+ logic')
    # WGN å‚æ•°
    parser.add_argument('--wgn-base-order', type=int, default=3)
    parser.add_argument('--wgn-orders', type=str, default=None)
    parser.add_argument('--use-sparse-skip', action='store_true', default=False, help='Enable Wavelet Skip Refiner in Skip Connections')
    return parser.parse_args()

if __name__ == '__main__':
    args = get_args()
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logging.info(f'Using device {device}')

    # WGN Orders æ„å»º
    wgn_orders = None
    if args.use_wgn_enhancement:
        if args.wgn_orders:
            orders_list = [int(x) for x in args.wgn_orders.split(',')]
            wgn_orders = {'layer1': (orders_list[0], orders_list[1]), 'layer2': (orders_list[2], orders_list[3]), 'layer3': (orders_list[4], orders_list[5])}
        else:
            base = args.wgn_base_order
            wgn_orders = {'layer1': (base, base-1), 'layer2': (base+1, base), 'layer3': (base+2, base+1)}

    # ğŸ”¥ 1. å®ä¾‹åŒ–æ¨¡å‹ (ç»“æ„å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
    logging.info(f"ğŸš€ Building Model: Encoder={args.encoder.upper()}, Decoder={args.decoder.upper()}")
    
    if args.use_dubm:
        logging.info("   âœ¨ Mode: D-UBM Enabled (SOTA 2)")
    elif args.use_dcn:
        logging.info("   âœ¨ Mode: DCNv3 Enabled (SOTA 1)")

    model = UNet(
        n_channels=3,
        n_classes=args.classes,
        bilinear=args.bilinear,
        encoder_name=args.encoder,
        decoder_type=args.decoder,  # <--- ğŸ”¥ğŸ”¥ğŸ”¥ å¿…é¡»åŠ ä¸Šè¿™ä¸€è¡Œï¼
        cnext_type=args.cnext_type,
        use_wgn_enhancement=args.use_wgn_enhancement,
        use_cafm=args.use_cafm,
        use_edge_loss=args.use_edge_loss,
        wgn_orders=wgn_orders,
        # ğŸ”¥ğŸ”¥ğŸ”¥ [å…³é”®ä¿®æ”¹ 2] ä¼ å…¥å‚æ•° ğŸ”¥ğŸ”¥ğŸ”¥
        use_dcn_in_phd=args.use_dcn,
        use_dsis=args.use_dsis,
        use_dubm=args.use_dubm,
        use_strg=args.use_strg,            # è¡¥ä¸Š
        use_dual_stream=args.use_dual_stream,  # ğŸ”¥ ä¼ å…¥åŒæµå¼€å…³
        use_unet3p=args.use_unet3p,        # è¡¥ä¸Š
        use_wavelet_denoise=args.use_wavelet_denoise,
        use_deep_supervision=args.use_deep_supervision,
        # ğŸ”¥ğŸ”¥ğŸ”¥ [å…³é”®ä¿®æ”¹] ä¼ å…¥è¿™ä¸ªå‚æ•°ï¼ ğŸ”¥ğŸ”¥ğŸ”¥
        use_sparse_skip=args.use_sparse_skip
    )

    # 2. åŠ è½½æƒé‡
    logging.info(f'Loading model from {args.model}')
    try:
        checkpoint = torch.load(args.model, map_location=device)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            logging.info('âœ… Loaded model weights successfully.')
        else:
            model.load_state_dict(checkpoint)
            logging.warning('âš ï¸ Loaded legacy weights structure.')
    except Exception as e:
        logging.error(f"âŒ Checkpoint Load Error: {e}")
        logging.error("ğŸ’¡ Hint: Did you forget to add '--use-dubm' or '--use-dcn' in arguments?")
        sys.exit(1)

    model.to(device)

    # 3. æ•°æ®é›†
    try:
        test_dataset = BasicDataset(args.test_img_dir, args.test_mask_dir, args.scale)
        test_loader = torch.utils.data.DataLoader(
            test_dataset, batch_size=args.batch_size, shuffle=False,
            num_workers=max(1, os.cpu_count() // 2), pin_memory=True, drop_last=False
        )
    except Exception as e:
        logging.error(f"Dataset Error: {e}")
        sys.exit(1)

    # 4. é˜ˆå€¼é€»è¾‘
    if args.threshold is not None:
        best_threshold = args.threshold
        logging.info(f"Using manual threshold: {best_threshold}")
    elif 'best_threshold_f1' in checkpoint: 
        best_threshold = checkpoint['best_threshold_f1']
        logging.info(f"Using optimal threshold from training: {best_threshold:.4f}")
    else:
        best_threshold = 0.5
        logging.info(f"Using default threshold: {best_threshold}")

    # 5. æµ‹è¯•
    final_metrics = test_model(
        model, device, test_loader,
        threshold=best_threshold, amp=False,
        save_predictions=args.save_preds, output_dir=args.output_dir
    )

    # 6. æ‰“å°ç»“æœ
    print("\n" + "=" * 50)
    print("         Final Test Set Evaluation Report")
    print("-" * 50)
    for k, v in final_metrics.items():
        print(f"  - Global {k.upper()}: {v:.4f}")
    print("=" * 50)