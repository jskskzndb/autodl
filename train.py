import argparse
import logging
import os
import random
import sys
import numpy as np  # <--- æ·»åŠ è¿™ä¸€è¡Œ
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from torch import optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import wandb
from evaluate import evaluate, threshold_scan_evaluate
from utils.data_loading import BasicDataset
from utils.dice_score import dice_loss


from utils.losses import FocalLoss, CombinedLoss, DiceLossOnly, EdgeLoss
from utils.utils import log_grad_stats

from unet import UNet

import random

def log_best_visuals(model, val_loader, device, num_samples=5):
    """
    å°† åŸå›¾ã€é¢„æµ‹æ©ç ã€çœŸå€¼æ©ç  å¹¶æ’å±•ç¤ºåœ¨ WandB è¡¨æ ¼ä¸­ã€‚
    è‡ªåŠ¨å¤„ç†åæ ‡å‡†åŒ–ï¼Œé˜²æ­¢åŸå›¾å˜é»‘ã€‚
    """
    model.eval()
    
    # 1. å®šä¹‰ ImageNet çš„å‡å€¼å’Œæ–¹å·® (ç”¨äºåæ ‡å‡†åŒ–)
    # å¦‚æœä½ åœ¨ dataset é‡Œç”¨äº†å…¶ä»–æ•°å€¼ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)

    # 2. åˆ›å»º WandB è¡¨æ ¼ï¼Œå®šä¹‰ä¸‰åˆ—
    columns = ["Input Image (åŸå›¾)", "Prediction (é¢„æµ‹)", "Ground Truth (çœŸå€¼)"]
    test_table = wandb.Table(columns=columns)

    print(f"âœ¨ æ­£åœ¨ç”Ÿæˆ {num_samples} ç»„å¯è§†åŒ–æ ·æœ¬...")

    with torch.no_grad():
        for i, batch in enumerate(val_loader):
            if len(test_table.data) >= num_samples: break
            
            imgs = batch['image'].to(device)
            masks = batch['mask'].to(device)
            
            # æ¨ç†
            outputs = model(imgs)
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float()
            
            for j in range(imgs.shape[0]):
                if len(test_table.data) >= num_samples: break
                
                # --- A. ä¿®å¤åŸå›¾ (é˜²æ­¢å…¨é»‘çš„æ ¸å¿ƒæ­¥éª¤) ---
                # 1. åæ ‡å‡†åŒ–: image = image * std + mean
                img_tensor = imgs[j] * std + mean
                # 2. é™åˆ¶æ•°å€¼èŒƒå›´åœ¨ 0-1 ä¹‹é—´ (æ¶ˆé™¤è®¡ç®—è¯¯å·®å¯¼è‡´çš„è¶Šç•Œ)
                img_tensor = torch.clamp(img_tensor, 0, 1)
                # 3. è½¬æ¢ç»´åº¦ [C,H,W] -> [H,W,C] å¹¶è½¬ä¸º numpy
                img_np = img_tensor.cpu().numpy().transpose(1, 2, 0)
                # 4. ä¹˜ä»¥ 255 å¹¶è½¬ä¸ºæ•´æ•° (å˜æˆæ ‡å‡†çš„ RGB å›¾ç‰‡)
                img_np = (img_np * 255).astype(np.uint8)

                # --- B. å¤„ç†æ©ç  (å˜æˆé»‘ç™½å›¾) ---
                # 1. å–å‡ºå•å¼ æ©ç 
                pred_mask = preds[j].squeeze().cpu().numpy()
                true_mask = masks[j].squeeze().cpu().numpy()
                
                # 2. ä¹˜ä»¥ 255ï¼(éå¸¸é‡è¦ï¼š0å˜æˆé»‘ï¼Œ1å˜æˆç™½)
                pred_mask = (pred_mask * 255).astype(np.uint8)
                true_mask = (true_mask * 255).astype(np.uint8)
                
                # --- C. åˆ›å»º WandB å›¾ç‰‡å¯¹è±¡ ---
                input_img_log = wandb.Image(img_np)
                pred_img_log = wandb.Image(pred_mask)
                true_img_log = wandb.Image(true_mask)
                
                # --- D. æ·»åŠ åˆ°è¡¨æ ¼çš„ä¸€è¡Œä¸­ ---
                test_table.add_data(input_img_log, pred_img_log, true_img_log)

    # 3. ä¸Šä¼ è¡¨æ ¼
    wandb.log({"Visual Results Table": test_table}, commit=False)
    print("âœ… å¯è§†åŒ–è¡¨æ ¼å·²ä¸Šä¼ ï¼")
    
    model.train() # æ¢å¤è®­ç»ƒæ¨¡å¼

# ================= é…ç½®è·¯å¾„ =================
dir_img = Path('./data/train/imgs/')
dir_mask = Path('./data/train/masks/')
val_dir_img = Path('./data/val/imgs/')
val_dir_mask = Path('./data/val/masks/')
dir_checkpoint = Path('./data/checkpoints/')

# ================= è¾…åŠ©å‡½æ•° =================

def generate_edge_tensor(mask):
    """
    [ä¿ç•™] å®æ—¶å°† Segmentation Mask è½¬ä¸º Edge GT (é«˜æ•ˆ Sobel ç®—å­)
    mask: [B, H, W] (LongTensor)
    return: [B, 1, H, W] (FloatTensor)
    """
    # è½¬æ¢ä¸º Float å¹¶å¢åŠ  Channel ç»´
    mask = mask.unsqueeze(1).float()
    
    # å®šä¹‰ Sobel ç®—å­
    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], device=mask.device).float().view(1, 1, 3, 3)
    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], device=mask.device).float().view(1, 1, 3, 3)
    
    # è®¡ç®—æ¢¯åº¦
    edge_x = F.conv2d(mask, sobel_x, padding=1)
    edge_y = F.conv2d(mask, sobel_y, padding=1)
    
    # æ¢¯åº¦å¹…å€¼
    edge = torch.sqrt(edge_x**2 + edge_y**2)
    
    # äºŒå€¼åŒ– (åªè¦æœ‰æ¢¯åº¦å°±æ˜¯è¾¹ç¼˜)
    edge = (edge > 0.1).float()
    return edge

# [å·²åˆ é™¤] generate_edge_label (æ—§ç‰ˆè†¨èƒ€è…èš€ç®—æ³•ï¼Œå·²æŒ‰è¦æ±‚ç§»é™¤)

def train_model(
        model,
        device,
        epochs: int = 20,
        batch_size: int = 32,
        learning_rate: float = 1e-5,
        val_percent: float = 0.1,
        save_checkpoint: bool = True,
        img_scale: float = 1.0,
        amp: bool = True,
        weight_decay: float = 1e-8,
        momentum: float = 0.999,
        gradient_clipping: float = 1.0,
        start_epoch: int = 1,
        checkpoint_to_load: dict = None,
        loss_combination: str = 'focal+dice',
        loss_weights: str = '1.0,1.0',
        focal_alpha: float = 0.25,
        focal_gamma: float = 2.0,
        optimizer_type: str = 'adamw',
        backbone_lr_scale: float = 0.1,
        lambda_edge: float = 20.0,
        lambda_body: float = 1.0,
        
):
    # 1. æ•°æ®å‡†å¤‡
    train_dataset = BasicDataset(dir_img, dir_mask, img_scale, mask_suffix='', augment=True)
    val_dataset = BasicDataset(val_dir_img, val_dir_mask, img_scale, mask_suffix='', augment=False)
    n_train = len(train_dataset)
    n_val = len(val_dataset)

    # 2. DataLoader
    num_workers = min(4, os.cpu_count()) if os.name == 'nt' else min(8, os.cpu_count())
    loader_args = dict(batch_size=batch_size, num_workers=num_workers, pin_memory=True)
    train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)
    val_loader = DataLoader(val_dataset, shuffle=False, drop_last=True, **loader_args)

    # 3. WandB åˆå§‹åŒ– (ä¿ç•™åŸæœ‰é…ç½®)
    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')
    experiment.config.update(dict(
        epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,
        img_scale=img_scale, amp=amp, backbone_lr=backbone_lr_scale
    ), allow_val_change=True)
    
    logging.info(f'''Starting training:
        Epochs:          {epochs}
        Batch size:      {batch_size}
        Learning rate:   {learning_rate}
        Training size:   {n_train}
        Validation size: {n_val}
        Checkpoints:     {save_checkpoint}
        Device:          {device.type}
        Images scaling:  {img_scale}
        Mixed Precision: {amp}
    ''')

    # 4. ä¼˜åŒ–å™¨ä¸å·®åˆ†å­¦ä¹ ç‡
    backbone_params_ids = []
    use_differential_lr = False
    
    if backbone_lr_scale < 1.0:
        if hasattr(model, 'encoder_name') and model.encoder_name in ['resnet', 'cnextv2']:
            use_differential_lr = True
        elif hasattr(model, 'use_resnet_encoder') and model.use_resnet_encoder:
            use_differential_lr = True

    if use_differential_lr:
        logging.info(f'âœ¨ å¯ç”¨å·®åˆ†å­¦ä¹ ç‡ç­–ç•¥: Backbone Scale = {backbone_lr_scale}')
        backbone_names = ['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 
                          'enc_stem', 'enc_model'] 
        
        for name, module in model.named_children():
            if name in backbone_names:
                for param in module.parameters():
                    backbone_params_ids.append(id(param))
        
        backbone_params = filter(lambda p: id(p) in backbone_params_ids, model.parameters())
        base_params = filter(lambda p: id(p) not in backbone_params_ids, model.parameters())
        
        param_groups = [
            {'params': base_params, 'lr': learning_rate}, 
            {'params': backbone_params, 'lr': learning_rate * backbone_lr_scale}
        ]
    else:
        logging.info('ä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡ (æ— å·®åˆ†)')
        param_groups = model.parameters()

    if optimizer_type.lower() == 'adamw':
        optimizer = optim.AdamW(param_groups, lr=learning_rate, weight_decay=weight_decay)
        logging.info('âœ… Using AdamW optimizer')
    else:
        optimizer = optim.RMSprop(param_groups, lr=learning_rate, weight_decay=weight_decay,
                                  momentum=momentum, foreach=True)
        logging.info('âœ… Using RMSprop optimizer')

    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-9)
    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)

    # æŸå¤±å‡½æ•°
    if model.n_classes > 1:
        criterion = nn.CrossEntropyLoss()
    else:
        loss_parts = loss_combination.split('+')
        weights = [float(w) for w in loss_weights.split(',')] if ',' in loss_weights else [1.0]*len(loss_parts)
        
        if loss_combination == 'bce': criterion = nn.BCEWithLogitsLoss()
        elif loss_combination == 'focal': criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        elif loss_combination == 'dice': criterion = DiceLossOnly()
        else: criterion = CombinedLoss(loss_parts, weights, focal_alpha, focal_gamma)
        logging.info(f'âœ… Using Loss: {loss_combination}')
    # ğŸ”¥ [æ–°å¢] åˆå§‹åŒ– EdgeLoss (å¿…é¡»æ”¾åœ¨è¿™é‡Œ)
    edge_criterion = EdgeLoss(device=device)
    global_step = 0

    # æ¢å¤ Checkpoint
    if checkpoint_to_load is not None:
        try:
            optimizer.load_state_dict(checkpoint_to_load['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint_to_load['scheduler_state_dict'])
            if 'grad_scaler_state_dict' in checkpoint_to_load and amp:
                grad_scaler.load_state_dict(checkpoint_to_load['grad_scaler_state_dict'])
            logging.info('âœ… è®­ç»ƒçŠ¶æ€å®Œå…¨æ¢å¤')
        except Exception as e:
            logging.warning(f'âš ï¸ æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥: {e}')

    # ============================================================
    # 5. è®­ç»ƒå¾ªç¯
    # ============================================================
    for epoch in range(start_epoch, epochs + 1):
        model.train()
        epoch_loss = 0
        epoch_grad_norms = []
        batch_count = 0
        
        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:
            for batch in train_loader:
                images, true_masks = batch['image'], batch['mask']
                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)
                true_masks = true_masks.to(device=device, dtype=torch.long)

                with torch.cuda.amp.autocast(enabled=amp):
                    output = model(images)
                    
                   # -----------------------------------------------------------
                    # ğŸ”¥ ä¿®å¤åçš„é€»è¾‘ï¼šè‡ªé€‚åº”å¤„ç† 2è¾“å‡º æˆ– 3è¾“å‡º
                    # -----------------------------------------------------------
                    if isinstance(output, tuple):
                        # 1. å‡†å¤‡è¾¹ç¼˜çœŸå€¼ (æ‰€æœ‰åŒæµæ¨¡å¼éƒ½éœ€è¦)
                        true_edges = generate_edge_tensor(true_masks)

                        if len(output) == 3:
                            # === [æ¨¡å¼ A] MDBES-Net (Seg, Body, Edge) ===
                            masks_pred, body_pred, edge_pred = output
                            
                            # Body GT è®¡ç®—
                            true_masks_float = true_masks.unsqueeze(1).float()
                            true_body = torch.clamp(true_masks_float - true_edges, 0, 1)

                            # å°ºå¯¸å¯¹é½
                            if edge_pred.shape[2:] != true_edges.shape[2:]:
                                edge_pred = F.interpolate(edge_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)
                                body_pred = F.interpolate(body_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)

                            # Loss è®¡ç®—
                            l_seg = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                            l_body = F.binary_cross_entropy_with_logits(body_pred, true_body)
                            l_edge = F.binary_cross_entropy_with_logits(edge_pred, true_edges, pos_weight=torch.tensor([5.0], device=device))
                            
                            loss = l_seg + (lambda_body * l_body) + (lambda_edge * l_edge)

                        elif len(output) == 2:
                            # === [æ¨¡å¼ B] S-DMFNet (Seg, Aux_Edge) ===
                            # ğŸ”¥ è¿™æ˜¯ä½ ç°åœ¨éœ€è¦çš„é€»è¾‘
                            masks_pred, edge_pred = output
                            
                            # å°ºå¯¸å¯¹é½
                            if edge_pred.shape[2:] != true_edges.shape[2:]:
                                edge_pred = F.interpolate(edge_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)
                            
                            # Loss è®¡ç®—
                            # 1. ä¸»åˆ†å‰² Loss (BCE/Dice/Focal)
                            l_seg = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                            
                            # 2. è¾…åŠ©è¾¹ç¼˜ Loss (BCE With Logits)
                            # ä½¿ç”¨è¾…åŠ©å¤´é¢„æµ‹çš„ edge_pred å’Œç”Ÿæˆçš„ true_edges è¿›è¡Œæ¯”è¾ƒ
                            # pos_weight=5.0 æ˜¯ä¸ºäº†è§£å†³è¾¹ç¼˜åƒç´ è¿‡å°‘çš„ä¸å¹³è¡¡é—®é¢˜
                            l_edge = F.binary_cross_entropy_with_logits(
                                edge_pred, true_edges, pos_weight=torch.tensor([5.0], device=device)
                            )
                            
                            # 3. æ€» Loss
                            loss = l_seg + (lambda_edge * l_edge)

                    else:
                        # === [æ¨¡å¼ C] å•è¾“å‡ºæ¨¡å¼ (Seg only) ===
                        masks_pred = output
                        loss = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                        
                        # ğŸ”¥ éšå¼è¾¹ç¼˜ç›‘ç£ (Gradient-based Edge Loss)
                        # å¦‚æœæ²¡æœ‰è¾…åŠ©å¤´ï¼Œå°±å¼ºè¿«ä¸»åˆ†å‰²å›¾çš„æ¢¯åº¦è¦é”åˆ©
                        if lambda_edge > 0:
                            loss_e = edge_criterion(masks_pred, true_masks)
                            loss += lambda_edge * loss_e

                # å¼‚å¸¸æ£€æµ‹
                if torch.isnan(loss) or torch.isinf(loss):
                    logging.error(f'Loss NaN/Inf detected: {loss.item()}. Skipping batch.')
                    optimizer.zero_grad()
                    continue
                # åå‘ä¼ æ’­
                optimizer.zero_grad(set_to_none=True)
                grad_scaler.scale(loss).backward()
                grad_scaler.unscale_(optimizer)
                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)
                epoch_grad_norms.append(grad_norm.item())

                grad_scaler.step(optimizer)
                grad_scaler.update()

                pbar.update(images.shape[0])
                global_step += 1
                batch_count += 1
                epoch_loss += loss.item()
                
                # WandB å®æ—¶æ—¥å¿— (ä¿ç•™ä½ çš„åŸé…ç½®)
                experiment.log({
                    'train/loss_batch': loss.item(), 
                    'train/grad_norm': grad_norm.item(), 
                    'global_step': global_step
                })
                pbar.set_postfix(**{'loss': loss.item(), 'grad': grad_norm.item()})

        # ====== éªŒè¯ä¸è¯„ä¼° ======
        avg_epoch_loss = epoch_loss / max(batch_count, 1)
        avg_grad_norm = sum(epoch_grad_norms) / len(epoch_grad_norms) if epoch_grad_norms else 0.0
        # ğŸ”´ [ä¿®æ”¹ 1] ä¼ å…¥ criterion
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å®šä¹‰å¥½çš„ criterion è®¡ç®— loss
        val_metrics = evaluate(model, val_loader, device, amp, criterion=criterion)
        
        
        # 2. ğŸ”¥ [å…³é”®ä¿®æ”¹] ç¦ç”¨é˜ˆå€¼æ‰«æï¼Œç›´æ¥å¤ç”¨ 0.5 é˜ˆå€¼çš„ç»“æœ
        # logging.info('Starting threshold scanning...')
        # threshold_res = threshold_scan_evaluate(...) # <--- æ³¨é‡Šæ‰è¿™ä¸€è¡Œ
        
        # ğŸ”¥ æ‰‹åŠ¨æ„é€ ç»“æœå­—å…¸ï¼Œä¿æŒå˜é‡åå…¼å®¹ï¼Œé˜²æ­¢åé¢æŠ¥é”™
        threshold_res = {
            'best_dice': val_metrics['dice'],      # ç›´æ¥ç”¨ 0.5 çš„ Dice
            'best_f1': val_metrics['f1'],          # ç›´æ¥ç”¨ 0.5 çš„ F1
            'best_threshold_dice': 0.5,            # å›ºå®šæ˜¾ç¤º 0.5
            'best_threshold_f1': 0.5               # å›ºå®šæ˜¾ç¤º 0.5
        }
        
        logging.info('â© Skipping threshold scan. Using fixed threshold 0.5.')

        scheduler.step()
        
        # 4. è¯¦ç»†æ§åˆ¶å°è¾“å‡º
        logging.info(
            f'Epoch {epoch}/{epochs} completed - '
            f'Train Loss: {avg_epoch_loss:.4f}, '
            f'Val Loss: {val_metrics["loss"]:.4f}, '
            f'Avg Grad Norm: {avg_grad_norm:.4f}, '
            f'Val Dice: {val_metrics["dice"]:.4f}, '
            f'Val IoU: {val_metrics["iou"]:.4f}, '
            f'Val F1: {val_metrics["f1"]:.4f}, '
            f'Val Precision: {val_metrics["precision"]:.4f}, '
            f'Val Recall: {val_metrics["recall"]:.4f}, '
            f'Best Dice: {threshold_res["best_dice"]:.4f} (threshold: {threshold_res["best_threshold_dice"]:.2f}), '
            f'Best F1: {threshold_res["best_f1"]:.4f} (threshold: {threshold_res["best_threshold_f1"]:.2f})'
        )

        # 5. ä¸Šä¼  WandB æ—¥å¿—
        current_lr = optimizer.param_groups[0]['lr']
        experiment.log({
            'train/epoch_loss': avg_epoch_loss,
            'val/loss': val_metrics['loss'],       # <--- å…³é”®ï¼æ·»åŠ è¿™ä¸€è¡Œï¼
            'train/avg_grad_norm': avg_grad_norm,
            'val/dice': val_metrics['dice'],
            'val/iou': val_metrics['iou'],
            'val/f1': val_metrics['f1'],
            'val/precision': val_metrics['precision'],
            'val/recall': val_metrics['recall'],
            'val/best_dice': threshold_res['best_dice'],
            'val/best_f1': threshold_res['best_f1'],
            'epoch': epoch,                        # ğŸ”¥ æ–°å¢: å½“å‰è½®æ¬¡
            'train/learning_rate': current_lr      # ğŸ”¥ æ–°å¢: å½“å‰å­¦ä¹ ç‡æ›²çº¿
        })

        

        # ====== ä¿å­˜ Checkpoint ======
        if save_checkpoint:
            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'grad_scaler_state_dict': grad_scaler.state_dict(),
                'loss': avg_epoch_loss,
                'val_dice': float(val_metrics['dice']),
                'val_best_f1': float(threshold_res['best_f1']),
                # ... ä¿ç•™ä½ çš„å…¶ä»–é”®å€¼
            }
            
            # Latest
            torch.save(checkpoint, str(dir_checkpoint / 'checkpoint_latest.pth'))
            # 2. ğŸ”¥ [ä¿®æ”¹ç‚¹ 2] 30è½®ä»¥åï¼Œæ¯ä¸€è½®éƒ½é¢å¤–ä¿å­˜ä¸€ä¸ªæ–‡ä»¶
            if epoch > 30:
                # æ–‡ä»¶åä¾‹å¦‚: checkpoint_epoch_31.pth, checkpoint_epoch_32.pth ...
                epoch_path = str(dir_checkpoint / f'checkpoint_epoch_{epoch}.pth')
                torch.save(checkpoint, epoch_path)
                logging.info(f'ğŸ’¾ [å¤‡ä»½] å·²ä¿å­˜ç¬¬ {epoch} è½®æƒé‡: {epoch_path}')
            # Best
            best_path = str(dir_checkpoint / 'checkpoint_best.pth')
            current_dice = val_metrics['dice']
            save_best = False
            
            if not Path(best_path).exists():
                save_best = True
                logging.info(f'   ğŸŒŸ é¦–æ¬¡åˆ›å»ºæœ€ä½³æ¨¡å‹ (Dice: {current_dice:.4f})')
            else:
                try:
                    prev_best = torch.load(best_path, map_location='cpu', weights_only=False).get('val_dice', 0.0)
                    if current_dice > prev_best:
                        save_best = True
                        logging.info(f'   ğŸ† åˆ·æ–°æœ€ä½³è®°å½•! ({prev_best:.4f} -> {current_dice:.4f})')
                    else:
                        # ğŸ”¥ğŸ”¥ğŸ”¥ è¿™ä¸€è¡Œæ˜¯ä½ è¦æ±‚çš„å…³é”®æ—¥å¿— ğŸ”¥ğŸ”¥ğŸ”¥
                        logging.info(f'   (å½“å‰ Dice {current_dice:.4f} æœªè¶…è¿‡æœ€ä½³ {prev_best:.4f})')
                except:
                    save_best = True
            # ğŸ”¥ å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼šä¿å­˜æƒé‡ + ä¸Šä¼ é«˜æ¸…å›¾ç‰‡
            if save_best:
                torch.save(checkpoint, best_path)
                try:
                    # è°ƒç”¨æˆ‘ä»¬å†™å¥½çš„å¯è§†åŒ–å‡½æ•°
                    log_best_visuals(model, val_loader, device, num_samples=5)
                except Exception as e:
                    logging.warning(f"âš ï¸ å¯è§†åŒ–ä¸Šä¼ å¤±è´¥: {e}")

            
    wandb.finish()

# è®¡ç®— Loss è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
def calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma):
    if loss_combination == 'bce':
        criterion = nn.BCEWithLogitsLoss()
        return criterion(masks_pred.squeeze(1), true_masks.float())
    elif loss_combination == 'focal':
        criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        return criterion(masks_pred.squeeze(1), true_masks.float())
    elif loss_combination == 'dice':
        return dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)
    else:
        # Combined Loss (å‡è®¾ä½ åœ¨ utils.losses é‡Œå®šä¹‰äº†)
        # è¿™é‡Œä¸ºäº†ç¨³å¥æ€§ï¼Œå¦‚æœæ‰¾ä¸åˆ° CombinedLoss ç±»ï¼Œå›é€€åˆ°æ‰‹åŠ¨ç›¸åŠ 
        try:
            criterion = CombinedLoss(loss_combination.split('+'), [1.0, 1.0], focal_alpha, focal_gamma)
            return criterion(masks_pred.squeeze(1), true_masks.float())
        except:
             # ç®€å•çš„ fallback
             bce = nn.BCEWithLogitsLoss()(masks_pred.squeeze(1), true_masks.float())
             dice = dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)
             return bce + dice

def get_args():
    parser = argparse.ArgumentParser(description='Train the Unified UNet')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--epochs', '-e', type=int, default=20)
    parser.add_argument('--batch-size', '-b', type=int, default=8)
    parser.add_argument('--learning-rate', '-l', type=float, default=1e-4)
    parser.add_argument('--load', '-f', type=str, default=False)
    parser.add_argument('--scale', '-s', type=float, default=1.0)
    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0)
    parser.add_argument('--amp', action='store_true', default=False)
    parser.add_argument('--bilinear', action='store_true', default=False)
    parser.add_argument('--classes', '-c', type=int, default=1)
    parser.add_argument('--start-epoch', type=int, default=1)
    
    # æ¶æ„å‚æ•°
    parser.add_argument('--encoder', type=str, default='resnet', choices=['resnet', 'cnextv2', 'standard'])
    parser.add_argument('--decoder', type=str, default='phd', choices=['phd', 'standard'])
    parser.add_argument('--cnext-type', type=str, default='convnextv2_tiny')
    
    # SOTA æ¨¡å—å¼€å…³
    parser.add_argument('--use-dcn', action='store_true', default=False, help='Enable standard DCNv3')
    parser.add_argument('--use-dubm', action='store_true', default=False, help='Enable D-UBM (SOTA)')
    parser.add_argument('--use-strg', action='store_true', default=False, help='Enable STRG Skip Enhancement')
    parser.add_argument('--use-dual-stream', action='store_true', default=False, help='Enable Dual-Stream Boundary Architecture')
    parser.add_argument('--use-wavelet-denoise', action='store_true', default=False, help='Enable Wavelet Denoising on Skip Connections')
    parser.add_argument('--use-dsis', action='store_true', default=False, help='Enable Dual-Stream Interactive Skip Module')
    parser.add_argument('--use-unet3p', action='store_true', default=False, help='Enable UNet 3+ Full-Scale Skip Connections')
    # [æ–°å¢] MDBES-Net ç›¸å…³å‚æ•°
    parser.add_argument('--use_decouple', action='store_true', default=False, help='Enable MDBES-Net explicit decoupling supervision')
    parser.add_argument('--lambda_edge', type=float, default=20.0, help='Weight for the Edge loss (default: 20.0)')
    parser.add_argument('--lambda_body', type=float, default=1.0, help='Weight for the Body loss (default: 1.0)')
    
    # å…¶ä»–å¢å¼ºæ¨¡å— (ä¿æŒåŸæœ‰å¼€å…³å®šä¹‰ï¼Œä½†ç§»é™¤äº†æ—§ç‰ˆ Edge Logic çš„æ‰§è¡Œ)
    parser.add_argument('--use-wgn-enhancement', action='store_true', default=False)
    parser.add_argument('--use-cafm', action='store_true', default=False)
    parser.add_argument('--use-edge-loss', action='store_true', default=False, help='Legacy WGN Edge Loss (Deprecated logic removed)')
    parser.add_argument('--use-fme', action='store_true', default=False, 
                        help='Enable Frequency-Mamba Enhancement (FME) module')
    # WGN å‚æ•°
    parser.add_argument('--wgn-base-order', type=int, default=3)
    parser.add_argument('--wgn-orders', type=str, default=None)

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument('--optimizer', type=str, default='adamw', choices=['adamw', 'rmsprop'])
    parser.add_argument('--loss-combination', type=str, default='focal+dice')
    parser.add_argument('--loss-weights', type=str, default='1.0,1.0')
    parser.add_argument('--focal-alpha', type=float, default=0.25)
    parser.add_argument('--focal-gamma', type=float, default=2.0)
    parser.add_argument('--weight-decay', type=float, default=1e-8)
    parser.add_argument('--momentum', type=float, default=0.999)
    parser.add_argument('--gradient-clipping', type=float, default=1.0)
    parser.add_argument('--backbone-lr-scale', type=float, default=0.1)

    return parser.parse_args()

if __name__ == '__main__':
    args = get_args()
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # WGN Orders å¤„ç†
    wgn_orders = None
    if args.use_wgn_enhancement:
        if args.wgn_orders:
            orders_list = [int(x) for x in args.wgn_orders.split(',')]
            wgn_orders = {'layer1': (orders_list[0], orders_list[1]), 'layer2': (orders_list[2], orders_list[3]), 'layer3': (orders_list[4], orders_list[5])}
        else:
            base = args.wgn_base_order
            wgn_orders = {'layer1': (base, base-1), 'layer2': (base+1, base), 'layer3': (base+2, base+1)}

    # å®ä¾‹åŒ–æ¨¡å‹
    logging.info(f"ğŸš€ Building Model: Encoder={args.encoder}, Decoder={args.decoder}")
    model = UNet(
        n_channels=3,
        n_classes=args.classes,
        bilinear=args.bilinear,
        encoder_name=args.encoder,
        decoder_name=args.decoder,
        cnext_type=args.cnext_type,
        use_wgn_enhancement=args.use_wgn_enhancement,
        use_cafm=args.use_cafm,
        # æ³¨æ„: å³ä½¿ä¼ å…¥ use_edge_loss=True, train loop ä¸­å·²ç§»é™¤äº†å¤„ç†å®ƒçš„é€»è¾‘
        use_edge_loss=args.use_edge_loss, 
        wgn_orders=wgn_orders,
        use_dcn_in_phd=args.use_dcn,
        use_dubm=args.use_dubm,
        use_strg=args.use_strg,
        use_dual_stream=args.use_dual_stream, # ğŸ”¥ æ–°å¢åŒæµ
        use_dsis=args.use_dsis, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_unet3p=args.use_unet3p, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_wavelet_denoise=args.use_wavelet_denoise  # ğŸ‘ˆ ä¼ å…¥è¿™ä¸ªå‚æ•°
          # ğŸ”¥ ä¼ å…¥ MDBES-Net è§£è€¦å‚æ•°
    )
    
    model = model.to(memory_format=torch.channels_last)
    model.to(device=device)

    # åŠ è½½æƒé‡
    checkpoint_to_load = None
    if args.load:
        try:
            ckpt = torch.load(args.load, map_location=device, weights_only=False)
            if 'model_state_dict' in ckpt:
                model.load_state_dict(ckpt['model_state_dict'])
                checkpoint_to_load = ckpt
                # ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] è‡ªåŠ¨è¯»å–æ–­ç‚¹è½®æ•°ï¼Œå®ç°æ— ç¼ç»­è®­ ğŸ”¥ğŸ”¥ğŸ”¥
                if 'epoch' in ckpt:
                    args.start_epoch = ckpt['epoch'] + 1
                    logging.info(f"ğŸ”„ è‡ªåŠ¨æ£€æµ‹åˆ°æ–­ç‚¹ (Epoch {ckpt['epoch']})ï¼Œå°†ä» Epoch {args.start_epoch} ç»§ç»­è®­ç»ƒï¼")
            else:
                model.load_state_dict(ckpt)
            logging.info(f'Model loaded from {args.load}')
        except Exception as e:
            logging.error(f"Load failed: {e}")
            sys.exit(1)

    try:
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            device=device,
            img_scale=args.scale,
            val_percent=args.val / 100,
            amp=args.amp,
            start_epoch=args.start_epoch,
            checkpoint_to_load=checkpoint_to_load,
            backbone_lr_scale=args.backbone_lr_scale,
            weight_decay=args.weight_decay,
            momentum=args.momentum,
            gradient_clipping=args.gradient_clipping,
            loss_combination=args.loss_combination,
            loss_weights=args.loss_weights,
            focal_alpha=args.focal_alpha,
            focal_gamma=args.focal_gamma,
            optimizer_type=args.optimizer,
            # ğŸ”¥ [æ–°å¢] æŠŠæƒé‡ä¼ ç»™è®­ç»ƒå‡½æ•°
            lambda_edge=args.lambda_edge,
            lambda_body=args.lambda_body
        )
    except KeyboardInterrupt:
        torch.save(model.state_dict(), 'INTERRUPTED.pth')
        logging.info('Saved interrupt checkpoint')