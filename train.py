import argparse
import logging
import os
import random
import sys
import numpy as np  # <--- æ·»åŠ è¿™ä¸€è¡Œ
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from torch import optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import wandb
import cv2
from evaluate import evaluate, threshold_scan_evaluate
from utils.data_loading import BasicDataset
from utils.dice_score import dice_loss


from utils.losses import FocalLoss, CombinedLoss, DiceLossOnly, EdgeLoss
from utils.utils import log_grad_stats

from unet import UNet

import random

def setup_seed(seed):
    import random
    import numpy as np
    
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è¯ç®—æ³•ç»“æœç¡®å®š
    # torch.backends.cudnn.benchmark = False   # å»ºè®®æ³¨é‡Šæ‰ã€‚è®¾ä¸ºFalseä¼šå˜æ…¢ï¼Œé€šå¸¸ä¸å€¼å¾—

def log_best_visuals(model, val_loader, device, num_samples=5):
    """
    å°† åŸå›¾ã€é¢„æµ‹æ©ç ã€çœŸå€¼æ©ç  å¹¶æ’å±•ç¤ºåœ¨ WandB è¡¨æ ¼ä¸­ã€‚
    è‡ªåŠ¨å¤„ç†åæ ‡å‡†åŒ–ï¼Œé˜²æ­¢åŸå›¾å˜é»‘ã€‚
    """
    model.eval()
    
    # 1. å®šä¹‰ ImageNet çš„å‡å€¼å’Œæ–¹å·® (ç”¨äºåæ ‡å‡†åŒ–)
    # å¦‚æœä½ åœ¨ dataset é‡Œç”¨äº†å…¶ä»–æ•°å€¼ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)

    # 2. åˆ›å»º WandB è¡¨æ ¼ï¼Œå®šä¹‰ä¸‰åˆ—
    columns = ["Input Image (åŸå›¾)", "Prediction (é¢„æµ‹)", "Ground Truth (çœŸå€¼)"]
    test_table = wandb.Table(columns=columns)

    print(f"âœ¨ æ­£åœ¨ç”Ÿæˆ {num_samples} ç»„å¯è§†åŒ–æ ·æœ¬...")

    with torch.no_grad():
        for i, batch in enumerate(val_loader):
            if len(test_table.data) >= num_samples: break
            
            imgs = batch['image'].to(device)
            masks = batch['mask'].to(device)
            
            # æ¨ç†
            outputs = model(imgs)
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float()
            
            for j in range(imgs.shape[0]):
                if len(test_table.data) >= num_samples: break
                
                # --- A. ä¿®å¤åŸå›¾ (é˜²æ­¢å…¨é»‘çš„æ ¸å¿ƒæ­¥éª¤) ---
                # 1. åæ ‡å‡†åŒ–: image = image * std + mean
                img_tensor = imgs[j] * std + mean
                # 2. é™åˆ¶æ•°å€¼èŒƒå›´åœ¨ 0-1 ä¹‹é—´ (æ¶ˆé™¤è®¡ç®—è¯¯å·®å¯¼è‡´çš„è¶Šç•Œ)
                img_tensor = torch.clamp(img_tensor, 0, 1)
                # 3. è½¬æ¢ç»´åº¦ [C,H,W] -> [H,W,C] å¹¶è½¬ä¸º numpy
                img_np = img_tensor.cpu().numpy().transpose(1, 2, 0)
                # 4. ä¹˜ä»¥ 255 å¹¶è½¬ä¸ºæ•´æ•° (å˜æˆæ ‡å‡†çš„ RGB å›¾ç‰‡)
                img_np = (img_np * 255).astype(np.uint8)

                # --- B. å¤„ç†æ©ç  (å˜æˆé»‘ç™½å›¾) ---
                # 1. å–å‡ºå•å¼ æ©ç 
                pred_mask = preds[j].squeeze().cpu().numpy()
                true_mask = masks[j].squeeze().cpu().numpy()
                
                # 2. ä¹˜ä»¥ 255ï¼(éå¸¸é‡è¦ï¼š0å˜æˆé»‘ï¼Œ1å˜æˆç™½)
                pred_mask = (pred_mask * 255).astype(np.uint8)
                true_mask = (true_mask * 255).astype(np.uint8)
                
                # --- C. åˆ›å»º WandB å›¾ç‰‡å¯¹è±¡ ---
                input_img_log = wandb.Image(img_np)
                pred_img_log = wandb.Image(pred_mask)
                true_img_log = wandb.Image(true_mask)
                
                # --- D. æ·»åŠ åˆ°è¡¨æ ¼çš„ä¸€è¡Œä¸­ ---
                test_table.add_data(input_img_log, pred_img_log, true_img_log)

    # 3. ä¸Šä¼ è¡¨æ ¼
    wandb.log({"Visual Results Table": test_table}, commit=False)
    print("âœ… å¯è§†åŒ–è¡¨æ ¼å·²ä¸Šä¼ ï¼")
    
    model.train() # æ¢å¤è®­ç»ƒæ¨¡å¼

# ================= é…ç½®è·¯å¾„ =================
dir_img = Path('./data/train/imgs/')
dir_mask = Path('./data/train/masks/')
val_dir_img = Path('./data/val/imgs/')
val_dir_mask = Path('./data/val/masks/')
dir_checkpoint = Path('./data/checkpoints/')

# ================= è¾…åŠ©å‡½æ•° =================

# ================= è¾…åŠ©å‡½æ•° (ä¿®æ”¹ç‰ˆ) =================

def generate_edge_tensor(mask, edge_width=3):
    """
    ğŸ”¥ [æ–°] å½¢æ€å­¦è¾¹ç¼˜ç”Ÿæˆ (Morphological Edge)
    åŸç†: è†¨èƒ€(Mask) - è…èš€(Mask) = è¾¹ç¼˜å¸¦
    ä¼˜åŠ¿: ç”Ÿæˆ 3-5 åƒç´ å®½çš„è¾¹ç¼˜ï¼Œå®¹é”™ç‡é«˜ï¼Œé€‚åˆè®­ç»ƒ Mamba/CNN æ•æ‰ç»“æ„
    """
    # 1. è®°å½•åŸå§‹æ‰€åœ¨çš„è®¾å¤‡ (CPU or CUDA)
    target_device = mask.device
    
    # 2. è½¬æ¢ä¸º Numpy (CPU) è¿›è¡Œ OpenCV å¤„ç†
    if isinstance(mask, torch.Tensor):
        mask_np = mask.detach().cpu().numpy()
    else:
        mask_np = mask
        
    # å¦‚æœç»´åº¦æ˜¯ [B, 1, H, W]ï¼Œå‹ç¼©ä¸º [B, H, W]
    if mask_np.ndim == 4:
        mask_np = mask_np.squeeze(1)
        
    B, H, W = mask_np.shape
    edges = []
    
    # å®šä¹‰ç»“æ„å…ƒç´  (å†³å®šè¾¹ç¼˜å®½åº¦)
    # cv2.MORPH_RECT è¡¨ç¤ºçŸ©å½¢ç»“æ„
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (edge_width, edge_width))
    
    for i in range(B):
        # ç¡®ä¿æ˜¯ uint8 ç±»å‹
        m = mask_np[i].astype(np.uint8)
        
        # è†¨èƒ€ - è…èš€
        dilated = cv2.dilate(m, kernel, iterations=1)
        eroded = cv2.erode(m, kernel, iterations=1)
        
        # ç›¸å‡å¾—åˆ°è¾¹ç¼˜
        edge = dilated - eroded
        
        # äºŒå€¼åŒ–ä¿æŠ¤ (å¤§äº0çš„éƒ½ç®—è¾¹ç¼˜)
        edge[edge > 0] = 1
        edges.append(edge)
    
    # 3. å †å å¹¶è½¬å› Tensor
    edges = np.stack(edges, axis=0) # [B, H, W]
    edges_tensor = torch.from_numpy(edges).float().unsqueeze(1) # [B, 1, H, W]
    
    # 4. ç§»å›åŸæ¥çš„è®¾å¤‡ (GPU)
    return edges_tensor.to(target_device)

def train_model(
        model,
        device,
        epochs: int = 20,
        batch_size: int = 32,
        learning_rate: float = 1e-5,
        val_percent: float = 0.1,
        save_checkpoint: bool = True,
        img_scale: float = 1.0,
        amp: bool = True,
        weight_decay: float = 1e-8,
        momentum: float = 0.999,
        gradient_clipping: float = 1.0,
        start_epoch: int = 1,
        checkpoint_to_load: dict = None,
        loss_combination: str = 'focal+dice',
        loss_weights: str = '1.0,1.0',
        focal_alpha: float = 0.25,
        focal_gamma: float = 2.0,
        optimizer_type: str = 'adamw',
        backbone_lr_scale: float = 0.1,
        lambda_edge: float = 20.0,
        lambda_body: float = 1.0,
        accumulation_steps: int = 1  # <--- ğŸ”¥ å¿…é¡»åŠ ä¸Šè¿™ä¸€è¡Œï¼
        
):
    # 1. æ•°æ®å‡†å¤‡
    train_dataset = BasicDataset(dir_img, dir_mask, img_scale, mask_suffix='', augment=True)
    val_dataset = BasicDataset(val_dir_img, val_dir_mask, img_scale, mask_suffix='', augment=False)
    n_train = len(train_dataset)
    n_val = len(val_dataset)

    # 2. DataLoader
    num_workers = min(4, os.cpu_count()) if os.name == 'nt' else min(8, os.cpu_count())
    loader_args = dict(batch_size=batch_size, num_workers=num_workers, pin_memory=True)
    train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True, **loader_args)
    val_loader = DataLoader(val_dataset, shuffle=False, drop_last=True, **loader_args)

    # 3. WandB åˆå§‹åŒ– (ä¿ç•™åŸæœ‰é…ç½®)
    # ğŸ”¥ [æ–°å¢] å¿…é¡»å…ˆå®šä¹‰ run_idï¼Œå¦åˆ™åé¢ä¼šæŠ¥é”™
    run_id = None
    if checkpoint_to_load is not None and 'wandb_id' in checkpoint_to_load:
        run_id = checkpoint_to_load['wandb_id']
        logging.info(f"ğŸ”— æ£€æµ‹åˆ° WandB ID: {run_id}ï¼Œæ­£åœ¨æ¢å¤è¿æ¥...")
    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must', id=run_id)
    experiment.config.update(dict(
        epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,
        img_scale=img_scale, amp=amp, backbone_lr=backbone_lr_scale
    ), allow_val_change=True)
    
    logging.info(f'''Starting training:
        Epochs:          {epochs}
        Batch size:      {batch_size}
        Learning rate:   {learning_rate}
        Training size:   {n_train}
        Validation size: {n_val}
        Checkpoints:     {save_checkpoint}
        Device:          {device.type}
        Images scaling:  {img_scale}
        Mixed Precision: {amp}
    ''')

    # 4. ä¼˜åŒ–å™¨ä¸å·®åˆ†å­¦ä¹ ç‡
    backbone_params_ids = []
    use_differential_lr = False
    
    # ğŸ”¥ ä¿®æ”¹ 1: åªè¦ä½ è®¾ç½®äº†å€ç‡ < 1.0ï¼Œå°±æ— æ¡ä»¶å¼€å¯ï¼Œä¸è¦å»æ£€æŸ¥ model.encoder_name
    if backbone_lr_scale < 1.0:
        use_differential_lr = True

    if use_differential_lr:
        logging.info(f'âœ¨ å¯ç”¨å·®åˆ†å­¦ä¹ ç‡ç­–ç•¥: Backbone Scale = {backbone_lr_scale}')
        
        
        backbone_names = ['spatial_encoder'] 
        
        # å¯»æ‰¾éª¨å¹²å‚æ•°
        found_backbone_layer = False
        for name, module in model.named_children():
            if name in backbone_names:
                found_backbone_layer = True
                # logging.info(f"   -> æ•è·éª¨å¹²å±‚: {name}") # è°ƒè¯•æ—¶å¯ä»¥è§£å¼€è¿™è¡Œ
                for param in module.parameters():
                    backbone_params_ids.append(id(param))
        
        # ğŸ”¥ ä¿®æ”¹ 2: å®‰å…¨æ£€æŸ¥
        # å¦‚æœæ‰¾äº†ä¸€åœˆæ²¡æ‰¾åˆ°éª¨å¹²å±‚ (åå­—ä¸å¯¹)ï¼Œå°±è‡ªåŠ¨å›é€€åˆ°ç»Ÿä¸€å­¦ä¹ ç‡ï¼Œé˜²æ­¢æŠ¥é”™
        if not found_backbone_layer or len(backbone_params_ids) == 0:
            logging.warning("âš ï¸ è­¦å‘Š: å¯ç”¨äº†å·®åˆ†å­¦ä¹ ç‡ï¼Œä½†æ²¡åœ¨æ¨¡å‹é‡Œæ‰¾åˆ°åä¸º 'enc_model' æˆ– 'encoder' çš„å±‚ï¼")
            logging.warning("   -> å°†è‡ªåŠ¨å›é€€åˆ°ç»Ÿä¸€å­¦ä¹ ç‡ã€‚è¯·æ£€æŸ¥ UNet ä»£ç ä¸­éª¨å¹²ç½‘çš„å˜é‡åã€‚")
            param_groups = model.parameters()
        else:
            # æ­£å¸¸åˆ†ç¦»å‚æ•°
            backbone_params = filter(lambda p: id(p) in backbone_params_ids, model.parameters())
            base_params = filter(lambda p: id(p) not in backbone_params_ids, model.parameters())
            
            param_groups = [
                {'params': base_params, 'lr': learning_rate}, 
                {'params': backbone_params, 'lr': learning_rate * backbone_lr_scale}
            ]
            logging.info(f"   -> æˆåŠŸåˆ†ç¦»å‚æ•°: éª¨å¹²ç½‘å°†ä½¿ç”¨ lr={learning_rate * backbone_lr_scale:.2e}")
            
    else:
        logging.info('ä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡ (æ— å·®åˆ†)')
        param_groups = model.parameters()

    if optimizer_type.lower() == 'adamw':
        optimizer = optim.AdamW(param_groups, lr=learning_rate, weight_decay=weight_decay)
        logging.info('âœ… Using AdamW optimizer')
    else:
        optimizer = optim.RMSprop(param_groups, lr=learning_rate, weight_decay=weight_decay,
                                  momentum=momentum, foreach=True)
        logging.info('âœ… Using RMSprop optimizer')

    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-9)
    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)

    # æŸå¤±å‡½æ•°
    if model.n_classes > 1:
        criterion = nn.CrossEntropyLoss()
    else:
        loss_parts = loss_combination.split('+')
        weights = [float(w) for w in loss_weights.split(',')] if ',' in loss_weights else [1.0]*len(loss_parts)
        
        if loss_combination == 'bce': criterion = nn.BCEWithLogitsLoss()
        elif loss_combination == 'focal': criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        elif loss_combination == 'dice': criterion = DiceLossOnly()
        else: criterion = CombinedLoss(loss_parts, weights, focal_alpha, focal_gamma)
        logging.info(f'âœ… Using Loss: {loss_combination}')
    # ğŸ”¥ [æ–°å¢] åˆå§‹åŒ– EdgeLoss (å¿…é¡»æ”¾åœ¨è¿™é‡Œ)
    edge_criterion = EdgeLoss(device=device)
    # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] æ¢å¤ global_step
    if checkpoint_to_load is not None and 'global_step' in checkpoint_to_load:
        global_step = checkpoint_to_load['global_step']
        logging.info(f"ğŸ“‰ ç»§ç»­ä» Global Step {global_step} å¼€å§‹è®°å½•æ—¥å¿—")
    else:
        global_step = 0

    # æ¢å¤ Checkpoint
    if checkpoint_to_load is not None:
        try:
            optimizer.load_state_dict(checkpoint_to_load['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint_to_load['scheduler_state_dict'])
            if 'grad_scaler_state_dict' in checkpoint_to_load and amp:
                grad_scaler.load_state_dict(checkpoint_to_load['grad_scaler_state_dict'])
            logging.info('âœ… è®­ç»ƒçŠ¶æ€å®Œå…¨æ¢å¤')
        except Exception as e:
            logging.warning(f'âš ï¸ æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥: {e}')

    # ============================================================
    # 5. è®­ç»ƒå¾ªç¯
    # ============================================================
    for epoch in range(start_epoch, epochs + 1):
        model.train()
        epoch_loss = 0
        epoch_grad_norms = []
        batch_count = 0
        
        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:
            for i, batch in enumerate(train_loader):
                images, true_masks = batch['image'], batch['mask']
                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)
                true_masks = true_masks.to(device=device, dtype=torch.long)

                with torch.cuda.amp.autocast(enabled=amp):
                    output = model(images)
                    
                   # -----------------------------------------------------------
                    # ğŸ”¥ ä¿®å¤åçš„é€»è¾‘ï¼šè‡ªé€‚åº”å¤„ç† 2è¾“å‡º æˆ– 3è¾“å‡º
                    # -----------------------------------------------------------
                    if isinstance(output, tuple):
                        # 1. å‡†å¤‡è¾¹ç¼˜çœŸå€¼ (æ‰€æœ‰åŒæµæ¨¡å¼éƒ½éœ€è¦)
                        true_edges = generate_edge_tensor(true_masks)

                        if len(output) == 3:
                            # === [æ¨¡å¼ A] MDBES-Net (Seg, Body, Edge) ===
                            masks_pred, body_pred, edge_pred = output
                            
                            # Body GT è®¡ç®—
                            true_masks_float = true_masks.unsqueeze(1).float()
                            true_body = torch.clamp(true_masks_float - true_edges, 0, 1)

                            # å°ºå¯¸å¯¹é½
                            if edge_pred.shape[2:] != true_edges.shape[2:]:
                                edge_pred = F.interpolate(edge_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)
                                body_pred = F.interpolate(body_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)

                            # Loss è®¡ç®—
                            l_seg = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                            l_body = F.binary_cross_entropy_with_logits(body_pred, true_body)
                            l_edge = F.binary_cross_entropy_with_logits(edge_pred, true_edges, pos_weight=torch.tensor([5.0], device=device))
                            
                            loss = l_seg + (lambda_body * l_body) + (lambda_edge * l_edge)

                        elif len(output) == 2:
                            # === [æ¨¡å¼ B] S-DMFNet (Seg, Aux_Edge) ===
                            # ğŸ”¥ è¿™æ˜¯ä½ ç°åœ¨éœ€è¦çš„é€»è¾‘
                            masks_pred, edge_pred = output
                            
                            # å°ºå¯¸å¯¹é½
                            if edge_pred.shape[2:] != true_edges.shape[2:]:
                                edge_pred = F.interpolate(edge_pred, size=true_edges.shape[2:], mode='bilinear', align_corners=True)
                            
                            # Loss è®¡ç®—
                            # 1. ä¸»åˆ†å‰² Loss (BCE/Dice/Focal)
                            l_seg = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                            
                            # 2. è¾…åŠ©è¾¹ç¼˜ Loss (BCE With Logits)
                            # ä½¿ç”¨è¾…åŠ©å¤´é¢„æµ‹çš„ edge_pred å’Œç”Ÿæˆçš„ true_edges è¿›è¡Œæ¯”è¾ƒ
                            # pos_weight=5.0 æ˜¯ä¸ºäº†è§£å†³è¾¹ç¼˜åƒç´ è¿‡å°‘çš„ä¸å¹³è¡¡é—®é¢˜
                            l_edge = F.binary_cross_entropy_with_logits(
                                edge_pred.float(), true_edges.float(), pos_weight=torch.tensor([5.0], device=device)
                            )
                            
                            # 3. æ€» Loss
                            loss = l_seg + (lambda_edge * l_edge)

                    else:
                        # === [æ¨¡å¼ C] å•è¾“å‡ºæ¨¡å¼ (Seg only) ===
                        masks_pred = output
                        loss = calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma)
                        
                        # ğŸ”¥ éšå¼è¾¹ç¼˜ç›‘ç£ (Gradient-based Edge Loss)
                        # å¦‚æœæ²¡æœ‰è¾…åŠ©å¤´ï¼Œå°±å¼ºè¿«ä¸»åˆ†å‰²å›¾çš„æ¢¯åº¦è¦é”åˆ©
                        if lambda_edge > 0:
                               # âœ… åŠ ä¸ª float() ä¿å¹³å®‰
                            loss_e = edge_criterion(masks_pred.float(), true_masks.float()) 
                            loss += lambda_edge * loss_e
                     # ğŸ”¥ [ä¿®æ”¹ç‚¹ 1] Loss å½’ä¸€åŒ–
                     # å¦‚æœæˆ‘ä»¬è¦ç´¯è®¡ 2 æ­¥ï¼Œé‚£ä¹ˆæ¯æ­¥çš„ Loss åº”è¯¥é™¤ä»¥ 2
                    loss = loss / accumulation_steps
                # å¼‚å¸¸æ£€æµ‹
                if torch.isnan(loss) or torch.isinf(loss):
                    logging.error(f'Loss NaN/Inf detected: {loss.item()}. Skipping batch.')
                    optimizer.zero_grad()
                    continue
                # åå‘ä¼ æ’­
                
                grad_scaler.scale(loss).backward()
                # ğŸ”¥ [ä¿®æ”¹] åªæœ‰è¾¾åˆ°ç´¯è®¡æ­¥æ•°ï¼Œæˆ– epoch ç»“æŸæ—¶æ‰æ›´æ–°
                if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):
                    grad_scaler.unscale_(optimizer)
                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)
                    epoch_grad_norms.append(grad_norm.item())

                    grad_scaler.step(optimizer)
                    grad_scaler.update()
                    
                    # æ›´æ–°å®Œåæ‰æ¸…é›¶
                    optimizer.zero_grad(set_to_none=True)

                    # WandB å®æ—¶æ—¥å¿— (è¿˜åŸ loss æ•°å€¼ç”¨äºæ˜¾ç¤º)
                    experiment.log({
                        'train/loss_batch': loss.item() * accumulation_steps, 
                        'train/grad_norm': grad_norm.item(), 
                        'global_step': global_step
                    })
                    pbar.set_postfix(**{'loss': loss.item() * accumulation_steps, 'grad': grad_norm.item()})
                    global_step += 1

                pbar.update(images.shape[0])
                batch_count += 1
                # ç´¯åŠ  Loss ç”¨äºæ˜¾ç¤º Epoch å¹³å‡å€¼ (è¿˜åŸæ•°å€¼)
                epoch_loss += loss.item() * accumulation_steps

        # ====== éªŒè¯ä¸è¯„ä¼° ======
        avg_epoch_loss = epoch_loss / max(batch_count, 1)
        avg_grad_norm = sum(epoch_grad_norms) / len(epoch_grad_norms) if epoch_grad_norms else 0.0
        # ğŸ”´ [ä¿®æ”¹ 1] ä¼ å…¥ criterion
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å®šä¹‰å¥½çš„ criterion è®¡ç®— loss
        val_metrics = evaluate(model, val_loader, device, amp, criterion=criterion)
        
        
        # 2. ğŸ”¥ [å…³é”®ä¿®æ”¹] ç¦ç”¨é˜ˆå€¼æ‰«æï¼Œç›´æ¥å¤ç”¨ 0.5 é˜ˆå€¼çš„ç»“æœ
        # logging.info('Starting threshold scanning...')
        # threshold_res = threshold_scan_evaluate(...) # <--- æ³¨é‡Šæ‰è¿™ä¸€è¡Œ
        
        # ğŸ”¥ æ‰‹åŠ¨æ„é€ ç»“æœå­—å…¸ï¼Œä¿æŒå˜é‡åå…¼å®¹ï¼Œé˜²æ­¢åé¢æŠ¥é”™
        threshold_res = {
            'best_dice': val_metrics['dice'],      # ç›´æ¥ç”¨ 0.5 çš„ Dice
            'best_f1': val_metrics['f1'],          # ç›´æ¥ç”¨ 0.5 çš„ F1
            'best_threshold_dice': 0.5,            # å›ºå®šæ˜¾ç¤º 0.5
            'best_threshold_f1': 0.5               # å›ºå®šæ˜¾ç¤º 0.5
        }
        
        logging.info('â© Skipping threshold scan. Using fixed threshold 0.5.')

        scheduler.step()
        
        # 4. è¯¦ç»†æ§åˆ¶å°è¾“å‡º
        logging.info(
            f'Epoch {epoch}/{epochs} completed - '
            f'Train Loss: {avg_epoch_loss:.4f}, '
            f'Val Loss: {val_metrics["loss"]:.4f}, '
            f'Avg Grad Norm: {avg_grad_norm:.4f}, '
            f'Val Dice: {val_metrics["dice"]:.4f}, '
            f'Val IoU: {val_metrics["iou"]:.4f}, '
            f'Val F1: {val_metrics["f1"]:.4f}, '
            f'Val Precision: {val_metrics["precision"]:.4f}, '
            f'Val Recall: {val_metrics["recall"]:.4f}, '
            f'Best Dice: {threshold_res["best_dice"]:.4f} (threshold: {threshold_res["best_threshold_dice"]:.2f}), '
            f'Best F1: {threshold_res["best_f1"]:.4f} (threshold: {threshold_res["best_threshold_f1"]:.2f})'
        )

        # 5. ä¸Šä¼  WandB æ—¥å¿—
        current_lr = optimizer.param_groups[0]['lr']
        experiment.log({
            'train/epoch_loss': avg_epoch_loss,
            'val/loss': val_metrics['loss'],       # <--- å…³é”®ï¼æ·»åŠ è¿™ä¸€è¡Œï¼
            'train/avg_grad_norm': avg_grad_norm,
            'val/dice': val_metrics['dice'],
            'val/iou': val_metrics['iou'],
            'val/f1': val_metrics['f1'],
            'val/precision': val_metrics['precision'],
            'val/recall': val_metrics['recall'],
            'val/best_dice': threshold_res['best_dice'],
            'val/best_f1': threshold_res['best_f1'],
            'epoch': epoch,                        # ğŸ”¥ æ–°å¢: å½“å‰è½®æ¬¡
            'train/learning_rate': current_lr      # ğŸ”¥ æ–°å¢: å½“å‰å­¦ä¹ ç‡æ›²çº¿
        })

        

        # ====== ä¿å­˜ Checkpoint ======
        if save_checkpoint:
            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'grad_scaler_state_dict': grad_scaler.state_dict(),
                'loss': avg_epoch_loss,
                'val_dice': float(val_metrics['dice']),
                'val_best_f1': float(threshold_res['best_f1']),
                # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] æ–°å¢è¿™ä¸¤è¡Œ
                'wandb_id': experiment.id,  # ä¿å­˜èº«ä»½è¯å·
                'global_step': global_step, # ä¿å­˜å½“å‰æ­¥æ•°
                # ... ä¿ç•™ä½ çš„å…¶ä»–é”®å€¼
            }
            
            # Latest
            torch.save(checkpoint, str(dir_checkpoint / 'checkpoint_latest.pth'))
            # 2. ğŸ”¥ [ä¿®æ”¹ç‚¹ 2] 30è½®ä»¥åï¼Œæ¯ä¸€è½®éƒ½é¢å¤–ä¿å­˜ä¸€ä¸ªæ–‡ä»¶
            if epoch > 30:
                # æ–‡ä»¶åä¾‹å¦‚: checkpoint_epoch_31.pth, checkpoint_epoch_32.pth ...
                epoch_path = str(dir_checkpoint / f'checkpoint_epoch_{epoch}.pth')
                torch.save(checkpoint, epoch_path)
                logging.info(f'ğŸ’¾ [å¤‡ä»½] å·²ä¿å­˜ç¬¬ {epoch} è½®æƒé‡: {epoch_path}')
            # Best
            best_path = str(dir_checkpoint / 'checkpoint_best.pth')
            current_dice = val_metrics['dice']
            save_best = False
            
            if not Path(best_path).exists():
                save_best = True
                logging.info(f'   ğŸŒŸ é¦–æ¬¡åˆ›å»ºæœ€ä½³æ¨¡å‹ (Dice: {current_dice:.4f})')
            else:
                try:
                    prev_best = torch.load(best_path, map_location='cpu', weights_only=False).get('val_dice', 0.0)
                    if current_dice > prev_best:
                        save_best = True
                        logging.info(f'   ğŸ† åˆ·æ–°æœ€ä½³è®°å½•! ({prev_best:.4f} -> {current_dice:.4f})')
                    else:
                        # ğŸ”¥ğŸ”¥ğŸ”¥ è¿™ä¸€è¡Œæ˜¯ä½ è¦æ±‚çš„å…³é”®æ—¥å¿— ğŸ”¥ğŸ”¥ğŸ”¥
                        logging.info(f'   (å½“å‰ Dice {current_dice:.4f} æœªè¶…è¿‡æœ€ä½³ {prev_best:.4f})')
                except:
                    save_best = True
            # ğŸ”¥ å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼šä¿å­˜æƒé‡ + ä¸Šä¼ é«˜æ¸…å›¾ç‰‡
            if save_best:
                torch.save(checkpoint, best_path)
                try:
                    # è°ƒç”¨æˆ‘ä»¬å†™å¥½çš„å¯è§†åŒ–å‡½æ•°
                    log_best_visuals(model, val_loader, device, num_samples=5)
                except Exception as e:
                    logging.warning(f"âš ï¸ å¯è§†åŒ–ä¸Šä¼ å¤±è´¥: {e}")

            
    wandb.finish()

# è®¡ç®— Loss è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
def calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma):
    """
    ğŸ”¥ [æœ€ç»ˆå®Œæ•´ç‰ˆ] 
    1. å¼ºåˆ¶ FP32 è®¡ç®— (V100 ä¿å‘½)
    2. ä¿ç•™äº†åŸæœ¬çš„ try-except å…¼å®¹é€»è¾‘
    """
    # -----------------------------------------------------------
    # 1. å…¨å±€å¼ºåˆ¶è½¬æ¢ï¼šè¿›é—¨å…ˆå®‰æ£€ï¼Œç»Ÿç»Ÿå˜ float32
    # -----------------------------------------------------------
    masks_pred = masks_pred.float()
    true_masks = true_masks.float()

    # -----------------------------------------------------------
    # 2. åˆ†æƒ…å†µè®¡ç®— (æ³¨æ„ï¼šä¸‹é¢éƒ½ä¸éœ€è¦å†å†™ .float() äº†)
    # -----------------------------------------------------------
    if loss_combination == 'bce':
        criterion = nn.BCEWithLogitsLoss()
        return criterion(masks_pred.squeeze(1), true_masks)
    
    elif loss_combination == 'focal':
        criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        return criterion(masks_pred.squeeze(1), true_masks)
    
    elif loss_combination == 'dice':
        # ç¡®ä¿ sigmoid ä¹Ÿåœ¨ float32 ä¸‹è¿›è¡Œ
        return dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks, multiclass=False)
    
    else:
        # -----------------------------------------------------------
        # 3. ç»„åˆ Loss (ä¿ç•™ä½ åŸæ¥çš„ try-except é€»è¾‘)
        # -----------------------------------------------------------
        try:
            # å°è¯•è°ƒç”¨å°è£…å¥½çš„ç±»
            criterion = CombinedLoss(loss_combination.split('+'), [1.0, 1.0], focal_alpha, focal_gamma)
            return criterion(masks_pred.squeeze(1), true_masks)
        except:
            # ğŸ”¥ Fallback: æ‰‹åŠ¨ç›¸åŠ 
            # è¿™é‡Œçš„ input å·²ç»æ˜¯ float32 äº†ï¼Œè®¡ç®—éå¸¸å®‰å…¨
            bce = nn.BCEWithLogitsLoss()(masks_pred.squeeze(1), true_masks)
            
            # Dice éœ€è¦ sigmoid åçš„æ¦‚ç‡
            dice = dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks, multiclass=False)
            
            return bce + dice

def get_args():
    parser = argparse.ArgumentParser(description='Train the Unified UNet')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--epochs', '-e', type=int, default=20)
    parser.add_argument('--batch-size', '-b', type=int, default=8)
    parser.add_argument('--learning-rate', '-l', type=float, default=1e-4)
    parser.add_argument('--load', '-f', type=str, default=False)
    parser.add_argument('--scale', '-s', type=float, default=1.0)
    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0)
    parser.add_argument('--amp', action='store_true', default=False)
    parser.add_argument('--bilinear', action='store_true', default=False)
    parser.add_argument('--classes', '-c', type=int, default=1)
    parser.add_argument('--start-epoch', type=int, default=1)
    
    # æ¶æ„å‚æ•°
    parser.add_argument('--encoder', type=str, default='resnet', choices=['resnet', 'cnextv2', 'standard'])
    parser.add_argument('--decoder', type=str, default='phd', choices=['phd', 'standard'])
    parser.add_argument('--cnext-type', type=str, default='convnextv2_tiny')
    
    # SOTA æ¨¡å—å¼€å…³
    parser.add_argument('--use-dcn', action='store_true', default=False, help='Enable standard DCNv3')
    parser.add_argument('--use-dubm', action='store_true', default=False, help='Enable D-UBM (SOTA)')
    parser.add_argument('--use-strg', action='store_true', default=False, help='Enable STRG Skip Enhancement')
    parser.add_argument('--use-dual-stream', action='store_true', default=False, help='Enable Dual-Stream Boundary Architecture')
    parser.add_argument('--use-wavelet-denoise', action='store_true', default=False, help='Enable Wavelet Denoising on Skip Connections')
    parser.add_argument('--use-dsis', action='store_true', default=False, help='Enable Dual-Stream Interactive Skip Module')
    parser.add_argument('--use-unet3p', action='store_true', default=False, help='Enable UNet 3+ Full-Scale Skip Connections')
    # [æ–°å¢] MDBES-Net ç›¸å…³å‚æ•°
    parser.add_argument('--use_decouple', action='store_true', default=False, help='Enable MDBES-Net explicit decoupling supervision')
    parser.add_argument('--lambda_edge', type=float, default=1.0, help='Weight for the Edge loss (default: 2.0)')
    parser.add_argument('--lambda_body', type=float, default=1.0, help='Weight for the Body loss (default: 1.0)')
    
    # å…¶ä»–å¢å¼ºæ¨¡å— (ä¿æŒåŸæœ‰å¼€å…³å®šä¹‰ï¼Œä½†ç§»é™¤äº†æ—§ç‰ˆ Edge Logic çš„æ‰§è¡Œ)
    parser.add_argument('--use-wgn-enhancement', action='store_true', default=False)
    parser.add_argument('--use-cafm', action='store_true', default=False)
    parser.add_argument('--use-edge-loss', action='store_true', default=False, help='Legacy WGN Edge Loss (Deprecated logic removed)')
    parser.add_argument('--use-fme', action='store_true', default=False, 
                        help='Enable Frequency-Mamba Enhancement (FME) module')
    # WGN å‚æ•°
    parser.add_argument('--wgn-base-order', type=int, default=3)
    parser.add_argument('--wgn-orders', type=str, default=None)

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument('--optimizer', type=str, default='adamw', choices=['adamw', 'rmsprop'])
    parser.add_argument('--loss-combination', type=str, default='focal+dice')
    parser.add_argument('--loss-weights', type=str, default='1.0,1.0')
    parser.add_argument('--focal-alpha', type=float, default=0.25)
    parser.add_argument('--focal-gamma', type=float, default=2.0)
    parser.add_argument('--weight-decay', type=float, default=1e-8)
    parser.add_argument('--momentum', type=float, default=0.999)
    parser.add_argument('--gradient-clipping', type=float, default=1.0)
    parser.add_argument('--backbone-lr-scale', type=float, default=0.1)
    # ğŸ”¥ [æ–°å¢] æ¢¯åº¦ç´¯è®¡æ­¥æ•°ï¼Œé»˜è®¤1è¡¨ç¤ºä¸ç´¯è®¡
    parser.add_argument('--accumulation-steps', type=int, default=1, help='Gradient accumulation steps')

    return parser.parse_args()

if __name__ == '__main__':
    # ğŸ”¥ğŸ”¥ğŸ”¥ åœ¨è¿™é‡Œè°ƒç”¨ï¼Œæ•°å­—éšä¾¿å¡«ï¼ˆæ¯”å¦‚ 42, 3407, 2023ï¼‰
    setup_seed(42)
    
    args = get_args()
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # WGN Orders å¤„ç†
    wgn_orders = None
    if args.use_wgn_enhancement:
        if args.wgn_orders:
            orders_list = [int(x) for x in args.wgn_orders.split(',')]
            wgn_orders = {'layer1': (orders_list[0], orders_list[1]), 'layer2': (orders_list[2], orders_list[3]), 'layer3': (orders_list[4], orders_list[5])}
        else:
            base = args.wgn_base_order
            wgn_orders = {'layer1': (base, base-1), 'layer2': (base+1, base), 'layer3': (base+2, base+1)}

    # å®ä¾‹åŒ–æ¨¡å‹
    logging.info(f"ğŸš€ Building Model: Encoder={args.encoder}, Decoder={args.decoder}")
    model = UNet(
        n_channels=3,
        n_classes=args.classes,
        bilinear=args.bilinear,
        encoder_name=args.encoder,
        decoder_name=args.decoder,
        cnext_type=args.cnext_type,
        use_wgn_enhancement=args.use_wgn_enhancement,
        use_cafm=args.use_cafm,
        # æ³¨æ„: å³ä½¿ä¼ å…¥ use_edge_loss=True, train loop ä¸­å·²ç§»é™¤äº†å¤„ç†å®ƒçš„é€»è¾‘
        use_edge_loss=args.use_edge_loss, 
        wgn_orders=wgn_orders,
        use_dcn_in_phd=args.use_dcn,
        use_dubm=args.use_dubm,
        use_strg=args.use_strg,
        use_dual_stream=args.use_dual_stream, # ğŸ”¥ æ–°å¢åŒæµ
        use_dsis=args.use_dsis, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_unet3p=args.use_unet3p, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_wavelet_denoise=args.use_wavelet_denoise  # ğŸ‘ˆ ä¼ å…¥è¿™ä¸ªå‚æ•°
          # ğŸ”¥ ä¼ å…¥ MDBES-Net è§£è€¦å‚æ•°
    )
    
    model = model.to(memory_format=torch.channels_last)
    model.to(device=device)
    # =================================================================================
    # ğŸ”¥ [æ–°å¢ä»£ç ] è®¡ç®—å¹¶æ‰“å°æ¨¡å‹å‚æ•°é‡
    # =================================================================================
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    logging.info(f"""
    ğŸ“Š Model Summary:
        Total Parameters:     {total_params / 1e6:.2f} M
        Trainable Parameters: {trainable_params / 1e6:.2f} M
        Frozen Parameters:    {(total_params - trainable_params) / 1e6:.2f} M
    """)
    # =================================================================================
    # åŠ è½½æƒé‡
    checkpoint_to_load = None
    if args.load:
        try:
            ckpt = torch.load(args.load, map_location=device, weights_only=False)
            if 'model_state_dict' in ckpt:
                model.load_state_dict(ckpt['model_state_dict'])
                checkpoint_to_load = ckpt
                # ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] è‡ªåŠ¨è¯»å–æ–­ç‚¹è½®æ•°ï¼Œå®ç°æ— ç¼ç»­è®­ ğŸ”¥ğŸ”¥ğŸ”¥
                if 'epoch' in ckpt:
                    args.start_epoch = ckpt['epoch'] + 1
                    logging.info(f"ğŸ”„ è‡ªåŠ¨æ£€æµ‹åˆ°æ–­ç‚¹ (Epoch {ckpt['epoch']})ï¼Œå°†ä» Epoch {args.start_epoch} ç»§ç»­è®­ç»ƒï¼")
            else:
                model.load_state_dict(ckpt)
            logging.info(f'Model loaded from {args.load}')
        except Exception as e:
            logging.error(f"Load failed: {e}")
            sys.exit(1)

    try:
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            device=device,
            img_scale=args.scale,
            val_percent=args.val / 100,
            amp=args.amp,
            start_epoch=args.start_epoch,
            checkpoint_to_load=checkpoint_to_load,
            backbone_lr_scale=args.backbone_lr_scale,
            weight_decay=args.weight_decay,
            momentum=args.momentum,
            gradient_clipping=args.gradient_clipping,
            loss_combination=args.loss_combination,
            loss_weights=args.loss_weights,
            focal_alpha=args.focal_alpha,
            focal_gamma=args.focal_gamma,
            optimizer_type=args.optimizer,
            # ğŸ”¥ [æ–°å¢] æŠŠæƒé‡ä¼ ç»™è®­ç»ƒå‡½æ•°
            lambda_edge=args.lambda_edge,
            lambda_body=args.lambda_body,
            accumulation_steps=args.accumulation_steps # <--- ğŸ”¥ åŠ ä¸Šè¿™ä¸€è¡Œï¼
        )
    except KeyboardInterrupt:
        torch.save(model.state_dict(), 'INTERRUPTED.pth')
        logging.info('Saved interrupt checkpoint')