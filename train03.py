import argparse
import logging
import os
import random
import sys
import numpy as np  # <--- æ·»åŠ è¿™ä¸€è¡Œ
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from torch import optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import wandb
import cv2
from evaluate import evaluate, threshold_scan_evaluate
from utils.data_loading import BasicDataset
from utils.dice_score import dice_loss
import csv
from timm.scheduler import CosineLRScheduler  # ğŸ”¥ [æ–°å¢ 1] æ·»åŠ è¿™ä¸€è¡Œ
from utils.losses import FocalLoss, CombinedLoss, DiceLossOnly, EdgeLoss, compute_prototype_ortho_loss
from utils.utils import log_grad_stats

# ğŸ”¥ ç¡®ä¿å¼•ç”¨çš„æ˜¯åˆšæ‰ä¿®æ”¹è¿‡çš„æ–‡ä»¶
from unet.unet_universal3 import UniversalUNet as UNet

import random
import csv
import os

class MetricLogger:
    def __init__(self, save_path):
        self.save_path = save_path
        # åˆå§‹åŒ– CSV æ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™å†™å…¥è¡¨å¤´
        if not os.path.exists(self.save_path):
            with open(self.save_path, mode='w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Epoch', 'Train_Loss', 'Val_Loss', 'Dice', 'Precision', 'Recall', 'F1', 'IoU', 'LR'])

    def log(self, epoch, train_loss, val_metrics, lr):
        with open(self.save_path, mode='a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                epoch,
                f"{train_loss:.4f}",
                f"{val_metrics['loss']:.4f}",
                f"{val_metrics['dice']:.4f}",
                f"{val_metrics['precision']:.4f}",
                f"{val_metrics['recall']:.4f}",
                f"{val_metrics['f1']:.4f}",
                f"{val_metrics['iou']:.4f}",
                f"{lr:.8f}"
            ])
def setup_seed(seed):
    import random
    import numpy as np
    import os  # ğŸ‘ˆ ç¡®ä¿å¯¼å…¥ os
    os.environ['PYTHONHASHSEED'] = str(seed) # ğŸ‘ˆ æ–°å¢ï¼šæ§åˆ¶å“ˆå¸Œç®—æ³•éšæœºæ€§
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)       # ğŸ‘ˆ ä¿®æ­£ï¼šå•å¡ä½¿ç”¨è¿™ä¸ª
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è¯ç®—æ³•ç»“æœç¡®å®š
    torch.backends.cudnn.benchmark = False   # å»ºè®®æ³¨é‡Šæ‰ã€‚è®¾ä¸ºFalseä¼šå˜æ…¢ï¼Œé€šå¸¸ä¸å€¼å¾—
# åœ¨ setup_seed ä¸‹æ–¹æ·»åŠ è¿™ä¸ªå‡½æ•°
def worker_init_fn(worker_id):
    import random
    import numpy as np
    # è·å– PyTorch ä¼ ä¸‹æ¥çš„ç§å­
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)
def log_best_visuals(model, val_loader, device, num_samples=5):
    """
    å°† åŸå›¾ã€é¢„æµ‹æ©ç ã€çœŸå€¼æ©ç  å¹¶æ’å±•ç¤ºåœ¨ WandB è¡¨æ ¼ä¸­ã€‚
    è‡ªåŠ¨å¤„ç†åæ ‡å‡†åŒ–ï¼Œé˜²æ­¢åŸå›¾å˜é»‘ã€‚
    """
    model.eval()
    
    # 1. å®šä¹‰ ImageNet çš„å‡å€¼å’Œæ–¹å·® (ç”¨äºåæ ‡å‡†åŒ–)
    # å¦‚æœä½ åœ¨ dataset é‡Œç”¨äº†å…¶ä»–æ•°å€¼ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)

    # 2. åˆ›å»º WandB è¡¨æ ¼ï¼Œå®šä¹‰ä¸‰åˆ—
    columns = ["Input Image (åŸå›¾)", "Prediction (é¢„æµ‹)", "Ground Truth (çœŸå€¼)"]
    test_table = wandb.Table(columns=columns)

    print(f"âœ¨ æ­£åœ¨ç”Ÿæˆ {num_samples} ç»„å¯è§†åŒ–æ ·æœ¬...")

    with torch.no_grad():
        for i, batch in enumerate(val_loader):
            if len(test_table.data) >= num_samples: break
            
            imgs = batch['image'].to(device)
            masks = batch['mask'].to(device)
            
            # æ¨ç†
            outputs = model(imgs)
            
            # å…¼å®¹å¤šè¾“å‡ºçš„æƒ…å†µï¼Œåªå–ç¬¬ä¸€ä¸ªä¸»è¾“å‡ºè¿›è¡Œå¯è§†åŒ–
            if isinstance(outputs, (list, tuple)):
                outputs = outputs[0]
                
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float()
            
            for j in range(imgs.shape[0]):
                if len(test_table.data) >= num_samples: break
                
                # --- A. ä¿®å¤åŸå›¾ (é˜²æ­¢å…¨é»‘çš„æ ¸å¿ƒæ­¥éª¤) ---
                # 1. åæ ‡å‡†åŒ–: image = image * std + mean
                img_tensor = imgs[j] * std + mean
                # 2. é™åˆ¶æ•°å€¼èŒƒå›´åœ¨ 0-1 ä¹‹é—´ (æ¶ˆé™¤è®¡ç®—è¯¯å·®å¯¼è‡´çš„è¶Šç•Œ)
                img_tensor = torch.clamp(img_tensor, 0, 1)
                # 3. è½¬æ¢ç»´åº¦ [C,H,W] -> [H,W,C] å¹¶è½¬ä¸º numpy
                img_np = img_tensor.cpu().numpy().transpose(1, 2, 0)
                # 4. ä¹˜ä»¥ 255 å¹¶è½¬ä¸ºæ•´æ•° (å˜æˆæ ‡å‡†çš„ RGB å›¾ç‰‡)
                img_np = (img_np * 255).astype(np.uint8)

                # --- B. å¤„ç†æ©ç  (å˜æˆé»‘ç™½å›¾) ---
                # 1. å–å‡ºå•å¼ æ©ç 
                pred_mask = preds[j].squeeze().cpu().numpy()
                true_mask = masks[j].squeeze().cpu().numpy()
                
                # 2. ä¹˜ä»¥ 255ï¼(éå¸¸é‡è¦ï¼š0å˜æˆé»‘ï¼Œ1å˜æˆç™½)
                pred_mask = (pred_mask * 255).astype(np.uint8)
                true_mask = (true_mask * 255).astype(np.uint8)
                
                # --- C. åˆ›å»º WandB å›¾ç‰‡å¯¹è±¡ ---
                input_img_log = wandb.Image(img_np)
                pred_img_log = wandb.Image(pred_mask)
                true_img_log = wandb.Image(true_mask)
                
                # --- D. æ·»åŠ åˆ°è¡¨æ ¼çš„ä¸€è¡Œä¸­ ---
                test_table.add_data(input_img_log, pred_img_log, true_img_log)

    # 3. ä¸Šä¼ è¡¨æ ¼
    wandb.log({"Visual Results Table": test_table}, commit=False)
    print("âœ… å¯è§†åŒ–è¡¨æ ¼å·²ä¸Šä¼ ï¼")
    
    model.train() # æ¢å¤è®­ç»ƒæ¨¡å¼

# ================= é…ç½®è·¯å¾„ =================
dir_img = Path('./data/train/imgs/')
dir_mask = Path('./data/train/masks/')
val_dir_img = Path('./data/val/imgs/')
val_dir_mask = Path('./data/val/masks/')
dir_checkpoint = Path('./data/checkpoints/')

# ================= è¾…åŠ©å‡½æ•° =================

# ğŸ”¥ [æ–°å¢] å®æ—¶ç”Ÿæˆ Body å’Œ Edge çš„çœŸå€¼ (GPUç‰ˆ)
# åˆ©ç”¨ MaxPool å®ç°å½¢æ€å­¦æ“ä½œï¼Œé€Ÿåº¦æå¿«ã€‚
def generate_body_edge_targets(masks, edge_width=5, device='cuda'):
    if masks.ndim == 3:
        masks = masks.unsqueeze(1)
    
    masks_float = masks.float()
    padding = edge_width // 2
    
    # è†¨èƒ€ (Dilation)
    dilated = F.max_pool2d(masks_float, kernel_size=edge_width, stride=1, padding=padding)
    # è…èš€ (Erosion)
    eroded = -F.max_pool2d(-masks_float, kernel_size=edge_width, stride=1, padding=padding)
    
    # Edge = è†¨èƒ€ - è…èš€
    edge = dilated - eroded
    # Body = è…èš€
    body = eroded
    
    # äºŒå€¼åŒ–ä¿æŠ¤
    body = (body > 0.5).float()
    edge = (edge > 0.5).float()
    
    return body.to(device), edge.to(device)

def generate_edge_tensor(mask, edge_width=3):
    """
    [æ—§ç‰ˆ] å½¢æ€å­¦è¾¹ç¼˜ç”Ÿæˆ (OpenCV)
    ä¿ç•™æ­¤å‡½æ•°ä»¥å…¼å®¹æ—§çš„ EdgeLoss è°ƒç”¨ï¼ˆå¦‚æœä¸ä½¿ç”¨ Decoupleï¼‰
    """
    # 1. è®°å½•åŸå§‹æ‰€åœ¨çš„è®¾å¤‡ (CPU or CUDA)
    target_device = mask.device
    
    # 2. è½¬æ¢ä¸º Numpy (CPU) è¿›è¡Œ OpenCV å¤„ç†
    if isinstance(mask, torch.Tensor):
        mask_np = mask.detach().cpu().numpy()
    else:
        mask_np = mask
        
    # å¦‚æœç»´åº¦æ˜¯ [B, 1, H, W]ï¼Œå‹ç¼©ä¸º [B, H, W]
    if mask_np.ndim == 4:
        mask_np = mask_np.squeeze(1)
        
    B, H, W = mask_np.shape
    edges = []
    
    # å®šä¹‰ç»“æ„å…ƒç´  (å†³å®šè¾¹ç¼˜å®½åº¦)
    # cv2.MORPH_RECT è¡¨ç¤ºçŸ©å½¢ç»“æ„
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (edge_width, edge_width))
    
    for i in range(B):
        # ç¡®ä¿æ˜¯ uint8 ç±»å‹
        m = mask_np[i].astype(np.uint8)
        
        # è†¨èƒ€ - è…èš€
        dilated = cv2.dilate(m, kernel, iterations=1)
        eroded = cv2.erode(m, kernel, iterations=1)
        
        # ç›¸å‡å¾—åˆ°è¾¹ç¼˜
        edge = dilated - eroded
        
        # äºŒå€¼åŒ–ä¿æŠ¤ (å¤§äº0çš„éƒ½ç®—è¾¹ç¼˜)
        edge[edge > 0] = 1
        edges.append(edge)
    
    # 3. å †å å¹¶è½¬å› Tensor
    edges = np.stack(edges, axis=0) # [B, H, W]
    edges_tensor = torch.from_numpy(edges).float().unsqueeze(1) # [B, 1, H, W]
    
    # 4. ç§»å›åŸæ¥çš„è®¾å¤‡ (GPU)
    return edges_tensor.to(target_device)

def train_model(
        model,
        device,
        epochs: int = 20,
        batch_size: int = 32,
        learning_rate: float = 1e-5,
        val_percent: float = 0.1,
        save_checkpoint: bool = True,
        img_scale: float = 1.0,
        amp: bool = True,
        weight_decay: float = 1e-8,
        momentum: float = 0.999,
        gradient_clipping: float = 1.0,
        start_epoch: int = 1,
        checkpoint_to_load: dict = None,
        loss_combination: str = 'focal+dice',
        loss_weights: str = '1.0,1.0',
        focal_alpha: float = 0.25,
        focal_gamma: float = 2.0,
        optimizer_type: str = 'adamw',
        backbone_lr_scale: float = 0.1,
        lambda_edge: float = 20.0,
        lambda_body: float = 1.0,
        accumulation_steps: int = 1,  # <--- ğŸ”¥ å¿…é¡»åŠ ä¸Šè¿™ä¸€è¡Œï¼
        use_decouple: bool = False # ğŸ”¥ [æ–°å¢] ä¼ å…¥æ˜¯å¦å¼€å¯è§£è€¦
        
):
    # 1. æ•°æ®å‡†å¤‡
    train_dataset = BasicDataset(dir_img, dir_mask, img_scale, mask_suffix='', augment=True)
    val_dataset = BasicDataset(val_dir_img, val_dir_mask, img_scale, mask_suffix='', augment=False)
    n_train = len(train_dataset)
    n_val = len(val_dataset)

    # 2. DataLoader
    num_workers = min(4, os.cpu_count()) if os.name == 'nt' else min(8, os.cpu_count())
    # ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] å®šä¹‰ä¸€ä¸ªéšæœºæ•°ç”Ÿæˆå™¨ï¼Œå¹¶è®¾å®šç§å­
    g = torch.Generator()
    g.manual_seed(42)  # è¿™é‡Œå¡«ä½ æƒ³è¦çš„ç§å­ï¼Œå»ºè®®å’Œå…¨å±€ç§å­ä¿æŒä¸€è‡´
    loader_args = dict(batch_size=batch_size, num_workers=num_workers, pin_memory=True)
    train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True, worker_init_fn=worker_init_fn, generator=g, **loader_args)
    val_loader = DataLoader(val_dataset, shuffle=False, drop_last=True, worker_init_fn=worker_init_fn, generator=g, **loader_args)

    # 3. WandB åˆå§‹åŒ– (ä¿ç•™åŸæœ‰é…ç½®)
    # ğŸ”¥ [æ–°å¢] å¿…é¡»å…ˆå®šä¹‰ run_idï¼Œå¦åˆ™åé¢ä¼šæŠ¥é”™
    run_id = None
    if checkpoint_to_load is not None and 'wandb_id' in checkpoint_to_load:
        run_id = checkpoint_to_load['wandb_id']
        logging.info(f"ğŸ”— æ£€æµ‹åˆ° WandB ID: {run_id}ï¼Œæ­£åœ¨æ¢å¤è¿æ¥...")
    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must', id=run_id)
    # ğŸ”¥ [æ–°å¢] åˆå§‹åŒ–æœ¬åœ° CSV Logger
# å»ºè®®ä¿å­˜åœ¨ checkpoints ç›®å½•ä¸‹ï¼Œæˆ–è€…ä½ æŒ‡å®šçš„ç›®å½•
    csv_log_path = dir_checkpoint / "training_metrics.csv"
    csv_logger = MetricLogger(csv_log_path)
    logging.info(f"ğŸ“Š æœ¬åœ°æŒ‡æ ‡è®°å½•å™¨å·²å°±ç»ª: {csv_log_path}")
    experiment.config.update(dict(
        epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,
        img_scale=img_scale, amp=amp, backbone_lr=backbone_lr_scale
    ), allow_val_change=True)
    
    logging.info(f'''Starting training:
        Epochs:          {epochs}
        Batch size:      {batch_size}
        Learning rate:   {learning_rate}
        Training size:   {n_train}
        Validation size: {n_val}
        Checkpoints:     {save_checkpoint}
        Device:          {device.type}
        Images scaling:  {img_scale}
        Mixed Precision: {amp}
        Decoupling:      {use_decouple}
    ''')

    # 4. ä¼˜åŒ–å™¨ä¸å·®åˆ†å­¦ä¹ ç‡
    backbone_params_ids = []
    use_differential_lr = False
    
    # ğŸ”¥ ä¿®æ”¹ 1: åªè¦ä½ è®¾ç½®äº†å€ç‡ < 1.0ï¼Œå°±æ— æ¡ä»¶å¼€å¯ï¼Œä¸è¦å»æ£€æŸ¥ model.encoder_name
    if backbone_lr_scale < 1.0:
        use_differential_lr = True

    if use_differential_lr:
        logging.info(f'âœ¨ å¯ç”¨å·®åˆ†å­¦ä¹ ç‡ç­–ç•¥: Backbone Scale = {backbone_lr_scale}')
        
        
        backbone_names = ['spatial_encoder'] 
        
        # å¯»æ‰¾éª¨å¹²å‚æ•°
        found_backbone_layer = False
        for name, module in model.named_children():
            if name in backbone_names:
                found_backbone_layer = True
                # logging.info(f"   -> æ•è·éª¨å¹²å±‚: {name}") # è°ƒè¯•æ—¶å¯ä»¥è§£å¼€è¿™è¡Œ
                for param in module.parameters():
                    backbone_params_ids.append(id(param))
        
        # ğŸ”¥ ä¿®æ”¹ 2: å®‰å…¨æ£€æŸ¥
        # å¦‚æœæ‰¾äº†ä¸€åœˆæ²¡æ‰¾åˆ°éª¨å¹²å±‚ (åå­—ä¸å¯¹)ï¼Œå°±è‡ªåŠ¨å›é€€åˆ°ç»Ÿä¸€å­¦ä¹ ç‡ï¼Œé˜²æ­¢æŠ¥é”™
        if not found_backbone_layer or len(backbone_params_ids) == 0:
            logging.warning("âš ï¸ è­¦å‘Š: å¯ç”¨äº†å·®åˆ†å­¦ä¹ ç‡ï¼Œä½†æ²¡åœ¨æ¨¡å‹é‡Œæ‰¾åˆ°åä¸º 'enc_model' æˆ– 'encoder' çš„å±‚ï¼")
            logging.warning("   -> å°†è‡ªåŠ¨å›é€€åˆ°ç»Ÿä¸€å­¦ä¹ ç‡ã€‚è¯·æ£€æŸ¥ UNet ä»£ç ä¸­éª¨å¹²ç½‘çš„å˜é‡åã€‚")
            param_groups = model.parameters()
        else:
            # æ­£å¸¸åˆ†ç¦»å‚æ•°
            backbone_params = filter(lambda p: id(p) in backbone_params_ids, model.parameters())
            base_params = filter(lambda p: id(p) not in backbone_params_ids, model.parameters())
            
            param_groups = [
                {'params': base_params, 'lr': learning_rate}, 
                {'params': backbone_params, 'lr': learning_rate * backbone_lr_scale}
            ]
            logging.info(f"   -> æˆåŠŸåˆ†ç¦»å‚æ•°: éª¨å¹²ç½‘å°†ä½¿ç”¨ lr={learning_rate * backbone_lr_scale:.2e}")
            
    else:
        logging.info('ä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡ (æ— å·®åˆ†)')
        param_groups = model.parameters()

    if optimizer_type.lower() == 'adamw':
        optimizer = optim.AdamW(param_groups, lr=learning_rate, weight_decay=weight_decay)
        logging.info('âœ… Using AdamW optimizer')
    else:
        optimizer = optim.RMSprop(param_groups, lr=learning_rate, weight_decay=weight_decay,
                                  momentum=momentum, foreach=True)
        logging.info('âœ… Using RMSprop optimizer')

    # -------------------------------------------------------------------------
    # ğŸ”¥ [æ–°å¢ 3] ä½¿ç”¨ timm çš„ CosineLRScheduler å®ç° Warmup
    # -------------------------------------------------------------------------
    # è‡ªåŠ¨è®¾å®š Warmup è½®æ•° (æ€»è½®æ•°çš„ 10%ï¼Œæœ€å°‘ 5 è½®)
    warmup_epochs = int(epochs * 0.1)
    if warmup_epochs < 5: warmup_epochs = 5
    
    logging.info(f"ğŸ“… å­¦ä¹ ç‡è°ƒåº¦: æ€»è½®æ•° {epochs}, Warmup {warmup_epochs} è½®")

    scheduler = CosineLRScheduler(
        optimizer,
        t_initial=epochs,            # å‘¨æœŸé•¿åº¦ (æ€» Epoch)
        lr_min=1e-6,                 # æœ€å°å­¦ä¹ ç‡ (è®­ç»ƒç»“æŸæ—¶é™åˆ°å¤šå°‘)
        warmup_t=warmup_epochs,      # Warmup æŒç»­å¤šå°‘ä¸ª Epoch
        warmup_lr_init=1e-6,         # Warmup åˆå§‹å­¦ä¹ ç‡ (ä»è¿™ä¸ªå€¼çº¿æ€§å‡åˆ°ç›®æ ‡ lr)
        warmup_prefix=False          # è®¾ä¸º Trueï¼Œè¡¨ç¤º warmup è¿‡ç¨‹åŒ…å«åœ¨æ€»å‘¨æœŸè®¡ç®—é€»è¾‘ä¸­
    )
    
    # ğŸ”¥ åˆå§‹åŒ–ä¸€ä¸‹ï¼Œç¡®ä¿ç¬¬ 1 ä¸ª Epoch å°±å¼€å§‹ä½¿ç”¨ Warmup å­¦ä¹ ç‡
    scheduler.step(0)
    # -------------------------------------------------------------------------
    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)

    # æŸå¤±å‡½æ•°
    if model.n_classes > 1:
        criterion = nn.CrossEntropyLoss()
    else:
        loss_parts = loss_combination.split('+')
        weights = [float(w) for w in loss_weights.split(',')] if ',' in loss_weights else [1.0]*len(loss_parts)
        
        if loss_combination == 'bce': criterion = nn.BCEWithLogitsLoss()
        elif loss_combination == 'focal': criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        elif loss_combination == 'dice': criterion = DiceLossOnly()
        else: criterion = CombinedLoss(loss_parts, weights, focal_alpha, focal_gamma)
        logging.info(f'âœ… Using Loss: {loss_combination}')
    # ğŸ”¥ [æ–°å¢] åˆå§‹åŒ– EdgeLoss (å¿…é¡»æ”¾åœ¨è¿™é‡Œ)
    edge_criterion = EdgeLoss(device=device)
    # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] æ¢å¤ global_step
    if checkpoint_to_load is not None and 'global_step' in checkpoint_to_load:
        global_step = checkpoint_to_load['global_step']
        logging.info(f"ğŸ“‰ ç»§ç»­ä» Global Step {global_step} å¼€å§‹è®°å½•æ—¥å¿—")
    else:
        global_step = 0

    # æ¢å¤ Checkpoint
    if checkpoint_to_load is not None:
        try:
            optimizer.load_state_dict(checkpoint_to_load['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint_to_load['scheduler_state_dict'])
            if 'grad_scaler_state_dict' in checkpoint_to_load and amp:
                grad_scaler.load_state_dict(checkpoint_to_load['grad_scaler_state_dict'])
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ [ä¿®æ”¹è¿™é‡Œ] åŠ ä¸Š .cpu() ğŸ”¥ğŸ”¥ğŸ”¥
            if 'cpu_rng_state' in checkpoint_to_load:
                # 1. æ¢å¤ CPU éšæœºæ•° (å¿…é¡»æ˜¯ CPU Tensor)
                torch.set_rng_state(checkpoint_to_load['cpu_rng_state'].cpu())
                
                # 2. æ¢å¤ CUDA éšæœºæ•° (é€šå¸¸ set_rng_state ä¹Ÿåå¥½ CPU tensor ä½œä¸ºè¾“å…¥æ¥è®¾ç½® GPU çŠ¶æ€)
                try:
                    if 'cuda_rng_state' in checkpoint_to_load:
                        torch.cuda.set_rng_state(checkpoint_to_load['cuda_rng_state'].cpu())
                except Exception as e:
                    logging.warning(f"âš ï¸ æ— æ³•æ¢å¤ CUDA éšæœºçŠ¶æ€ (å¯èƒ½æ˜¾å¡æ•°é‡ä¸ä¸€è‡´): {e}")

                # 3. æ¢å¤ Numpy å’Œ Python éšæœºæ•° (è¿™äº›ä¸å— map_location å½±å“)
                if 'numpy_rng_state' in checkpoint_to_load:
                    np.random.set_state(checkpoint_to_load['numpy_rng_state'])
                if 'py_rng_state' in checkpoint_to_load:
                    random.setstate(checkpoint_to_load['py_rng_state'])
                
                logging.info("ğŸ² éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€å·²å®Œç¾æ¢å¤ï¼")

            logging.info('âœ… è®­ç»ƒçŠ¶æ€å®Œå…¨æ¢å¤')
        except Exception as e:
            logging.warning(f'âš ï¸ æ¢å¤çŠ¶æ€å¤±è´¥: {e}')
    # ============================================================
    # 5. è®­ç»ƒå¾ªç¯
    # ============================================================
    for epoch in range(start_epoch, epochs + 1):
        model.train()
        epoch_loss = 0
        epoch_grad_norms = []
        batch_count = 0
        
        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:
            for i, batch in enumerate(train_loader):
                images, true_masks = batch['image'], batch['mask']
                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)
                true_masks = true_masks.to(device=device, dtype=torch.long)

                with torch.cuda.amp.autocast(enabled=amp):
                    output = model(images)
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ [å…³é”®ä¿®å¤] å®šä¹‰æ•°å€¼æˆªæ–­å‡½æ•° ğŸ”¥ğŸ”¥ğŸ”¥
                    # é˜²æ­¢æ¨¡å‹è¾“å‡ºè¿‡å¤§å¯¼è‡´ BCE Loss è®¡ç®—å‡º NaN
                    def clamp_logits(x):
                        return torch.clamp(x, min=-50, max=50)

                    loss = 0.0
                    
                    # ==========================================================
                    # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] ç»Ÿä¸€çš„è¾“å‡ºè§£æé€»è¾‘ (å…¼å®¹ DS å’Œ Decouple)
                    # ==========================================================
                    if isinstance(output, list):
                        # 1. ä¸»åˆ†å‰² Loss (åˆ—è¡¨ç¬¬ä¸€ä¸ªæ°¸è¿œæ˜¯ Final Output)
                        pred_final = clamp_logits(output[0])
                        l_main = calc_loss(pred_final, true_masks, loss_combination, focal_alpha, focal_gamma)
                        loss += l_main
                        
                        idx = 1 # æŒ‡é’ˆï¼ŒæŒ‡å‘ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„è¾“å‡º
                        
                        # 2. å¤„ç† Deep Supervision (Aux Head)
                        if model.use_deep_supervision:
                            # å‡è®¾æœ‰ä¸¤ä¸ª aux head
                            if idx + 1 < len(output):
                                pred_aux2 = clamp_logits(output[idx])
                                pred_aux3 = clamp_logits(output[idx+1])
                                idx += 2
                                # ä¸Šé‡‡æ ·å¯¹é½
                                pred_aux2 = F.interpolate(pred_aux2, size=true_masks.shape[1:], mode='bilinear', align_corners=True)
                                pred_aux3 = F.interpolate(pred_aux3, size=true_masks.shape[1:], mode='bilinear', align_corners=True)
                                
                                l_aux2 = calc_loss(pred_aux2, true_masks, loss_combination, focal_alpha, focal_gamma)
                                l_aux3 = calc_loss(pred_aux3, true_masks, loss_combination, focal_alpha, focal_gamma)
                                loss += 0.5 * l_aux2 + 0.4 * l_aux3

                        # 3. ğŸ”¥ å¤„ç† Decouple (Body + Edge)
                        # åˆ¤æ–­æ¡ä»¶ï¼šæ¨¡å‹å¼€å¯äº†è§£è€¦ ä¸” åˆ—è¡¨é‡Œè¿˜æœ‰è¶³å¤Ÿå…ƒç´ 
                        # (æ³¨æ„ï¼šå…¼å®¹ DataParallelï¼Œç”¨ getattr è·å– use_decouple)
                        is_decouple = getattr(model, 'use_decouple', False) or getattr(model.module, 'use_decouple', False) if hasattr(model, 'module') else False
                        
                        if is_decouple and idx + 1 < len(output):
                            pred_body = clamp_logits(output[idx])
                            pred_edge = clamp_logits(output[idx+1])
                            idx += 2
                            
                            # A. å®æ—¶ç”Ÿæˆ Body/Edge çœŸå€¼
                            target_body, target_edge = generate_body_edge_targets(true_masks, edge_width=5, device=device)
                            
                            # B. Body Loss (Dice + BCE)
                            # å¯¹é½å°ºå¯¸(é˜²æ­¢æ¨¡å‹ä¸­æœ‰ä¸‹é‡‡æ ·æœªæ¢å¤)
                            if pred_body.shape[2:] != target_body.shape[2:]:
                                pred_body = F.interpolate(pred_body, size=target_body.shape[2:], mode='bilinear')
                            
                            l_body = F.binary_cross_entropy_with_logits(pred_body, target_body) + \
                                     dice_loss(torch.sigmoid(pred_body), target_body)
                                     
                            # C. Edge Loss (Weighted BCE)
                            if pred_edge.shape[2:] != target_edge.shape[2:]:
                                pred_edge = F.interpolate(pred_edge, size=target_edge.shape[2:], mode='bilinear')
                                
                            pos_weight = torch.tensor([5.0], device=device) # è¾¹ç¼˜æ­£æ ·æœ¬åŠ æƒ
                            l_edge = F.binary_cross_entropy_with_logits(pred_edge, target_edge, pos_weight=pos_weight)
                            
                            # D. ç´¯åŠ  Loss
                            loss += lambda_body * l_body + lambda_edge * l_edge

                        # 4. å¤„ç†æ—§çš„ SFDA Edge (å¦‚æœè¿˜æœ‰å‰©ä½™)
                        if idx < len(output):
                            # è¿™é‡Œå¯ä»¥å¿½ç•¥ï¼Œæˆ–è€…è®¡ç®—æ—§çš„è¾¹ç¼˜ loss
                            pass
                            
                    else:
                        # å•è¾“å‡ºæƒ…å†µ
                        pred_main = clamp_logits(output)
                        loss = calc_loss(pred_main, true_masks, loss_combination, focal_alpha, focal_gamma)
                        
                        # éšå¼è¾¹ç¼˜ç›‘ç£ (Sobel Edge Loss)
                        if lambda_edge > 0 and not use_decouple:
                            try:
                                loss_e = edge_criterion(pred_main.float(), true_masks.float())
                                loss += lambda_edge * loss_e
                            except NameError:
                                pass 
                    
                    # -----------------------------------------------------------
                    # åŸå‹æ­£äº¤ Loss (å¦‚æœæœ‰)
                    # -----------------------------------------------------------
                    lambda_ortho = 0.0 # ğŸ”¥ [ä¿®æ­£] å»ºè®®å¼€å¯ä¸º 0.01ï¼ŒåŸä»£ç ä¸º 0.0 ä¼šå¯¼è‡´ä¸è®¡ç®—
                    if lambda_ortho > 0:
                         ortho_loss = compute_prototype_ortho_loss(model, device=device)
                         loss += lambda_ortho * ortho_loss

                    # -----------------------------------------------------------
                    # Loss å½’ä¸€åŒ– (ç”¨äºæ¢¯åº¦ç´¯ç§¯)
                    # -----------------------------------------------------------
                    loss = loss / accumulation_steps
                
                # å¼‚å¸¸æ£€æµ‹
                if torch.isnan(loss) or torch.isinf(loss):
                    logging.error(f'Loss NaN/Inf detected: {loss.item()}. Skipping batch.')
                    optimizer.zero_grad()
                    continue
                
                # åå‘ä¼ æ’­
                grad_scaler.scale(loss).backward()
                
                # ğŸ”¥ [ä¿®æ”¹] åªæœ‰è¾¾åˆ°ç´¯è®¡æ­¥æ•°ï¼Œæˆ– epoch ç»“æŸæ—¶æ‰æ›´æ–°
                if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):
                    grad_scaler.unscale_(optimizer)
                      # ğŸ”¥ [æ–°å¢] ä¸¥æ ¼çš„æ¢¯åº¦æ£€æŸ¥ï¼šå¦‚æœæ¢¯åº¦æœ‰ inf/nanï¼Œç›´æ¥è·³è¿‡è¿™ä¸€æ­¥æ›´æ–°
                    grad_is_valid = True
                    for param in model.parameters():
                        if param.grad is not None:
                            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                                grad_is_valid = False
                                break
                    
                    if not grad_is_valid:
                        logging.warning(f"âš ï¸ Epoch {epoch} Step {i}: Gradient Explosion detected (Inf/NaN). Skipping step.")
                        optimizer.zero_grad() # ä¸¢å¼ƒè¿™æ¬¡çš„æ¢¯åº¦
                        # ä¸åš stepï¼Œä¹Ÿä¸åš update
                    else:
                        # 2.2 æ¢¯åº¦è£å‰ª (Clip Gradient Norm)
                        # ğŸ”¥ [å»ºè®®] æŠŠ max_norm ä» 1.0 é™ä½åˆ° 0.5 æˆ– 0.1ï¼Œå¯¹ Transformer ç»“æ„æ›´ç¨³
                        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)
                        
                        epoch_grad_norms.append(grad_norm.item())

                    grad_scaler.step(optimizer)
                    grad_scaler.update()
                    
                    # æ›´æ–°å®Œåæ‰æ¸…é›¶
                    optimizer.zero_grad(set_to_none=True)

                    # WandB å®æ—¶æ—¥å¿— (è¿˜åŸ loss æ•°å€¼ç”¨äºæ˜¾ç¤º)
                    experiment.log({
                        'train/loss_batch': loss.item() * accumulation_steps, 
                        'train/grad_norm': grad_norm.item(), 
                        'global_step': global_step
                    })
                    pbar.set_postfix(**{'loss': loss.item() * accumulation_steps, 'grad': grad_norm.item()})
                    global_step += 1

                pbar.update(images.shape[0])
                batch_count += 1
                # ç´¯åŠ  Loss ç”¨äºæ˜¾ç¤º Epoch å¹³å‡å€¼ (è¿˜åŸæ•°å€¼)
                epoch_loss += loss.item() * accumulation_steps

        # ====== éªŒè¯ä¸è¯„ä¼° ======
        avg_epoch_loss = epoch_loss / max(batch_count, 1)
        avg_grad_norm = sum(epoch_grad_norms) / len(epoch_grad_norms) if epoch_grad_norms else 0.0
        # ğŸ”´ [ä¿®æ”¹ 1] ä¼ å…¥ criterion
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å®šä¹‰å¥½çš„ criterion è®¡ç®— loss
        val_metrics = evaluate(model, val_loader, device, amp, criterion=criterion)
        
        
        # 2. ğŸ”¥ [å…³é”®ä¿®æ”¹] ç¦ç”¨é˜ˆå€¼æ‰«æï¼Œç›´æ¥å¤ç”¨ 0.5 é˜ˆå€¼çš„ç»“æœ
        # logging.info('Starting threshold scanning...')
        # threshold_res = threshold_scan_evaluate(...) # <--- æ³¨é‡Šæ‰è¿™ä¸€è¡Œ
        
        # ğŸ”¥ æ‰‹åŠ¨æ„é€ ç»“æœå­—å…¸ï¼Œä¿æŒå˜é‡åå…¼å®¹ï¼Œé˜²æ­¢åé¢æŠ¥é”™
        threshold_res = {
            'best_dice': val_metrics['dice'],      # ç›´æ¥ç”¨ 0.5 çš„ Dice
            'best_f1': val_metrics['f1'],          # ç›´æ¥ç”¨ 0.5 çš„ F1
            'best_threshold_dice': 0.5,            # å›ºå®šæ˜¾ç¤º 0.5
            'best_threshold_f1': 0.5               # å›ºå®šæ˜¾ç¤º 0.5
        }
        
        logging.info('â© Skipping threshold scan. Using fixed threshold 0.5.')

        # ğŸ”¥ [ä¿®æ”¹] æ›´æ–°å­¦ä¹ ç‡ (å¿…é¡»ä¼ å…¥å½“å‰ epoch æ•°å€¼)
        # æ³¨æ„: timm çš„ step éœ€è¦ä¼ å…¥ epoch ç´¢å¼•
        scheduler.step(epoch)
        
        # 4. è¯¦ç»†æ§åˆ¶å°è¾“å‡º
        logging.info(
            f'Epoch {epoch}/{epochs} completed - '
            f'Train Loss: {avg_epoch_loss:.4f}, '
            f'Val Loss: {val_metrics["loss"]:.4f}, '
            f'Avg Grad Norm: {avg_grad_norm:.4f}, '
            f'Val Dice: {val_metrics["dice"]:.4f}, '
            f'Val IoU: {val_metrics["iou"]:.4f}, '
            f'Val F1: {val_metrics["f1"]:.4f}, '
            f'Val Precision: {val_metrics["precision"]:.4f}, '
            f'Val Recall: {val_metrics["recall"]:.4f}, '
            f'Best Dice: {threshold_res["best_dice"]:.4f} (threshold: {threshold_res["best_threshold_dice"]:.2f}), '
            f'Best F1: {threshold_res["best_f1"]:.4f} (threshold: {threshold_res["best_threshold_f1"]:.2f})'
        )

        # 5. ä¸Šä¼  WandB æ—¥å¿—
        current_lr = optimizer.param_groups[0]['lr']
        experiment.log({
            'train/epoch_loss': avg_epoch_loss,
            'val/loss': val_metrics['loss'],       # <--- å…³é”®ï¼æ·»åŠ è¿™ä¸€è¡Œï¼
            'train/avg_grad_norm': avg_grad_norm,
            'val/dice': val_metrics['dice'],
            'val/iou': val_metrics['iou'],
            'val/f1': val_metrics['f1'],
            'val/precision': val_metrics['precision'],
            'val/recall': val_metrics['recall'],
            'val/best_dice': threshold_res['best_dice'],
            'val/best_f1': threshold_res['best_f1'],
            'epoch': epoch,                        # ğŸ”¥ æ–°å¢: å½“å‰è½®æ¬¡
            'train/learning_rate': current_lr      # ğŸ”¥ æ–°å¢: å½“å‰å­¦ä¹ ç‡æ›²çº¿
        })
        # ğŸ”¥ [æ–°å¢] åŒæ—¶å†™å…¥æœ¬åœ° CSV æ–‡ä»¶
        csv_logger.log(epoch, avg_epoch_loss, val_metrics, current_lr)
        

        # ====== ä¿å­˜ Checkpoint ======
        if save_checkpoint:
            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'grad_scaler_state_dict': grad_scaler.state_dict(),
                'loss': avg_epoch_loss,
                'val_dice': float(val_metrics['dice']),
                'val_best_f1': float(threshold_res['best_f1']),
                # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] æ–°å¢è¿™ä¸¤è¡Œ
                'wandb_id': experiment.id,  # ä¿å­˜èº«ä»½è¯å·
                'global_step': global_step, # ä¿å­˜å½“å‰æ­¥æ•°
                # ... ä¿ç•™ä½ çš„å…¶ä»–é”®å€¼
                # ğŸ”¥ğŸ”¥ğŸ”¥ [æ ¸å¿ƒè¡¥å……] å¿…é¡»ä¿å­˜è¿™ 4 ä¸ªéšæœºçŠ¶æ€ ğŸ”¥ğŸ”¥ğŸ”¥
                'cpu_rng_state': torch.get_rng_state(),              # PyTorch CPU éšæœºçŠ¶æ€
                'cuda_rng_state': torch.cuda.get_rng_state(),        # PyTorch GPU éšæœºçŠ¶æ€ (å•å¡ç”¨è¿™ä¸ª)
                # 'cuda_rng_state': torch.cuda.get_rng_state_all(),  # å¦‚æœä½ æ˜¯å¤šå¡è®­ç»ƒï¼Œè¯·ç”¨è¿™è¡Œæ›¿æ¢ä¸Šä¸€è¡Œ
                'numpy_rng_state': np.random.get_state(),            # Numpy éšæœºçŠ¶æ€ (å½±å“æ•°æ®å¢å¼º)
                'py_rng_state': random.getstate(),                   # Python åŸç”ŸéšæœºçŠ¶æ€
            }
            
            # Latest
            torch.save(checkpoint, str(dir_checkpoint / 'checkpoint_latest.pth'))
            # 2. ğŸ”¥ [ä¿®æ”¹ç‚¹ 2] 30è½®ä»¥åï¼Œæ¯ä¸€è½®éƒ½é¢å¤–ä¿å­˜ä¸€ä¸ªæ–‡ä»¶
            if epoch > 50:
                # æ–‡ä»¶åä¾‹å¦‚: checkpoint_epoch_31.pth, checkpoint_epoch_32.pth ...
                epoch_path = str(dir_checkpoint / f'checkpoint_epoch_{epoch}.pth')
                torch.save(checkpoint, epoch_path)
                logging.info(f'ğŸ’¾ [å¤‡ä»½] å·²ä¿å­˜ç¬¬ {epoch} è½®æƒé‡: {epoch_path}')
            # Best
            best_path = str(dir_checkpoint / 'checkpoint_best.pth')
            current_dice = val_metrics['dice']
            save_best = False
            
            if not Path(best_path).exists():
                save_best = True
                logging.info(f'   ğŸŒŸ é¦–æ¬¡åˆ›å»ºæœ€ä½³æ¨¡å‹ (Dice: {current_dice:.4f})')
            else:
                try:
                    prev_best = torch.load(best_path, map_location='cpu', weights_only=False).get('val_dice', 0.0)
                    if current_dice > prev_best:
                        save_best = True
                        logging.info(f'   ğŸ† åˆ·æ–°æœ€ä½³è®°å½•! ({prev_best:.4f} -> {current_dice:.4f})')
                    else:
                        # ğŸ”¥ğŸ”¥ğŸ”¥ è¿™ä¸€è¡Œæ˜¯ä½ è¦æ±‚çš„å…³é”®æ—¥å¿— ğŸ”¥ğŸ”¥ğŸ”¥
                        logging.info(f'   (å½“å‰ Dice {current_dice:.4f} æœªè¶…è¿‡æœ€ä½³ {prev_best:.4f})')
                except:
                    save_best = True
            # ğŸ”¥ å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼šä¿å­˜æƒé‡ + ä¸Šä¼ é«˜æ¸…å›¾ç‰‡
            if save_best:
                torch.save(checkpoint, best_path)
                try:
                    # è°ƒç”¨æˆ‘ä»¬å†™å¥½çš„å¯è§†åŒ–å‡½æ•°
                    log_best_visuals(model, val_loader, device, num_samples=5)
                except Exception as e:
                    logging.warning(f"âš ï¸ å¯è§†åŒ–ä¸Šä¼ å¤±è´¥: {e}")

            
    wandb.finish()

# è®¡ç®— Loss è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
def calc_loss(masks_pred, true_masks, loss_combination, focal_alpha, focal_gamma):
    """
    ğŸ”¥ [æœ€ç»ˆå®Œæ•´ç‰ˆ] 
    1. å¼ºåˆ¶ FP32 è®¡ç®— (V100 ä¿å‘½)
    2. ä¿ç•™äº†åŸæœ¬çš„ try-except å…¼å®¹é€»è¾‘
    """
    # -----------------------------------------------------------
    # 1. å…¨å±€å¼ºåˆ¶è½¬æ¢ï¼šè¿›é—¨å…ˆå®‰æ£€ï¼Œç»Ÿç»Ÿå˜ float32
    # -----------------------------------------------------------
    masks_pred = masks_pred.float()
    true_masks = true_masks.float()

    # -----------------------------------------------------------
    # 2. åˆ†æƒ…å†µè®¡ç®— (æ³¨æ„ï¼šä¸‹é¢éƒ½ä¸éœ€è¦å†å†™ .float() äº†)
    # -----------------------------------------------------------
    if loss_combination == 'bce':
        criterion = nn.BCEWithLogitsLoss()
        return criterion(masks_pred.squeeze(1), true_masks)
    
    elif loss_combination == 'focal':
        criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        return criterion(masks_pred.squeeze(1), true_masks)
    
    elif loss_combination == 'dice':
        # ç¡®ä¿ sigmoid ä¹Ÿåœ¨ float32 ä¸‹è¿›è¡Œ
        return dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks, multiclass=False)
    
    else:
        # -----------------------------------------------------------
        # 3. ç»„åˆ Loss (ä¿ç•™ä½ åŸæ¥çš„ try-except é€»è¾‘)
        # -----------------------------------------------------------
        try:
            # å°è¯•è°ƒç”¨å°è£…å¥½çš„ç±»
            criterion = CombinedLoss(loss_combination.split('+'), [1.0, 1.0], focal_alpha, focal_gamma)
            return criterion(masks_pred.squeeze(1), true_masks)
        except:
            # ğŸ”¥ Fallback: æ‰‹åŠ¨ç›¸åŠ 
            # è¿™é‡Œçš„ input å·²ç»æ˜¯ float32 äº†ï¼Œè®¡ç®—éå¸¸å®‰å…¨
            bce = nn.BCEWithLogitsLoss()(masks_pred.squeeze(1), true_masks)
            
            # Dice éœ€è¦ sigmoid åçš„æ¦‚ç‡
            dice = dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks, multiclass=False)
            
            return bce + dice

def get_args():
    parser = argparse.ArgumentParser(description='Train the Unified UNet')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--epochs', '-e', type=int, default=20)
    parser.add_argument('--batch-size', '-b', type=int, default=8)
    parser.add_argument('--learning-rate', '-l', type=float, default=1e-4)
    parser.add_argument('--load', '-f', type=str, default=False)
    parser.add_argument('--scale', '-s', type=float, default=1.0)
    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0)
    parser.add_argument('--amp', action='store_true', default=False)
    parser.add_argument('--bilinear', action='store_true', default=False)
    parser.add_argument('--classes', '-c', type=int, default=1)
    parser.add_argument('--start-epoch', type=int, default=1)
    
    # æ¶æ„å‚æ•°
    parser.add_argument('--encoder', type=str, default='resnet', choices=['resnet', 'cnextv2', 'standard'])
    parser.add_argument('--decoder', type=str, default='phd', choices=['phd', 'standard'])
    parser.add_argument('--cnext-type', type=str, default='convnextv2_base')
    
    # SOTA æ¨¡å—å¼€å…³
    parser.add_argument('--use-dcn', action='store_true', default=False, help='Enable standard DCNv3')
    parser.add_argument('--use-dubm', action='store_true', default=False, help='Enable D-UBM (SOTA)')
    parser.add_argument('--use-strg', action='store_true', default=False, help='Enable STRG Skip Enhancement')
    parser.add_argument('--use-dual-stream', action='store_true', default=False, help='Enable Dual-Stream Boundary Architecture')
    parser.add_argument('--use-wavelet-denoise', action='store_true', default=False, help='Enable Wavelet Denoising on Skip Connections')
    parser.add_argument('--use-dsis', action='store_true', default=False, help='Enable Dual-Stream Interactive Skip Module')
    parser.add_argument('--use-unet3p', action='store_true', default=False, help='Enable UNet 3+ Full-Scale Skip Connections')
    # [æ–°å¢] MDBES-Net ç›¸å…³å‚æ•°
    parser.add_argument('--use_decouple', action='store_true', default=False, help='Enable MDBES-Net explicit decoupling supervision')
    parser.add_argument('--lambda_edge', type=float, default=1.0, help='Weight for the Edge loss (default: 2.0)')
    parser.add_argument('--lambda_body', type=float, default=1.0, help='Weight for the Body loss (default: 1.0)')
    
    # å…¶ä»–å¢å¼ºæ¨¡å— (ä¿æŒåŸæœ‰å¼€å…³å®šä¹‰ï¼Œä½†ç§»é™¤äº†æ—§ç‰ˆ Edge Logic çš„æ‰§è¡Œ)
    parser.add_argument('--use-wgn-enhancement', action='store_true', default=False)
    parser.add_argument('--use-cafm', action='store_true', default=False)
    parser.add_argument('--use-edge-loss', action='store_true', default=False, help='Legacy WGN Edge Loss (Deprecated logic removed)')
    parser.add_argument('--use-fme', action='store_true', default=False, 
                        help='Enable Frequency-Mamba Enhancement (FME) module')
    parser.add_argument('--no-mfam', action='store_true', help='Disable MFAM for ablation study')
    # WGN å‚æ•°
    parser.add_argument('--wgn-base-order', type=int, default=3)
    parser.add_argument('--wgn-orders', type=str, default=None)

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument('--optimizer', type=str, default='adamw', choices=['adamw', 'rmsprop'])
    parser.add_argument('--loss-combination', type=str, default='focal+dice')
    parser.add_argument('--loss-weights', type=str, default='1.0,1.0')
    parser.add_argument('--focal-alpha', type=float, default=0.25)
    parser.add_argument('--focal-gamma', type=float, default=2.0)
    parser.add_argument('--weight-decay', type=float, default=0.0005)
    parser.add_argument('--momentum', type=float, default=0.999)
    parser.add_argument('--gradient-clipping', type=float, default=1.0)
    parser.add_argument('--backbone-lr-scale', type=float, default=0.1)
    # ğŸ”¥ [æ–°å¢] æ¢¯åº¦ç´¯è®¡æ­¥æ•°ï¼Œé»˜è®¤1è¡¨ç¤ºä¸ç´¯è®¡
    parser.add_argument('--accumulation-steps', type=int, default=1, help='Gradient accumulation steps')
# ğŸ”¥ [æ–°å¢ 2] æ·»åŠ é¢„è®­ç»ƒæƒé‡å¼€å…³ (1=åŠ è½½, 0=ä¸åŠ è½½)
    parser.add_argument('--pretrained', type=int, default=1, help='Load ImageNet weights? 1=Yes, 0=No')
    parser.add_argument('--use-deep-supervision', action='store_true', default=False, help='Enable Deep Supervision')
    return parser.parse_args()
 
if __name__ == '__main__':
    # ğŸ”¥ğŸ”¥ğŸ”¥ åœ¨è¿™é‡Œè°ƒç”¨ï¼Œæ•°å­—éšä¾¿å¡«ï¼ˆæ¯”å¦‚ 42, 3407, 2023ï¼‰
    setup_seed(42)
    
    args = get_args()
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # WGN Orders å¤„ç†
    wgn_orders = None
    if args.use_wgn_enhancement:
        if args.wgn_orders:
            orders_list = [int(x) for x in args.wgn_orders.split(',')]
            wgn_orders = {'layer1': (orders_list[0], orders_list[1]), 'layer2': (orders_list[2], orders_list[3]), 'layer3': (orders_list[4], orders_list[5])}
        else:
            base = args.wgn_base_order
            wgn_orders = {'layer1': (base, base-1), 'layer2': (base+1, base), 'layer3': (base+2, base+1)}

    # å®ä¾‹åŒ–æ¨¡å‹
    logging.info(f"ğŸš€ Building Model: Encoder={args.encoder}, Decoder={args.decoder}")
    model = UNet(
        n_channels=3,
        n_classes=args.classes,
        bilinear=args.bilinear,
        encoder_name=args.encoder,
        decoder_type=args.decoder,
        cnext_type=args.cnext_type,
        # ğŸ”¥ [æ–°å¢ 4] ä¼ å…¥é¢„è®­ç»ƒå‚æ•° (è½¬ä¸ºå¸ƒå°”å€¼)
        pretrained=(args.pretrained == 1),
        use_wgn_enhancement=args.use_wgn_enhancement,
        use_cafm=args.use_cafm,
        # æ³¨æ„: å³ä½¿ä¼ å…¥ use_edge_loss=True, train loop ä¸­å·²ç§»é™¤äº†å¤„ç†å®ƒçš„é€»è¾‘
        use_edge_loss=args.use_edge_loss, 
        wgn_orders=wgn_orders,
        use_dcn_in_phd=args.use_dcn,
        use_dubm=args.use_dubm,
        use_strg=args.use_strg,
        use_dual_stream=args.use_dual_stream, # ğŸ”¥ æ–°å¢åŒæµ
        use_dsis=args.use_dsis, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_unet3p=args.use_unet3p, # ğŸ”¥ ä¼ å…¥å‚æ•°
        use_wavelet_denoise=args.use_wavelet_denoise,  # ğŸ‘ˆ ä¼ å…¥è¿™ä¸ªå‚æ•°
        use_mfam=not args.no_mfam, # æ³¨æ„è¿™é‡Œï¼šå¦‚æœå‘½ä»¤è¡ŒåŠ äº† --no-mfamï¼Œåˆ™ use_mfam=False
        use_deep_supervision=args.use_deep_supervision, # ğŸ”¥ ä¼ å…¥å‚æ•°
        # ğŸ”¥ ä¼ å…¥ MDBES-Net è§£è€¦å‚æ•°
        use_decouple=args.use_decouple # ğŸ‘ˆ ç¡®ä¿è¿™é‡Œä¼ å…¥äº†å‚æ•°ï¼
    )
    
    model = model.to(memory_format=torch.channels_last)
    model.to(device=device)
    # =================================================================================
    # ğŸ”¥ [æ–°å¢ä»£ç ] è®¡ç®—å¹¶æ‰“å°æ¨¡å‹å‚æ•°é‡
    # =================================================================================
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    logging.info(f"""
    ğŸ“Š Model Summary:
        Total Parameters:     {total_params / 1e6:.2f} M
        Trainable Parameters: {trainable_params / 1e6:.2f} M
        Frozen Parameters:    {(total_params - trainable_params) / 1e6:.2f} M
    """)
    # =================================================================================
    # åŠ è½½æƒé‡
    checkpoint_to_load = None
    if args.load:
        try:
            ckpt = torch.load(args.load, map_location=device, weights_only=False)
            if 'model_state_dict' in ckpt:
                model.load_state_dict(ckpt['model_state_dict'])
                checkpoint_to_load = ckpt
                # ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] è‡ªåŠ¨è¯»å–æ–­ç‚¹è½®æ•°ï¼Œå®ç°æ— ç¼ç»­è®­ ğŸ”¥ğŸ”¥ğŸ”¥
                if 'epoch' in ckpt:
                    args.start_epoch = ckpt['epoch'] + 1
                    logging.info(f"ğŸ”„ è‡ªåŠ¨æ£€æµ‹åˆ°æ–­ç‚¹ (Epoch {ckpt['epoch']})ï¼Œå°†ä» Epoch {args.start_epoch} ç»§ç»­è®­ç»ƒï¼")
            else:
                model.load_state_dict(ckpt)
            logging.info(f'Model loaded from {args.load}')
        except Exception as e:
            logging.error(f"Load failed: {e}")
            sys.exit(1)

    try:
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            device=device,
            img_scale=args.scale,
            val_percent=args.val / 100,
            amp=args.amp,
            start_epoch=args.start_epoch,
            checkpoint_to_load=checkpoint_to_load,
            backbone_lr_scale=args.backbone_lr_scale,
            weight_decay=args.weight_decay,
            momentum=args.momentum,
            gradient_clipping=args.gradient_clipping,
            loss_combination=args.loss_combination,
            loss_weights=args.loss_weights,
            focal_alpha=args.focal_alpha,
            focal_gamma=args.focal_gamma,
            optimizer_type=args.optimizer,
            # ğŸ”¥ [æ–°å¢] æŠŠæƒé‡ä¼ ç»™è®­ç»ƒå‡½æ•°
            lambda_edge=args.lambda_edge,
            lambda_body=args.lambda_body,
            accumulation_steps=args.accumulation_steps, # <--- ğŸ”¥ åŠ ä¸Šè¿™ä¸€è¡Œï¼
            use_decouple=args.use_decouple # ğŸ‘ˆ ç¡®ä¿ä¼ ç»™è®­ç»ƒå‡½æ•°
        )
    except KeyboardInterrupt:
        torch.save(model.state_dict(), 'INTERRUPTED.pth')
        logging.info('Saved interrupt checkpoint')