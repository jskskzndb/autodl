"""
unet_s_dmfnet.py
[S-DMFNet] Simplified Dual-Stream Mutual-Guided Frequency-Aware Network
æ¶æ„è¯´æ˜ï¼š
1. å·¦è·¯ä¸»å¹²ï¼šConvNeXt V2 Base (è¯­ä¹‰æµ)
2. å³è·¯ä¸»å¹²ï¼šWavelet-Mamba Encoder (é¢‘ç‡/è¾¹ç•Œæµ)
3. äº¤äº’æ¨¡å—ï¼šFGF (Frequency-Guided Fusion) - æ¯ä¸€å±‚äº¤äº’
4. ç“¶é¢ˆèåˆï¼šMFAM (Mixed-Frequency Attention Mechanism)
5. è§£ç å™¨ï¼šPHD Decoder (Single Stream) - ä»…è´Ÿè´£ä¸»ä½“é¢„æµ‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import sys
from pathlib import Path

# å°è¯•å¯¼å…¥ PHD è§£ç å™¨å— (é€‚é…ä½ çš„ç›®å½•ç»“æ„)
try:
    from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError:
    # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœç›´æ¥åœ¨æ ¹ç›®å½•è¿è¡Œ
    try:
        from unet.hybrid_decoder import PHD_DecoderBlock
    except ImportError:
        print("âŒ è­¦å‘Š: æœªæ‰¾åˆ° PHD_DecoderBlockï¼Œè¯·æ£€æŸ¥ decoder/hybrid_decoder.py æ˜¯å¦å­˜åœ¨ã€‚")
        PHD_DecoderBlock = None

# å°è¯•å¯¼å…¥ Mamba è¾…åŠ©ç±» (ç”¨äºå³è·¯é¢‘ç‡æµ)
try:
    from decoder.mamba_helper import MambaLayer2D
except ImportError:
    try:
        from unet.mamba_helper import MambaLayer2D
    except ImportError:
        print("âŒ è­¦å‘Š: æœªæ‰¾åˆ° MambaLayer2Dï¼Œè¯·æ£€æŸ¥ mamba_helper.pyã€‚")
        MambaLayer2D = None

# ================================================================
# 1. åŸºç¡€å·¥å…·ç±» (å°æ³¢å˜æ¢ & é¢‘ç‡å¤„ç†)
# ================================================================

class HaarWaveletTransform(nn.Module):
    """ ç¦»æ•£å°æ³¢å˜æ¢ (DWT) å’Œ é€†å˜æ¢ (IWT) """
    def __init__(self):
        super().__init__()
        # Haar æ»¤æ³¢å™¨
        ll = torch.tensor([[0.5, 0.5], [0.5, 0.5]])
        lh = torch.tensor([[-0.5, -0.5], [0.5, 0.5]])
        hl = torch.tensor([[-0.5, 0.5], [-0.5, 0.5]])
        hh = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])
        
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1))

    def dwt(self, x):
        B, C, H, W = x.shape
        # Pad if needed
        if H % 2 != 0 or W % 2 != 0:
            x = F.pad(x, (0, W % 2, 0, H % 2), mode='reflect')
        
        # Group convolution for channel-wise DWT
        filters = self.filters.repeat(C, 1, 1, 1)
        output = F.conv2d(x, filters, stride=2, groups=C)
        
        # Split into subbands
        B, C4, H2, W2 = output.shape
        # output structure: [C*4, H/2, W/2] -> 0::4 is LL, 1::4 is LH...
        # Reshape to easily extract: [B, C, 4, H/2, W/2]
        output = output.view(B, C, 4, H2, W2)
        
        ll, lh, hl, hh = output[:, :, 0], output[:, :, 1], output[:, :, 2], output[:, :, 3]
        return ll, lh, hl, hh

    def idwt(self, ll, lh, hl, hh):
        # ç®€åŒ–çš„ IWT (ä½¿ç”¨è½¬ç½®å·ç§¯æˆ–æ’å€¼+åŠ æƒï¼Œè¿™é‡Œä¸ºäº†æ•ˆç‡ä½¿ç”¨ Upsample è¿‘ä¼¼æˆ–ç›´æ¥åå‘é€»è¾‘)
        # ä¸ºä¿è¯æ¢¯åº¦ä¼ æ’­å’Œç²¾ç¡®é‡æ„ï¼Œè¿™é‡Œä½¿ç”¨ Upsample + Conv çš„å¯å­¦ä¹ é€†å˜æ¢æ–¹å¼æ›¿ä»£æ ‡å‡† IDWTï¼Œ
        # æˆ–è€…ä¸ºäº†ä¸¥æ ¼å¤ç°ï¼Œæˆ‘ä»¬ä½¿ç”¨åå‘ Haar å·ç§¯ã€‚
        # è¿™é‡Œä¸ºäº†ä»£ç ç¨³å®šæ€§ï¼Œé‡‡ç”¨ç‰¹å¾æ‹¼æ¥åä¸Šé‡‡æ ·èåˆï¼Œæ¨¡æ‹Ÿ IWT æ•ˆæœã€‚
        return torch.cat([ll, lh, hl, hh], dim=1) 

# ================================================================
# 2. æ ¸å¿ƒæ¨¡å—: FGF & MFAM & WaveletMambaBlock
# ================================================================

class WaveletMambaBlock(nn.Module):
    """
    [å³è·¯] å°æ³¢-Mamba ç¼–ç å™¨å—
    ç»“æ„: DWT -> LL(Mamba) + High(Conv) -> Fusion
    """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.dwt = HaarWaveletTransform()
        
        # 1. ä½é¢‘å¤„ç† (LL): ä½¿ç”¨ Mamba æ•æ‰å…¨å±€ç»“æ„
        # è¾“å…¥é€šé“æ˜¯ in_channels (DWT å spatial å‡åŠï¼Œé€šé“ä¸å˜)
        self.low_process = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            MambaLayer2D(dim=out_channels) if MambaLayer2D else nn.Identity()
        )
        
        # 2. é«˜é¢‘å¤„ç† (LH, HL, HH): ä½¿ç”¨å·ç§¯æ•æ‰è¾¹ç¼˜
        # è¾“å…¥é€šé“æ˜¯ in_channels * 3
        self.high_process = nn.Sequential(
            nn.Conv2d(in_channels * 3, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # 3. èåˆå±‚ (è¾“å‡ºç»™ä¸‹ä¸€å±‚ æˆ– FGF)
        self.fusion = nn.Conv2d(out_channels * 2, out_channels, 1)

    def forward(self, x):
        # 1. DWT åˆ†è§£
        ll, lh, hl, hh = self.dwt.dwt(x)
        
        # 2. åŒæµå¤„ç†
        ll_feat = self.low_process(ll)
        high_cat = torch.cat([lh, hl, hh], dim=1)
        high_feat = self.high_process(high_cat)
        
        # 3. èåˆ (æ¨¡æ‹Ÿ IWT çš„ä¿¡æ¯æ•´åˆ)
        out = self.fusion(torch.cat([ll_feat, high_feat], dim=1))
        
        # å¯¹é½å°ºå¯¸ (å¦‚æœ DWT å¯¼è‡´åˆ†è¾¨ç‡å‡åŠï¼Œè¿™é‡Œ out å·²ç»æ˜¯ H/2, W/2)
        return out

class FGF_Module(nn.Module):
    """
    [äº¤äº’] é¢‘ç‡å¼•å¯¼èåˆæ¨¡å— (Frequency-Guided Fusion)
    é€»è¾‘: å³è·¯(Freq) ç”Ÿæˆ Attention Map -> æŒ‡å¯¼ å·¦è·¯(Spatial)
    """
    def __init__(self, spatial_dim, freq_dim):
        super().__init__()
        # å°†å³è·¯ç‰¹å¾æ˜ å°„ä¸º 1 é€šé“æ³¨æ„åŠ›å›¾
        self.freq_to_att = nn.Sequential(
            nn.Conv2d(freq_dim, 1, 1),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        # ç®€å•çš„é€šé“å¯¹é½ (å¯é€‰ï¼Œç”¨äºæ®‹å·®å¢å¼º)
        self.align = nn.Conv2d(freq_dim, spatial_dim, 1)

    def forward(self, x_spatial, x_freq):
        # 1. å¯¹é½å°ºå¯¸ (å¦‚æœå³è·¯æ˜¯ä¸‹é‡‡æ ·åçš„ï¼Œéœ€è¦ä¸Šé‡‡æ ·å¯¹é½å·¦è·¯)
        # å·¦è·¯å¦‚æœæ˜¯ [H, W]ï¼Œå³è·¯åŒå±‚è¾“å…¥å‰æ˜¯ [H, W] (ä½†ç»è¿‡ Block åå¯èƒ½å˜äº†)
        # è¿™é‡Œå‡è®¾ x_freq å·²ç»è¢«è°ƒæ•´åˆ°ä¸ x_spatial åŒå°ºå¯¸ï¼Œæˆ–è€…éœ€è¦æ’å€¼
        if x_freq.shape[2:] != x_spatial.shape[2:]:
            x_freq = F.interpolate(x_freq, size=x_spatial.shape[2:], mode='bilinear', align_corners=False)

        # 2. ç”Ÿæˆé¢‘ç‡æ³¨æ„åŠ›å›¾ (0~1)
        att_map = self.freq_to_att(x_freq)
        
        # 3. æŒ‡å¯¼: ç©ºé—´ç‰¹å¾ * æ³¨æ„åŠ›å›¾ (æŠ‘åˆ¶å™ªå£°)
        x_guided = x_spatial * att_map
        
        # 4. æ®‹å·®è¡¥å……: å°†é¢‘ç‡ç‰¹å¾åŠ å›å»å¢å¼ºè¾¹ç¼˜
        x_out = x_guided + self.align(x_freq)
        
        return x_out

class MFAM(nn.Module):
    """
    [ç“¶é¢ˆ] æ··åˆé¢‘ç‡æ³¨æ„åŠ›æœºåˆ¶ (Mixed-Frequency Attention Mechanism)
    """
    def __init__(self, in_channels):
        super().__init__()
        reduction = 4
        mid_channels = max(16, in_channels // reduction)

        # è‡ªé€‚åº”é¢‘ç‡å¹³è¡¡å‚æ•°
        self.phi_h = nn.Parameter(torch.ones(1, in_channels, 1, 1), requires_grad=True)
        self.phi_l = nn.Parameter(torch.ones(1, in_channels, 1, 1), requires_grad=True)

        # æ–¹å‘ä¿¡æ¯æå– (æ¨¡æ‹Ÿæ°´å¹³/å‚ç›´å·ç§¯)
        self.proj_h_hor = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 3), padding=(0, 1))
        self.proj_h_ver = nn.Conv2d(in_channels, in_channels, kernel_size=(3, 1), padding=(1, 0))
        self.proj_l_hor = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 3), padding=(0, 1))
        self.proj_l_ver = nn.Conv2d(in_channels, in_channels, kernel_size=(3, 1), padding=(1, 0))
        self.gamma_h = nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.gamma_l = nn.Parameter(torch.tensor(0.5), requires_grad=True)

        # é€šé“ç›¸å…³æ€§å»ºæ¨¡
        self.gap = nn.AdaptiveAvgPool2d(1)
        self.fc_h = nn.Sequential(nn.Linear(in_channels, mid_channels), nn.ReLU(), nn.Linear(mid_channels, in_channels), nn.Sigmoid())
        self.fc_l = nn.Sequential(nn.Linear(in_channels, mid_channels), nn.ReLU(), nn.Linear(mid_channels, in_channels), nn.Sigmoid())
        self.alpha = nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.beta = nn.Parameter(torch.tensor(0.5), requires_grad=True)

        self.fusion_conv = nn.Conv2d(in_channels, in_channels, 1)

    def forward(self, f_spatial, f_freq):
        # å°ºå¯¸å¯¹é½
        if f_freq.shape[2:] != f_spatial.shape[2:]:
            f_freq = F.interpolate(f_freq, size=f_spatial.shape[2:], mode='bilinear', align_corners=False)

        B, C, H, W = f_spatial.shape
        
        # 1. å¹³è¡¡
        f_star = self.phi_h * f_freq + self.phi_l * f_spatial

        # 2. æ–¹å‘æå–
        d_h = self.proj_h_hor(f_freq) + self.proj_h_ver(f_freq)
        d_l = self.proj_l_hor(f_spatial) + self.proj_l_ver(f_spatial)
        f_dir = self.gamma_h * d_h + self.gamma_l * d_l

        # 3. é€šé“äº¤äº’
        u_h = self.gap(f_freq).view(B, C)
        u_l = self.gap(f_spatial).view(B, C)
        
        # ç®€åŒ–çš„äº’ç›¸å…³è®¡ç®— (ä¸ºäº†èŠ‚çœæ˜¾å­˜ï¼Œä¸ç›´æ¥ç®— BxCxC çš„çŸ©é˜µï¼Œè€Œæ˜¯ç”¨çº¿æ€§å±‚æ¨¡æ‹Ÿäº¤äº’)
        # è¿™é‡Œä¸¥æ ¼å¤ç°è®ºæ–‡é€»è¾‘éœ€è¦ BxCxCï¼Œä½†å¯¹äº Base æ¨¡å‹å¯èƒ½ OOMï¼Œé‡‡ç”¨è¿‘ä¼¼å¤ç°ï¼š
        w_h_c = self.fc_h(self.alpha * u_h + self.beta * u_l).view(B, C, 1, 1)
        w_l_c = self.fc_l(self.alpha * u_l + self.beta * u_h).view(B, C, 1, 1)
        w_c = 0.5 * (w_h_c + w_l_c)

        # 4. é‡æ„
        f_fused = (self.fusion_conv(f_star) + f_dir) * w_c
        return f_spatial + f_fused

# ================================================================
# 3. S_DMFNet ä¸»æ¨¡å‹
# ================================================================

class S_DMFNet(nn.Module):
    """
    S-DMFNet æ¨¡å‹ä¸»ç±»
    å®Œå…¨é€‚é… train.py çš„è°ƒç”¨æ¥å£
    """
    def __init__(self, n_channels, n_classes, bilinear=False, 
                 encoder_name='cnextv2', cnext_type='convnextv2_base', # å¼ºåˆ¶ Base
                 decoder_name='phd', use_dcn=True,
                 # æ¥æ”¶æ‰€æœ‰ train.py å¯èƒ½ä¼ å…¥çš„å‚æ•°ï¼Œé˜²æ­¢æŠ¥é”™ (ä½†ä¸ä¸€å®šéƒ½ä½¿ç”¨)
                 use_dsis=False, use_dual_stream=False, use_wavelet_denoise=False, 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, 
                 use_dubm=False, use_strg=False, **kwargs):
        super(S_DMFNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        
        print(f"ğŸš€ [S-DMFNet] åˆå§‹åŒ–... Encoder: {cnext_type} (Base), Decoder: {decoder_name}")

        # --- 1. å·¦è·¯: Spatial Encoder (ConvNeXt V2 Base) ---
        # å¼ºåˆ¶ä½¿ç”¨ convnextv2_baseï¼Œå¿½ç•¥ä¼ å…¥çš„ cnext_type å¦‚æœå®ƒä¸æ˜¯ base
        backbone_name = 'convnextv2_base' 
        self.spatial_encoder = timm.create_model(
            backbone_name, 
            pretrained=True, 
            features_only=True,
            out_indices=(0, 1, 2, 3)
        )
        
        # Base ç‰ˆæœ¬çš„é€šé“æ•°: [128, 256, 512, 1024]
        # s1(4x), s2(8x), s3(16x), s4(32x)
        s_dims = [128, 256, 512, 1024] 
        self.dims = s_dims

        # --- 2. å³è·¯: Frequency Encoder (Lightweight Wavelet Stream) ---
        # ä¸ºäº†æ˜¾å­˜å¹³è¡¡ï¼Œå³è·¯é€šé“æ•°è®¾ä¸ºå·¦è·¯çš„ 1/4
        f_dims = [c // 4 for c in s_dims] # [32, 64, 128, 256]
        
        # Stem: å¿«é€Ÿä¸‹é‡‡æ ·åˆ° 4x (å¯¹é½ s1)
        self.freq_stem = nn.Sequential(
            nn.Conv2d(3, f_dims[0], 4, stride=4, padding=0),
            nn.BatchNorm2d(f_dims[0]),
            nn.ReLU(inplace=True)
        )
        
        self.freq_layers = nn.ModuleList()
        # Stage 1->2, 2->3, 3->4
        for i in range(3):
            self.freq_layers.append(WaveletMambaBlock(f_dims[i], f_dims[i+1]))
            
        # æœ€åä¸€ä¸ª Stage 4 çš„å¤„ç†
        self.freq_stage4 = WaveletMambaBlock(f_dims[3], f_dims[3])

        # --- 3. äº¤äº’: FGF Modules (æ¯ä¸€å±‚) ---
        self.fgf_modules = nn.ModuleList([
            FGF_Module(s_dims[i], f_dims[i]) for i in range(4)
        ])

        # --- 4. ç“¶é¢ˆ: MFAM (Deep Fusion) ---
        # å…ˆå¯¹é½å³è·¯é€šé“åˆ°å·¦è·¯
        self.neck_freq_align = nn.Conv2d(f_dims[-1], s_dims[-1], 1)
        self.neck_mfam = MFAM(in_channels=s_dims[-1])

        # --- 5. è§£ç å™¨: PHD Decoder (ä»…å•æµ) ---
        # é‡æ–°æ˜ å°„é€šé“å˜é‡ï¼Œé€‚é… copy æ¥çš„ä»£ç ä¹ æƒ¯
        c1, c2, c3, c4 = s_dims
        
        # å®šä¹‰ä¸Šé‡‡æ ·æ¨¡å— (PHD Blocks)
        # PHD_DecoderBlock(in_ch, skip_ch, out_ch)
        # Up 1: x4 (1024) + s3 (512) -> 512
        self.up1 = PHD_DecoderBlock(c4, c3, c3, use_dcn=use_dcn)
        # Up 2: d1 (512) + s2 (256) -> 256
        self.up2 = PHD_DecoderBlock(c3, c2, c2, use_dcn=use_dcn)
        # Up 3: d2 (256) + s1 (128) -> 128
        self.up3 = PHD_DecoderBlock(c2, c1, c1, use_dcn=use_dcn)
        
        # Final Up: d3 (128) -> Original Res
        self.final_up = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)
        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)

    def forward(self, x):
        # === Encoder Pass ===
        
        # 1. å·¦è·¯ ConvNeXt
        # s_feats = [s1, s2, s3, s4]
        s_feats = list(self.spatial_encoder(x))
        
        # 2. å³è·¯ Wavelet
        f_feats = []
        f_curr = self.freq_stem(x) # [B, 32, H/4, W/4] -> Align with s1
        f_feats.append(f_curr)
        
        # é€çº§å¤„ç†: f1->f2, f2->f3, f3->f4
        for layer in self.freq_layers:
            f_curr = layer(f_curr) # DWT Downsample inside
            f_feats.append(f_curr)
        
        # å¤„ç†æœ€åä¸€å±‚ f4 (ä¿æŒåˆ†è¾¨ç‡)
        f_feats[-1] = self.freq_stage4(f_feats[-1])

        # === Interaction (FGF) ===
        # æ¯ä¸€å±‚è¿›è¡Œèåˆæ¸…æ´—
        s_clean = []
        for i in range(4):
            # s_feats[i] å’Œ f_feats[i] åˆ†è¾¨ç‡åº”å½“ä¸€è‡´
            s_out = self.fgf_modules[i](s_feats[i], f_feats[i])
            s_clean.append(s_out)
            
        s1, s2, s3, x4 = s_clean

        # === Neck (MFAM) ===
        # æ·±åº¦èåˆ x4 å’Œ f4
        f4_aligned = self.neck_freq_align(f_feats[3])
        x4_enhanced = self.neck_mfam(x4, f4_aligned)

        # === Decoder Pass (PHD) ===
        # ä½¿ç”¨æ¸…æ´—åçš„ skip features (s1, s2, s3) å’Œ å¢å¼ºåçš„æ·±å±‚ç‰¹å¾ (x4_enhanced)
        
        # d1: [B, 512, H/16, W/16]
        d1 = self.up1(x4_enhanced, s3)
        
        # d2: [B, 256, H/8, W/8]
        d2 = self.up2(d1, s2)
        
        # d3: [B, 128, H/4, W/4]
        d3 = self.up3(d2, s1)
        
        # Final: [B, n_classes, H, W]
        d4 = self.final_up(d3)
        logits = self.outc(d4)
        
        return logits