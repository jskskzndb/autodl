"""
unet/unet_s_dmfnet.py
[S-DMFNet Pro] Enhanced Dual-Stream Mutual-Guided Frequency-Aware Network
ç‰ˆæœ¬ç‰¹æ€§:
1. é›†æˆ Bi-FGF (åŒå‘äº’å¯¼) æ¨¡å—
2. ç§»é™¤ MFAM ç“¶é¢ˆå±‚ï¼Œé‡‡ç”¨è½»é‡åŒ–èåˆ
3. Edge Head ä½¿ç”¨è¯­ä¹‰æ¸…æ´—åçš„é¢‘ç‡ç‰¹å¾
4. å®Œå…¨å¤åˆ» Up_PHD æ¥å£
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import sys
from pathlib import Path

# ================================================================
# 0. åŠ¨æ€å¯¼å…¥ä¾èµ– (ä¿æŒåŸæœ‰ç›®å½•ç»“æ„çš„å…¼å®¹æ€§)
# ================================================================

# å°è¯•å¯¼å…¥ PHD è§£ç å™¨æ ¸å¿ƒå—
try: 
    from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError: 
    try: 
        from unet.hybrid_decoder import PHD_DecoderBlock
    except ImportError: 
        PHD_DecoderBlock = None
        print("Warning: PHD_DecoderBlock import failed.")

# å°è¯•å¯¼å…¥ Mamba (ç”¨äºå³è·¯)
try: 
    from decoder.mamba_helper import MambaLayer2D
except ImportError: 
    try: 
        from unet.mamba_helper import MambaLayer2D
    except ImportError: 
        MambaLayer2D = None
        print("Warning: MambaLayer2D import failed, using Identity.")

# ================================================================
# 1. åŸºç¡€å·¥å…·ç±» (Haar å°æ³¢) - ä¿æŒä¸å˜
# ================================================================

class HaarWaveletTransform(nn.Module):
    def __init__(self):
        super().__init__()
        ll = torch.tensor([[0.5, 0.5], [0.5, 0.5]])
        lh = torch.tensor([[-0.5, -0.5], [0.5, 0.5]])
        hl = torch.tensor([[-0.5, 0.5], [-0.5, 0.5]])
        hh = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1))

    def dwt(self, x):
        B, C, H, W = x.shape
        # å¶æ•°å¡«å……å¤„ç†
        if H % 2 != 0 or W % 2 != 0:
            x = F.pad(x, (0, W % 2, 0, H % 2), mode='reflect')
        filters = self.filters.repeat(C, 1, 1, 1)
        output = F.conv2d(x, filters, stride=2, groups=C)
        output = output.view(B, C, 4, output.shape[2], output.shape[3])
        return output[:, :, 0], output[:, :, 1], output[:, :, 2], output[:, :, 3]

# ================================================================
# 2. å³è·¯æ ¸å¿ƒæ¨¡å— (WaveletMamba) - ä¿æŒä¸å˜
# ================================================================

class WaveletMambaBlock(nn.Module):
    """ å³è·¯ï¼šå°æ³¢-Mamba ç¼–ç å™¨å— """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.dwt = HaarWaveletTransform()
        
        # LL (ä½é¢‘): Mamba æ•æ‰å…¨å±€ç»“æ„
        self.low_process = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            MambaLayer2D(dim=out_channels) if MambaLayer2D else nn.Identity()
        )
        
        # High (é«˜é¢‘): Conv æ•æ‰å±€éƒ¨è¾¹ç¼˜
        self.high_process = nn.Sequential(
            nn.Conv2d(in_channels * 3, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        # èåˆ
        self.fusion = nn.Conv2d(out_channels * 2, out_channels, 1)

    def forward(self, x):
        ll, lh, hl, hh = self.dwt.dwt(x)
        ll_feat = self.low_process(ll)
        high_cat = torch.cat([lh, hl, hh], dim=1)
        high_feat = self.high_process(high_cat)
        out = self.fusion(torch.cat([ll_feat, high_feat], dim=1))
        return out

# ================================================================
# 3. [ğŸ”¥æ ¸å¿ƒå‡çº§] Bi-FGF åŒå‘äº’å¯¼æ¨¡å—
#    å­¦æœ¯å¯¹æ ‡: RSBuilding (2024)
# ================================================================

class Bi_FGF_Module(nn.Module):
    """ 
    Bi-Directional Frequency-Guided Fusion 
    åŒå‘äº’å¯¼é¢‘ç‡èåˆæ¨¡å—
    """
    def __init__(self, s_channels, f_channels):
        super().__init__()
        
        # --- Path 1: Freq -> Spatial (é¢‘ç‡æ¸…æ´—è¯­ä¹‰) ---
        # åˆ©ç”¨è¾¹ç¼˜ä¿¡æ¯ (Freq) ç”Ÿæˆ Attentionï¼Œå»é™¤ Spatial ä¸­çš„å¹³å¦èƒŒæ™¯å™ªå£°
        self.freq_gate = nn.Sequential(
            nn.Conv2d(f_channels, 1, kernel_size=1),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        # é¢‘ç‡ç‰¹å¾æ³¨å…¥å¯¹é½
        self.freq_align = nn.Conv2d(f_channels, s_channels, kernel_size=1)

        # --- Path 2: Spatial -> Freq (è¯­ä¹‰æŠ‘åˆ¶é¢‘ç‡) ---
        # åˆ©ç”¨è¯­ä¹‰ç½®ä¿¡åº¦ (Spatial) ç”Ÿæˆ Attentionï¼Œå»é™¤ Freq ä¸­çš„è™šå‡çº¹ç†(å¦‚æ³¢çº¹)
        self.spatial_gate = nn.Sequential(
            nn.Conv2d(s_channels, 1, kernel_size=1),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        # è¯­ä¹‰ç‰¹å¾æ³¨å…¥å¯¹é½
        self.spatial_align = nn.Conv2d(s_channels, f_channels, kernel_size=1)

    def forward(self, x_s, x_f):
        # å¦‚æœå°ºå¯¸ä¸åŒ¹é…(é€šå¸¸ä¸ä¼šå‘ç”Ÿï¼Œä½†ä¸ºäº†é²æ£’æ€§)
        if x_f.shape[2:] != x_s.shape[2:]:
            x_f = F.interpolate(x_f, size=x_s.shape[2:], mode='bilinear', align_corners=False)

        # 1. æ­£å‘å¼•å¯¼ (Freq -> Spatial)
        # é€»è¾‘: è¯­ä¹‰ç‰¹å¾ * è¾¹ç¼˜æƒé‡ + é¢‘ç‡ç»†èŠ‚è¡¥å……
        att_map_f2s = self.freq_gate(x_f)
        s_out = (x_s * att_map_f2s) + self.freq_align(x_f)

        # 2. åå‘å¼•å¯¼ (Spatial -> Freq)
        # é€»è¾‘: é¢‘ç‡ç‰¹å¾ * è¯­ä¹‰æƒé‡ + è¯­ä¹‰ä¸Šä¸‹æ–‡è¡¥å……
        att_map_s2f = self.spatial_gate(x_s)
        f_out = (x_f * att_map_s2f) + self.spatial_align(x_s)

        return s_out, f_out
# ================================================================
# ğŸ”¥ [æ–°å¢] SK-Fusion: æ¶¨ç‚¹ç¥å™¨
# ================================================================
class SK_Fusion(nn.Module):
    """
    Selective Kernel Fusion (SK-Fusion)
    ä½œç”¨: åŠ¨æ€å­¦ä¹  Semanticæµ å’Œ Frequencyæµ çš„èåˆæƒé‡
    è¾“å…¥: ä¸¤ä¸ªç»´åº¦ç›¸åŒçš„ç‰¹å¾å›¾ x_s, x_f
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.d = max(channels // reduction, 32)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, self.d),
            nn.BatchNorm1d(self.d),
            nn.ReLU(inplace=True)
        )
        self.fc_selection = nn.Linear(self.d, channels * 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x_s, x_f):
        B, C, H, W = x_s.shape
        # 1. åˆå§‹å åŠ 
        U = x_s + x_f
        # 2. å…¨å±€æè¿°ç¬¦
        s = self.avg_pool(U).view(B, C)
        # 3. å‹ç¼©æ¿€åŠ±
        z = self.fc(s)
        # 4. ç”Ÿæˆç«äº‰æƒé‡
        weights = self.fc_selection(z).view(B, 2, C)
        weights = self.softmax(weights)
        # 5. åŠ æƒèåˆ
        w_s = weights[:, 0, :].view(B, C, 1, 1)
        w_f = weights[:, 1, :].view(B, C, 1, 1)
        return (x_s * w_s) + (x_f * w_f)
# ================================================================
# 4. [é€‚é…å™¨] Up_PHD - å®Œå…¨å¤åˆ»åŸä»£ç 
# ================================================================

class Up_PHD(nn.Module):
    """
    è´Ÿè´£ï¼šä¸Šé‡‡æ · -> Paddingå¯¹é½ -> æ‹¼æ¥ -> è°ƒç”¨ PHD_DecoderBlock
    """
    def __init__(self, in_channels, out_channels, bilinear=True, skip_channels=0, 
                 use_dcn=False, use_dubm=False, use_strg=False):
        super().__init__()
        
        # 1. å®šä¹‰ä¸Šé‡‡æ ·
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            conv_in_channels = in_channels + skip_channels
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            conv_in_channels = (in_channels // 2) + skip_channels

        # 2. æ ¸å¿ƒï¼šè°ƒç”¨ PHD_DecoderBlock
        self.conv = PHD_DecoderBlock(in_channels=conv_in_channels, out_channels=out_channels, 
                                     use_dcn=use_dcn, use_dubm=use_dubm)

    def forward(self, x1, x2=None, edge_prior=None):
        # x1: æ·±å±‚ç‰¹å¾ (éœ€è¦ä¸Šé‡‡æ ·)
        # x2: æµ…å±‚ Skip ç‰¹å¾ (éœ€è¦æ‹¼æ¥)
        
        x1 = self.up(x1)
        
        if x2 is not None:
            # Padding å¯¹é½
            diffY = x2.size()[2] - x1.size()[2]
            diffX = x2.size()[3] - x1.size()[3]
            if diffX != 0 or diffY != 0:
                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])
            
            # æ‹¼æ¥
            x = torch.cat([x2, x1], dim=1)
        else:
            x = x1
        
        # è°ƒç”¨ PHD Block
        return self.conv(x, edge_prior=edge_prior)

# ================================================================
# 5. S_DMFNet ä¸»æ¨¡å‹ (Bi-FGF ç‰ˆ)
# ================================================================

class S_DMFNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True, 
                 encoder_name='cnextv2', cnext_type='convnextv2_base', # æ¨è Base
                 decoder_name='phd', use_dcn=True,
                 # æ¥æ”¶å…¼å®¹å‚æ•°
                 use_dsis=False, use_dual_stream=False, use_wavelet_denoise=False, 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, 
                 use_dubm=False, use_strg=False, **kwargs):
        super(S_DMFNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        
        print(f"ğŸš€ [S-DMFNet Pro] åˆå§‹åŒ–... Encoder: {cnext_type}, Decoder: {decoder_name}")
        print(f"   âœ¨ Features: Bi-FGF (Enabled), MFAM (Removed), EdgeHead (Enhanced)")

        # --- 1. å·¦è·¯: Spatial Encoder (ConvNeXt V2 Base) ---
        backbone_name = cnext_type if cnext_type else 'convnextv2_base'
        self.spatial_encoder = timm.create_model(backbone_name, pretrained=True, features_only=True, out_indices=(0, 1, 2, 3))
        s_dims = self.spatial_encoder.feature_info.channels() 
        self.dims = s_dims

        # --- 2. å³è·¯: Frequency Encoder (é€šé“æ•° 1/4) ---
        f_dims = [c // 4 for c in s_dims]
        self.freq_stem = nn.Sequential(
            nn.Conv2d(3, f_dims[0], 4, stride=4, padding=0),
            nn.BatchNorm2d(f_dims[0]),
            nn.ReLU(inplace=True)
        )
        self.freq_layers = nn.ModuleList()
        for i in range(3):
            self.freq_layers.append(WaveletMambaBlock(f_dims[i], f_dims[i+1]))
        self.freq_stage4 = WaveletMambaBlock(f_dims[3], f_dims[3])

        # --- 3. [å‡çº§] äº¤äº’: Bi-FGF Modules ---
        # æ›¿æ¢äº†åŸæ¥çš„ FGF_Module
        self.bi_fgf_modules = nn.ModuleList([Bi_FGF_Module(s_dims[i], f_dims[i]) for i in range(4)])

        # --- 4. ğŸ”¥ [æ–°å¢] Fusion: SK-Fusion ---
        # ä¸ºæ¯ä¸€å±‚(åŒ…æ‹¬ç“¶é¢ˆå±‚)å‡†å¤‡ä¸€ä¸ª SK èåˆæ¨¡å—
        self.sk_fusions = nn.ModuleList([
            SK_Fusion(s_dims[0]), # Layer 1
            SK_Fusion(s_dims[1]), # Layer 2
            SK_Fusion(s_dims[2]), # Layer 3
            SK_Fusion(s_dims[3])  # Layer 4 (Neck)
        ])
        
        # ä¿ç•™å¯¹é½å±‚ (ä¸ºäº†å°† f å¯¹é½åˆ° sï¼Œä¾› SK-Fusion ä½¿ç”¨)
        # æ³¨æ„ï¼šå…¶å® Bi-FGF é‡Œå·²ç»æœ‰å¯¹é½å±‚äº†ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç”¨ Bi-FGF é‡Œçš„å‚æ•°ï¼Œ
        # ä½†ä¸ºäº†é€»è¾‘æ¸…æ™°ï¼ŒSK-Fusion ä¹‹å‰æˆ‘ä»¬è°ƒç”¨ Bi-FGF é‡Œçš„ freq_align å³å¯ï¼Œä¸éœ€è¦é¢å¤–å®šä¹‰ã€‚

        # --- 5. è§£ç å™¨: ä½¿ç”¨ Up_PHD åŒ…è£…å™¨ ---
        c1, c2, c3, c4 = s_dims
        
        # Up 1: x4_fused + s3
        self.up1 = Up_PHD(c4, c3, bilinear, skip_channels=c3, use_dcn=use_dcn, use_dubm=use_dubm)
        # Up 2: d1 + s2
        self.up2 = Up_PHD(c3, c2, bilinear, skip_channels=c2, use_dcn=use_dcn, use_dubm=use_dubm)
        # Up 3: d2 + s1
        self.up3 = Up_PHD(c2, c1, bilinear, skip_channels=c1, use_dcn=use_dcn, use_dubm=use_dubm)
        
        self.final_up = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)
        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)

        # --- 6. [å¢å¼º] è¾¹ç¼˜é¢„æµ‹å¤´ ---
        # è¾“å…¥ç»´åº¦ä¾ç„¶æ˜¯ f_dims[0]ï¼Œä½†ä¼ å…¥çš„å†…å®¹å°†æ˜¯è¢«è¯­ä¹‰æ¸…æ´—è¿‡çš„ç‰¹å¾
        self.edge_head = nn.Sequential(
            nn.Conv2d(f_dims[0], 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1)
        )

    def forward(self, x):
        # === Encoder ===
        s_feats = list(self.spatial_encoder(x)) # [s1, s2, s3, s4]
        
        f_feats = []
        f_curr = self.freq_stem(x)
        f_feats.append(f_curr) # f1
        for layer in self.freq_layers:
            f_curr = layer(f_curr)
            f_feats.append(f_curr) # f2, f3, f4
        f_feats[-1] = self.freq_stage4(f_feats[-1])

        # === Interaction (Bi-FGF) ===
        s_clean = []    # ç”¨äºè·³è·ƒè¿æ¥
        f_enhanced = [] # ç”¨äºè¾¹ç¼˜ç›‘ç£å’Œæ·±å±‚èåˆ
        
        for i in range(4):
            # ğŸ”¥ Bi-FGF åŒå‘äº’æ´—
            s_new, f_new = self.bi_fgf_modules[i](s_feats[i], f_feats[i])
            s_clean.append(s_new)
            f_enhanced.append(f_new)
            
        s1, s2, s3, x4 = s_clean
        f1_enh, f2_enh, f3_enh, f4_enh = f_enhanced

        # === Neck (SK-Fusion) ===
        # 1. å¤ç”¨ Bi-FGF ä¸­çš„å¯¹é½å±‚ï¼ŒæŠŠ f4 å˜æˆ s4 çš„é€šé“æ•°
        f4_aligned = self.bi_fgf_modules[3].freq_align(f4_enh)
        # 2. SK-Fusion: æ™ºèƒ½èåˆè¯­ä¹‰å’Œé¢‘ç‡
        x4_fused = self.sk_fusions[3](x4, f4_aligned)

        # === Decoder (å¸¦ SK-Fusion è·³è·ƒè¿æ¥) ===
        
        # Layer 3 Skip
        f3_aligned = self.bi_fgf_modules[2].freq_align(f3_enh)
        skip3 = self.sk_fusions[2](s3, f3_aligned) # ğŸ”¥ SK èåˆ
        d1 = self.up1(x4_fused, skip3)
        
        # Layer 2 Skip
        f2_aligned = self.bi_fgf_modules[1].freq_align(f2_enh)
        skip2 = self.sk_fusions[1](s2, f2_aligned) # ğŸ”¥ SK èåˆ
        d2 = self.up2(d1, skip2)
        
        # Layer 1 Skip
        f1_aligned = self.bi_fgf_modules[0].freq_align(f1_enh)
        skip1 = self.sk_fusions[0](s1, f1_aligned) # ğŸ”¥ SK èåˆ
        d3 = self.up3(d2, skip1)
        
        d4 = self.final_up(d3)
        logits = self.outc(d4)
        
        # === Auxiliary Output ===
        if self.training:
            # ğŸ”¥ å…³é”®æ”¹è¿›: ä½¿ç”¨ f_enhanced[0] è€Œä¸æ˜¯ f_feats[0]
            # è¿™é‡Œé€å…¥ Edge Head çš„ç‰¹å¾å·²ç»è¢« s1 (è¯­ä¹‰æµ) æ¸…æ´—è¿‡ï¼Œ
            # æŠ‘åˆ¶äº†æ°´æ³¢çº¹/æ–‘é©¬çº¿ç­‰ä¼ªè¾¹ç¼˜ï¼ŒLoss è®¡ç®—æ›´å‡†ã€‚
            edge_logits_small = self.edge_head(f_enhanced[0])
            edge_logits = F.interpolate(edge_logits_small, size=logits.shape[2:], mode='bilinear', align_corners=True)
            
            return logits, edge_logits
            
        return logits