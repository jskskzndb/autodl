"""
unet/unet_s_dmfnet.py
[S-DMFNet Pro] Enhanced Dual-Stream Mutual-Guided Frequency-Aware Network
ç‰ˆæœ¬ç‰¹æ€§:
1. é›†æˆ Bi-FGF (åŒå‘äº’å¯¼) æ¨¡å—
2. ç§»é™¤ MFAM ç“¶é¢ˆå±‚ï¼Œé‡‡ç”¨è½»é‡åŒ–èåˆ
3. Edge Head ä½¿ç”¨è¯­ä¹‰æ¸…æ´—åçš„é¢‘ç‡ç‰¹å¾
4. å®Œå…¨å¤åˆ» Up_PHD æ¥å£
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import sys
from pathlib import Path

# ================================================================
# 0. åŠ¨æ€å¯¼å…¥ä¾èµ– (ä¿æŒåŸæœ‰ç›®å½•ç»“æ„çš„å…¼å®¹æ€§)
# ================================================================

# å°è¯•å¯¼å…¥ PHD è§£ç å™¨æ ¸å¿ƒå—
try: 
    from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError: 
    try: 
        from unet.hybrid_decoder import PHD_DecoderBlock
    except ImportError: 
        PHD_DecoderBlock = None
        print("Warning: PHD_DecoderBlock import failed.")

# å°è¯•å¯¼å…¥ Mamba (ç”¨äºå³è·¯)
try: 
    from decoder.mamba_helper import MambaLayer2D
except ImportError: 
    try: 
        from unet.mamba_helper import MambaLayer2D
    except ImportError: 
        MambaLayer2D = None
        print("Warning: MambaLayer2D import failed, using Identity.")

# ================================================================
# 1. åŸºç¡€å·¥å…·ç±» (Haar å°æ³¢) - ä¿æŒä¸å˜
# ================================================================

class HaarWaveletTransform(nn.Module):
    def __init__(self):
        super().__init__()
        ll = torch.tensor([[0.5, 0.5], [0.5, 0.5]])
        lh = torch.tensor([[-0.5, -0.5], [0.5, 0.5]])
        hl = torch.tensor([[-0.5, 0.5], [-0.5, 0.5]])
        hh = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1))

    def dwt(self, x):
        B, C, H, W = x.shape
        # å¶æ•°å¡«å……å¤„ç†
        if H % 2 != 0 or W % 2 != 0:
            x = F.pad(x, (0, W % 2, 0, H % 2), mode='reflect')
        filters = self.filters.repeat(C, 1, 1, 1)
        output = F.conv2d(x, filters, stride=2, groups=C)
        output = output.view(B, C, 4, output.shape[2], output.shape[3])
        return output[:, :, 0], output[:, :, 1], output[:, :, 2], output[:, :, 3]
    

class InverseHaarWaveletTransform(nn.Module):
    """
    å°æ³¢é€†å˜æ¢ (IDWT)
    å°† LL, LH, HL, HH å››ä¸ªåˆ†é‡è¿˜åŸå›ç©ºé—´å›¾åƒå°ºå¯¸ (2x)
    """
    def __init__(self):
        super().__init__()
        # å®šä¹‰é€†å˜æ¢çš„å·ç§¯æ ¸ (åŸºäº Haar å°æ³¢å®šä¹‰)
        # è¿™é‡Œçš„æƒé‡æ˜¯ä¸ºäº†é…åˆ Forward çš„ 0.5 ç³»æ•°è¿›è¡Œè¿˜åŸ
        ll = torch.tensor([[1.0, 1.0], [1.0, 1.0]])
        lh = torch.tensor([[-1.0, -1.0], [1.0, 1.0]])
        hl = torch.tensor([[-1.0, 1.0], [-1.0, 1.0]])
        hh = torch.tensor([[1.0, -1.0], [-1.0, 1.0]])
        
        # ä½¿ç”¨ Transposed Conv æ¥å®ç°ä¸Šé‡‡æ ·+æ±‚å’Œ
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1) / 2.0)

    def idwt(self, ll, lh, hl, hh):
        # è¾“å…¥: [B, C, H, W] * 4
        # è¾“å‡º: [B, C, 2H, 2W]
        B, C, H, W = ll.shape
        # å°† 4 ä¸ªåˆ†é‡æ‹¼æ¥ä¸º [B, 4C, H, W]
        x = torch.cat([ll, lh, hl, hh], dim=1)
        # ä½¿ç”¨ Group ConvTranspose2d è¿›è¡Œç‹¬ç«‹é€šé“çš„é€†å˜æ¢
        # groups=C ä¿è¯æ¯ä¸ªé€šé“ç‹¬ç«‹è¿˜åŸ
        out = F.conv_transpose2d(
            x, 
            self.filters.repeat(C, 1, 1, 1), 
            stride=2, 
            groups=C
        )
        return out
# ================================================================
# 2. å³è·¯æ ¸å¿ƒæ¨¡å— (WaveletMamba) - ä¿æŒä¸å˜
# ================================================================

class WaveletMambaBlock(nn.Module):
    """ 
    [Modified] High-Frequency Aware Mamba
    åŠ¨æœºï¼šåˆ©ç”¨ Mamba çš„é•¿åºåˆ—èƒ½åŠ›ï¼Œä¿®å¤é«˜é¢‘åˆ†é‡ä¸­ä¸è¿ç»­çš„å»ºç­‘ç‰©è¾¹ç¼˜
    """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.dwt = HaarWaveletTransform()
        self.idwt = InverseHaarWaveletTransform() # ğŸ”¥ æ–°å¢é€†å˜æ¢
        # 1. Low Freq (LL): ä½¿ç”¨æ™®é€šå·ç§¯æ•æ‰ç²—ç•¥ç»“æ„
        self.low_process = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # 2. High Freq (LH+HL+HH): ä½¿ç”¨ Mamba è¿›è¡Œå…¨å±€è¾¹ç¼˜è¿é€šæ€§å»ºæ¨¡
        # è¾“å…¥ç»´åº¦æ˜¯ in_channels * 3
        self.high_process = nn.Sequential(
            nn.Conv2d(in_channels * 3, out_channels, 1), # é™ç»´å¯¹é½
            nn.BatchNorm2d(out_channels),
            # ğŸ”¥ Mamba æ”¾è¿™é‡Œï¼å¤„ç†é«˜é¢‘è¾¹ç¼˜
            MambaLayer2D(dim=out_channels) if MambaLayer2D else nn.Identity() 
        )
        # ğŸ”¥ [æ–°å¢] é«˜é¢‘æ¢å¤å±‚ï¼šæŠŠ Mamba èåˆåçš„ 1è·¯é«˜é¢‘ æ‹†å› 3è·¯ (LH, HL, HH)
        self.high_restore = nn.Conv2d(out_channels, out_channels * 3, 1)
        # ğŸ”¥ [æ–°å¢] äº¤äº’å¯¹é½å±‚ï¼šIDWT åå°ºå¯¸å˜å¤§ 2å€ï¼Œéœ€è¦ä¸‹é‡‡æ ·å›åŸå°ºå¯¸ä»¥ä¾¿äº¤äº’
        # ä¸ºä»€ä¹ˆï¼Ÿå› ä¸º s_feats[i] çš„å°ºå¯¸å’Œå½“å‰çš„ out_next æ˜¯ä¸€æ ·çš„ã€‚
        # IDWT å˜å¤§åå¦‚æœä¸ç¼©å›æ¥ï¼Œå°±æ²¡æ³•å’Œ ConvNeXt åˆ†æ”¯å¯¹åº”å±‚äº¤äº’äº†ã€‚
        self.inter_downsample = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        # 3. èåˆ
        self.fusion = nn.Conv2d(out_channels * 2, out_channels, 1)

    def forward(self, x):
        # 1. DWT åˆ†è§£
        ll, lh, hl, hh = self.dwt.dwt(x)
        
        # 2. å¤„ç†
        ll_feat = self.low_process(ll)
        high_cat = torch.cat([lh, hl, hh], dim=1)
        high_feat = self.high_process(high_cat) # [B, C, H/2, W/2]
        
        # === è·¯ 1: ä¼ ç»™ä¸‹ä¸€å±‚ (ä¿æŒç°çŠ¶ï¼Œæ‹¼æ¥èåˆ) ===
        out_next = self.fusion(torch.cat([ll_feat, high_feat], dim=1))
        
        # === è·¯ 2: å»äº¤äº’ (IDWT è¿˜åŸç©ºé—´åŸŸ) ===
        # A. æŠŠ Mamba å¤„ç†å®Œçš„é«˜é¢‘ç‰¹å¾ï¼Œå°è¯•æ‹†è§£å› 3 ä¸ªåˆ†é‡
        high_restored = self.high_restore(high_feat)
        lh_rec, hl_rec, hh_rec = torch.chunk(high_restored, 3, dim=1)
        
        # B. æ‰§è¡Œ IDWT (å°ºå¯¸å˜å¤§ 2å€: H/2 -> H)
        # è¿™é‡Œåˆ©ç”¨äº† IDWT çš„å½’çº³åç½®ï¼ŒæŠŠç‰¹å¾å˜å›â€œç±»å›¾åƒâ€ç»“æ„
        out_spatial_large = self.idwt.idwt(ll_feat, lh_rec, hl_rec, hh_rec)
        
        # C. å†æ¬¡ä¸‹é‡‡æ · (H -> H/2) ä»¥åŒ¹é… ConvNeXt å¯¹åº”å±‚çš„å°ºå¯¸
        out_inter = self.inter_downsample(out_spatial_large)
        
        # è¿”å›ä¸¤ä¸ªï¼šä¸€ä¸ªå»ä¸‹ä¸€å±‚ï¼Œä¸€ä¸ªå»äº¤äº’
        return out_next, out_inter
# ================================================================
# 3. [ğŸ”¥æ ¸å¿ƒå‡çº§] Bi-FGF åŒå‘äº’å¯¼æ¨¡å—
#    å­¦æœ¯å¯¹æ ‡: RSBuilding (2024)
# ================================================================

class Cross_GL_FGF(nn.Module):
    """
    [SOTAçº§äº¤äº’] Cross Global-Local Frequency-Guided Fusion
    è®ºæ–‡å›¾ç¤ºï¼šX-Structure (Serial)
    é€»è¾‘ï¼šGlobal Channel Gating (Denoise) -> Local Spatial Gating (Align) -> Injection (Fusion)
    """
    def __init__(self, s_channels, f_channels, reduction=16):
        super().__init__()
        
        # å®‰å…¨è®¡ç®—éšè—å±‚ç»´åº¦
        s_mid = max(s_channels // reduction, 4)
        f_mid = max(f_channels // reduction, 4)

        # --- Stage 1: Global Channel Interaction (å®è§‚å»å™ª) ---
        self.gap = nn.AdaptiveAvgPool2d(1)
        
        # S -> F (è¯­ä¹‰æŒ‡å¯¼é¢‘ç‡ï¼šå»å™ª)
        self.mlp_s2f = nn.Sequential(
            nn.Linear(s_channels, f_mid, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(f_mid, f_channels, bias=False),
            nn.Sigmoid()
        )
        # F -> S (é¢‘ç‡æŒ‡å¯¼è¯­ä¹‰ï¼šå…³æ³¨ç»†èŠ‚)
        self.mlp_f2s = nn.Sequential(
            nn.Linear(f_channels, s_mid, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(s_mid, s_channels, bias=False),
            nn.Sigmoid()
        )

        # --- Stage 2: Local Spatial Interaction (å¾®è§‚ç²¾ä¿®) ---
        self.spatial_conv_s2f = nn.Sequential(
            nn.Conv2d(s_channels, 1, kernel_size=7, padding=3, bias=False),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        self.spatial_conv_f2s = nn.Sequential(
            nn.Conv2d(f_channels, 1, kernel_size=7, padding=3, bias=False),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )

        # --- Stage 3: Feature Injection (ç‰¹å¾èåˆ) ---
        self.s_align = nn.Conv2d(s_channels, f_channels, 1)
        self.f_align = nn.Conv2d(f_channels, s_channels, 1)
        
        # Zero-Init: ä¿è¯è®­ç»ƒåˆæœŸäº’ä¸å¹²æ‰°
        nn.init.constant_(self.s_align.weight, 0)
        nn.init.constant_(self.s_align.bias, 0)
        nn.init.constant_(self.f_align.weight, 0)
        nn.init.constant_(self.f_align.bias, 0)
        
        # æœ€ç»ˆèåˆå·ç§¯ (Concatenate -> Conv)
        self.fusion_conv = nn.Sequential(
            nn.Conv2d(s_channels * 2, s_channels, 1),
            nn.BatchNorm2d(s_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x_s, x_f):
        B, Cs, H, W = x_s.shape
        _, Cf, _, _ = x_f.shape
        
        # å°ºå¯¸å¯¹é½
        if x_f.shape[2:] != x_s.shape[2:]:
            x_f = F.interpolate(x_f, size=(H, W), mode='bilinear', align_corners=False)

        # 1. å…¨å±€å»å™ª (Channel Gating)
        s_vec = self.gap(x_s).view(B, Cs)
        f_vec = self.gap(x_f).view(B, Cf)
        w_s2f = self.mlp_s2f(s_vec).view(B, Cf, 1, 1) 
        w_f2s = self.mlp_f2s(f_vec).view(B, Cs, 1, 1) 
        f_clean = x_f * w_s2f
        s_clean = x_s * w_f2s
        
        # 2. å±€éƒ¨ç²¾ä¿® (Spatial Attention)
        m_s2f = self.spatial_conv_s2f(s_clean) 
        m_f2s = self.spatial_conv_f2s(f_clean)
        f_refined = f_clean * m_s2f + f_clean
        s_refined = s_clean * m_f2s + s_clean

        # 3. äº¤å‰èåˆ (Fusion for Skip)
        # å°† F å¯¹é½å¹¶æ³¨å…¥
        f_injected = self.f_align(f_refined)
        # æ‹¼æ¥ + å·ç§¯èåˆ (ç”Ÿæˆè·³è·ƒè¿æ¥ç‰¹å¾)
        out = self.fusion_conv(torch.cat([s_refined, f_injected], dim=1))
        
        # è¿”å›: (è·³è·ƒè¿æ¥ç‰¹å¾, å¢å¼ºåçš„é¢‘ç‡ç‰¹å¾)
        return out, f_refined
# ================================================================
# ğŸ”¥ [æ–°å¢] SK-Fusion: æ¶¨ç‚¹ç¥å™¨
# ================================================================
class SK_Fusion(nn.Module):
    """
    Selective Kernel Fusion (SK-Fusion)
    ä½œç”¨: åŠ¨æ€å­¦ä¹  Semanticæµ å’Œ Frequencyæµ çš„èåˆæƒé‡
    è¾“å…¥: ä¸¤ä¸ªç»´åº¦ç›¸åŒçš„ç‰¹å¾å›¾ x_s, x_f
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.d = max(channels // reduction, 32)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, self.d),
            nn.BatchNorm1d(self.d),
            nn.ReLU(inplace=True)
        )
        self.fc_selection = nn.Linear(self.d, channels * 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x_s, x_f):
        B, C, H, W = x_s.shape
        # 1. åˆå§‹å åŠ 
        U = x_s + x_f
        # 2. å…¨å±€æè¿°ç¬¦
        s = self.avg_pool(U).view(B, C)
        # 3. å‹ç¼©æ¿€åŠ±
        z = self.fc(s)
        # 4. ç”Ÿæˆç«äº‰æƒé‡
        weights = self.fc_selection(z).view(B, 2, C)
        weights = self.softmax(weights)
        # 5. åŠ æƒèåˆ
        w_s = weights[:, 0, :].view(B, C, 1, 1)
        w_f = weights[:, 1, :].view(B, C, 1, 1)
        return (x_s * w_s) + (x_f * w_f)
# ================================================================
# 4. [é€‚é…å™¨] Up_PHD - å®Œå…¨å¤åˆ»åŸä»£ç 
# ================================================================

class Up_PHD(nn.Module):
    """
    è´Ÿè´£ï¼šä¸Šé‡‡æ · -> Paddingå¯¹é½ -> æ‹¼æ¥ -> è°ƒç”¨ PHD_DecoderBlock
    """
    def __init__(self, in_channels, out_channels, bilinear=True, skip_channels=0, 
                 use_dcn=False, use_dubm=False, use_strg=False):
        super().__init__()
        
        # 1. å®šä¹‰ä¸Šé‡‡æ ·
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            conv_in_channels = in_channels + skip_channels
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            conv_in_channels = (in_channels // 2) + skip_channels

        # 2. æ ¸å¿ƒï¼šè°ƒç”¨ PHD_DecoderBlock
        self.conv = PHD_DecoderBlock(in_channels=conv_in_channels, out_channels=out_channels, 
                                     use_dcn=use_dcn, use_dubm=use_dubm)

    def forward(self, x1, x2=None, edge_prior=None):
        # x1: æ·±å±‚ç‰¹å¾ (éœ€è¦ä¸Šé‡‡æ ·)
        # x2: æµ…å±‚ Skip ç‰¹å¾ (éœ€è¦æ‹¼æ¥)
        
        x1 = self.up(x1)
        
        if x2 is not None:
            # Padding å¯¹é½
            diffY = x2.size()[2] - x1.size()[2]
            diffX = x2.size()[3] - x1.size()[3]
            if diffX != 0 or diffY != 0:
                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])
            
            # æ‹¼æ¥
            x = torch.cat([x2, x1], dim=1)
        else:
            x = x1
        
        # è°ƒç”¨ PHD Block
        return self.conv(x, edge_prior=edge_prior)

# ================================================================
# 5. S_DMFNet ä¸»æ¨¡å‹ (Refined)
# ================================================================

class S_DMFNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True, 
                 encoder_name='cnextv2', cnext_type='convnextv2_base', # æ¨è Base
                 decoder_name='phd', use_dcn=True,
                 # æ¥æ”¶å…¼å®¹å‚æ•°
                 use_dsis=False, use_dual_stream=False, use_wavelet_denoise=False, 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, 
                 use_dubm=False, use_strg=False, **kwargs):
        super(S_DMFNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        
        print(f"ğŸš€ [S-DMFNet Pro] Rebuttal Version | Encoder: {cnext_type}")
        print(f"   âœ¨ Features: Cross-GL-FGF (SOTA Interaction), High-Freq Mamba, No SK-Fusion")

        # --- 1. å·¦è·¯: Spatial Encoder (ConvNeXt V2 Base) ---
        backbone_name = cnext_type if cnext_type else 'convnextv2_base'
        self.spatial_encoder = timm.create_model(backbone_name, pretrained=True, features_only=True, out_indices=(0, 1, 2, 3))
        s_dims = self.spatial_encoder.feature_info.channels() 
        self.dims = s_dims

        # --- 2. å³è·¯: Frequency Encoder (é€šé“æ•° 1/4) ---
        f_dims = [c // 4 for c in s_dims]
        self.freq_stem = nn.Sequential(
            nn.Conv2d(3, f_dims[0], 4, stride=4, padding=0),
            nn.BatchNorm2d(f_dims[0]),
            nn.ReLU(inplace=True)
        )
        self.freq_layers = nn.ModuleList()
        for i in range(3):
            self.freq_layers.append(WaveletMambaBlock(f_dims[i], f_dims[i+1]))
        self.freq_stage4 = WaveletMambaBlock(f_dims[3], f_dims[3])

        # --- 3. [å‡çº§] äº¤äº’: Cross_GL_FGF Modules ---
        self.bi_fgf_modules = nn.ModuleList([Cross_GL_FGF(s_dims[i], f_dims[i]) for i in range(4)])

        
        # --- 5. è§£ç å™¨: ä½¿ç”¨ Up_PHD åŒ…è£…å™¨ ---
        c1, c2, c3, c4 = s_dims
        
        # Up 1: x4_fused + s3
        self.up1 = Up_PHD(c4, c3, bilinear, skip_channels=c3, use_dcn=use_dcn, use_dubm=use_dubm)
        # Up 2: d1 + s2
        self.up2 = Up_PHD(c3, c2, bilinear, skip_channels=c2, use_dcn=use_dcn, use_dubm=use_dubm)
        # Up 3: d2 + s1
        self.up3 = Up_PHD(c2, c1, bilinear, skip_channels=c1, use_dcn=use_dcn, use_dubm=use_dubm)
        
        self.final_up = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)
        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)

        # --- 6. [å¢å¼º] è¾¹ç¼˜é¢„æµ‹å¤´ ---
        # è¾“å…¥ç»´åº¦ä¾ç„¶æ˜¯ f_dims[0]ï¼Œä½†ä¼ å…¥çš„å†…å®¹å°†æ˜¯è¢«è¯­ä¹‰æ¸…æ´—è¿‡çš„ç‰¹å¾
        self.edge_head = nn.Sequential(
            nn.Conv2d(f_dims[0], 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1)
        )

    def forward(self, x):
        # === Encoder ===
        s_feats = list(self.spatial_encoder(x))
        
        f_feats = []
        # Stem å±‚å¤„ç† (ä¿æŒä¸å˜)
        f_curr = self.freq_stem(x) 
        f_feats.append(f_curr) # f1 (å¯¹åº” s1)
        
        # === æ ¸å¿ƒä¿®æ”¹éƒ¨åˆ† ===
        # å¾ªç¯å¤„ç†é¢‘ç‡å±‚
        for layer in self.freq_layers:
            # ğŸ”¥ æ¥æ”¶ä¸¤ä¸ªè¾“å‡ºï¼šf_next (å»ä¸‹ä¸€å±‚), f_inter (å»äº¤äº’)
            f_next, f_inter = layer(f_curr)
            
            f_feats.append(f_inter) # å­˜å…¥å»äº¤äº’çš„ç‰¹å¾
            f_curr = f_next         # æ›´æ–°å½“å‰æµï¼Œç»§ç»­å¾€ä¸‹èµ°
            
        # å¤„ç†æœ€åä¸€å±‚ (Stage 4 é€šå¸¸æ²¡æœ‰ä¸‹ä¸€å±‚äº†ï¼Œç›´æ¥å½“åšäº¤äº’ç‰¹å¾)
        # æ³¨æ„ï¼šä½ éœ€è¦æ£€æŸ¥ freq_stage4 æ˜¯å¦ä¹Ÿéœ€è¦æ”¹æˆä¸Šé¢çš„ç»“æ„ï¼Œ
        # æˆ–è€…ç®€å•å¤„ç†ã€‚é€šå¸¸æœ€åä¸€å±‚å¯ä»¥ä¸éœ€è¦åˆ†æµï¼Œå› ä¸ºåé¢æ²¡æœ‰ä¸‹ä¸€å±‚äº†ã€‚
        # è¿™é‡Œå‡è®¾ freq_stage4 è¿˜æ˜¯åŸæ¥çš„ç»“æ„ï¼Œæˆ–è€…ä½ ä¹ŸæŠŠå®ƒæ”¹æˆæ–°çš„ Blockã€‚
        # å¦‚æœ freq_stage4 æ˜¯ WaveletMambaBlockï¼Œå®ƒä¼šè¿”å›ä¸¤ä¸ªå€¼ã€‚
        f_last_next, f_last_inter = self.freq_stage4(f_curr)
        f_feats[-1] = f_last_inter # æ›´æ–°æœ€åä¸€ä¸ªç‰¹å¾

        # === Interaction (Cross-GL-FGF) ===
        skips = []      # ç”¨äº Skip Connection
        f_enhanced = [] # ç”¨äº Edge Head
        
        for i in range(4):
            # fusion_out: èåˆåçš„ç‰¹å¾ (Skip)
            # f_out: å¢å¼ºåçš„é¢‘ç‡ç‰¹å¾ (Deep Supervision)
            fusion_out, f_out = self.bi_fgf_modules[i](s_feats[i], f_feats[i])
            skips.append(fusion_out)
            f_enhanced.append(f_out)

        s1_fused, s2_fused, s3_fused, s4_fused = skips

        # === Decoder ===
        d1 = self.up1(s4_fused, s3_fused)
        d2 = self.up2(d1, s2_fused)
        d3 = self.up3(d2, s1_fused)
        
        d4 = self.final_up(d3)
        logits = self.outc(d4)
        
        # === Auxiliary Output ===
        if self.training:
            # ğŸ”¥ [å…³é”®ä¿®æ­£] è¾“å…¥ä½¿ç”¨ f_enhanced[0] (æ¸…æ´—åçš„é¢‘ç‡ç‰¹å¾)
            # ç†ç”±ï¼šåˆ©ç”¨è¯­ä¹‰æµæŠ‘åˆ¶äº†èƒŒæ™¯çº¹ç†å™ªå£°ï¼Œä½¿è¾¹ç¼˜ç›‘ç£æ›´ç²¾å‡†
            edge_logits_small = self.edge_head(f_enhanced[0])
            edge_logits = F.interpolate(edge_logits_small, size=logits.shape[2:], mode='bilinear', align_corners=True)
            return logits, edge_logits
            
        return logits