"""
unet_s_dmfnet.py
[S-DMFNet] Simplified Dual-Stream Mutual-Guided Frequency-Aware Network     S-DMFNet V1 (Baseline) - å•å‘å¼•å¯¼ + MFAM + ç»Ÿä¸€å­¦ä¹ ç‡
å®Œå…¨å¤åˆ» unet_model_unified.py çš„è§£ç å™¨å†™æ³• (Up_PHD)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import sys
from pathlib import Path

# å°è¯•å¯¼å…¥ PHD è§£ç å™¨æ ¸å¿ƒå— (ä¿æŒå’Œä½ åŸæœ‰ä»£ç ä¸€è‡´çš„å¯¼å…¥é€»è¾‘)
try: from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError: 
    try: from unet.hybrid_decoder import PHD_DecoderBlock
    except ImportError: PHD_DecoderBlock = None

# å°è¯•å¯¼å…¥ Mamba (ç”¨äºå³è·¯)
try: from decoder.mamba_helper import MambaLayer2D
except ImportError: 
    try: from unet.mamba_helper import MambaLayer2D
    except ImportError: MambaLayer2D = None

# ================================================================
# 1. åŸºç¡€å·¥å…·ç±» (Haar å°æ³¢)
# ================================================================

class HaarWaveletTransform(nn.Module):
    def __init__(self):
        super().__init__()
        ll = torch.tensor([[0.5, 0.5], [0.5, 0.5]])
        lh = torch.tensor([[-0.5, -0.5], [0.5, 0.5]])
        hl = torch.tensor([[-0.5, 0.5], [-0.5, 0.5]])
        hh = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1))

    def dwt(self, x):
        B, C, H, W = x.shape
        if H % 2 != 0 or W % 2 != 0:
            x = F.pad(x, (0, W % 2, 0, H % 2), mode='reflect')
        filters = self.filters.repeat(C, 1, 1, 1)
        output = F.conv2d(x, filters, stride=2, groups=C)
        output = output.view(B, C, 4, output.shape[2], output.shape[3])
        return output[:, :, 0], output[:, :, 1], output[:, :, 2], output[:, :, 3]

# ================================================================
# 2. å³è·¯æ ¸å¿ƒæ¨¡å— (WaveletMamba) & äº¤äº’æ¨¡å— (FGF) & ç“¶é¢ˆ (MFAM)
# ================================================================

class WaveletMambaBlock(nn.Module):
    """ å³è·¯ï¼šå°æ³¢-Mamba ç¼–ç å™¨å— """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.dwt = HaarWaveletTransform()
        
        # LL: Mamba æ•æ‰ç»“æ„
        self.low_process = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            MambaLayer2D(dim=out_channels) if MambaLayer2D else nn.Identity()
        )
        
        # High: Conv æ•æ‰è¾¹ç¼˜
        self.high_process = nn.Sequential(
            nn.Conv2d(in_channels * 3, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        self.fusion = nn.Conv2d(out_channels * 2, out_channels, 1)

    def forward(self, x):
        ll, lh, hl, hh = self.dwt.dwt(x)
        ll_feat = self.low_process(ll)
        high_cat = torch.cat([lh, hl, hh], dim=1)
        high_feat = self.high_process(high_cat)
        out = self.fusion(torch.cat([ll_feat, high_feat], dim=1))
        return out

class FGF_Module(nn.Module):
    """ é¢‘ç‡å¼•å¯¼èåˆæ¨¡å— """
    def __init__(self, spatial_dim, freq_dim):
        super().__init__()
        self.freq_to_att = nn.Sequential(
            nn.Conv2d(freq_dim, 1, 1),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        self.align = nn.Conv2d(freq_dim, spatial_dim, 1)

    def forward(self, x_spatial, x_freq):
        if x_freq.shape[2:] != x_spatial.shape[2:]:
            x_freq = F.interpolate(x_freq, size=x_spatial.shape[2:], mode='bilinear', align_corners=False)
        att_map = self.freq_to_att(x_freq)
        x_guided = x_spatial * att_map
        return x_guided + self.align(x_freq)

class MFAM(nn.Module):
    """ æ··åˆé¢‘ç‡æ³¨æ„åŠ› (Neck) - å¤åˆ» FDENet """
    def __init__(self, in_channels):
        super().__init__()
        reduction = 4
        mid_channels = max(16, in_channels // reduction)

        self.phi_h = nn.Parameter(torch.ones(1, in_channels, 1, 1), requires_grad=True)
        self.phi_l = nn.Parameter(torch.ones(1, in_channels, 1, 1), requires_grad=True)

        self.proj_h_hor = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 3), padding=(0, 1))
        self.proj_h_ver = nn.Conv2d(in_channels, in_channels, kernel_size=(3, 1), padding=(1, 0))
        self.proj_l_hor = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 3), padding=(0, 1))
        self.proj_l_ver = nn.Conv2d(in_channels, in_channels, kernel_size=(3, 1), padding=(1, 0))
        self.gamma_h = nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.gamma_l = nn.Parameter(torch.tensor(0.5), requires_grad=True)

        self.gap = nn.AdaptiveAvgPool2d(1)
        self.fc_h = nn.Sequential(nn.Linear(in_channels, mid_channels), nn.ReLU(), nn.Linear(mid_channels, in_channels), nn.Sigmoid())
        self.fc_l = nn.Sequential(nn.Linear(in_channels, mid_channels), nn.ReLU(), nn.Linear(mid_channels, in_channels), nn.Sigmoid())
        self.alpha = nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.beta = nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.fusion_conv = nn.Conv2d(in_channels, in_channels, 1)

    def forward(self, f_spatial, f_freq):
        if f_freq.shape[2:] != f_spatial.shape[2:]:
            f_freq = F.interpolate(f_freq, size=f_spatial.shape[2:], mode='bilinear', align_corners=False)
        
        B, C, H, W = f_spatial.shape
        f_star = self.phi_h * f_freq + self.phi_l * f_spatial
        
        d_h = self.proj_h_hor(f_freq) + self.proj_h_ver(f_freq)
        d_l = self.proj_l_hor(f_spatial) + self.proj_l_ver(f_spatial)
        f_dir = self.gamma_h * d_h + self.gamma_l * d_l
        
        u_h = self.gap(f_freq).view(B, C)
        u_l = self.gap(f_spatial).view(B, C)
        w_h_c = self.fc_h(self.alpha * u_h + self.beta * u_l).view(B, C, 1, 1)
        w_l_c = self.fc_l(self.alpha * u_l + self.beta * u_h).view(B, C, 1, 1)
        w_c = 0.5 * (w_h_c + w_l_c)
        
        return f_spatial + (self.fusion_conv(f_star) + f_dir) * w_c

# ================================================================
# 3. [å…³é”®] å¤åˆ» unet_model_unified.py çš„ Up_PHD
# ================================================================

class Up_PHD(nn.Module):
    """
    å®Œå…¨å¤åˆ»ä½  unet_model_unified.py ä¸­çš„ Up_PHD ç±»
    è´Ÿè´£ï¼šä¸Šé‡‡æ · -> Paddingå¯¹é½ -> æ‹¼æ¥ -> è°ƒç”¨ PHD_DecoderBlock
    """
    def __init__(self, in_channels, out_channels, bilinear=True, skip_channels=0, 
                 use_dcn=False, use_dubm=False, use_strg=False):
        super().__init__()
        
        # 1. å®šä¹‰ä¸Šé‡‡æ ·
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            # è®¡ç®—æ‹¼æ¥åçš„æ€»é€šé“æ•°
            conv_in_channels = in_channels + skip_channels
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            conv_in_channels = (in_channels // 2) + skip_channels

        # 2. æ ¸å¿ƒï¼šè°ƒç”¨ PHD_DecoderBlock
        # è¿™é‡Œä¸éœ€è¦æ‰‹åŠ¨å¤„ç† catï¼Œå› ä¸º cat åœ¨ forward é‡Œåšå®Œåï¼Œé€šé“æ•°å°±æ˜¯ conv_in_channels
        # PHD_DecoderBlock ä¼šå¤„ç†è¿™ä¸ªç»´åº¦çš„è¾“å…¥
        self.conv = PHD_DecoderBlock(in_channels=conv_in_channels, out_channels=out_channels, 
                                     use_dcn=use_dcn, use_dubm=use_dubm)

    def forward(self, x1, x2=None, edge_prior=None):
        # x1: æ·±å±‚ç‰¹å¾ (éœ€è¦ä¸Šé‡‡æ ·)
        # x2: æµ…å±‚ Skip ç‰¹å¾ (éœ€è¦æ‹¼æ¥)
        
        x1 = self.up(x1)
        
        if x2 is not None:
            # Padding å¯¹é½ (é˜²æ­¢å¥‡æ•°å°ºå¯¸ä¸åŒ¹é…)
            diffY = x2.size()[2] - x1.size()[2]
            diffX = x2.size()[3] - x1.size()[3]
            if diffX != 0 or diffY != 0:
                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])
            
            # æ‹¼æ¥
            x = torch.cat([x2, x1], dim=1)
        else:
            x = x1
        
        # è°ƒç”¨ PHD Block (æ”¯æŒä¼  edge_prior)
        return self.conv(x, edge_prior=edge_prior)

# ================================================================
# 4. S_DMFNet ä¸»æ¨¡å‹
# ================================================================

class S_DMFNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True, 
                 encoder_name='cnextv2', cnext_type='convnextv2_base', # å¼ºåˆ¶ Base
                 decoder_name='phd', use_dcn=True,
                 # æ¥æ”¶å…¼å®¹å‚æ•°
                 use_mfam=Ture, use_dsis=False, use_dual_stream=False, use_wavelet_denoise=False, 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, 
                 use_dubm=False, use_strg=False, **kwargs):
        super(S_DMFNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        self.use_mfam = use_mfam  # <--- ğŸ”¥ [æ–°å¢] 2. ä¿å­˜å‚æ•°çŠ¶æ€
        print(f"ğŸš€ [S-DMFNet] åˆå§‹åŒ–... Encoder: {cnext_type} (Base), Decoder: {decoder_name}")

        # --- 1. å·¦è·¯: Spatial Encoder (ConvNeXt V2 Base) ---
        backbone_name = 'convnextv2_base' 
        self.spatial_encoder = timm.create_model(backbone_name, pretrained=True, features_only=True, out_indices=(0, 1, 2, 3))
        s_dims = [128, 256, 512, 1024] 
        self.dims = s_dims

        # --- 2. å³è·¯: Frequency Encoder (é€šé“æ•° 1/4) ---
        f_dims = [c // 4 for c in s_dims]
        self.freq_stem = nn.Sequential(
            nn.Conv2d(3, f_dims[0], 4, stride=4, padding=0),
            nn.BatchNorm2d(f_dims[0]),
            nn.ReLU(inplace=True)
        )
        self.freq_layers = nn.ModuleList()
        for i in range(3):
            self.freq_layers.append(WaveletMambaBlock(f_dims[i], f_dims[i+1]))
        self.freq_stage4 = WaveletMambaBlock(f_dims[3], f_dims[3])

        # --- 3. äº¤äº’: FGF Modules ---
        self.fgf_modules = nn.ModuleList([FGF_Module(s_dims[i], f_dims[i]) for i in range(4)])

        # --- 4. ç“¶é¢ˆ: MFAM ---
        self.neck_freq_align = nn.Conv2d(f_dims[-1], s_dims[-1], 1)
        self.neck_mfam = MFAM(in_channels=s_dims[-1])
        if self.use_mfam:  # <--- ğŸ”¥ [æ–°å¢] 3. åŠ åˆ¤æ–­
            self.neck_freq_align = nn.Conv2d(f_dims[-1], s_dims[-1], 1)
            self.neck_mfam = MFAM(in_channels=s_dims[-1])
            print("   âœ… MFAM (Neck) Enabled")
        else:
            print("   ğŸš« MFAM (Neck) Disabled for Ablation")
        # --- 5. è§£ç å™¨: ä½¿ç”¨ Up_PHD åŒ…è£…å™¨ (å®Œå…¨å¤åˆ»åŸä»£ç é£æ ¼) ---
        c1, c2, c3, c4 = s_dims
        
        # Up 1: x4(1024) + s3(512) -> è¾“å‡º c3(512)
        # è¿™é‡Œçš„ Up_PHD ä¼šè‡ªåŠ¨å¤„ç† x4 çš„ä¸Šé‡‡æ ·å’Œä¸ s3 çš„ concat
        self.up1 = Up_PHD(c4, c3, bilinear, skip_channels=c3, use_dcn=use_dcn)
        
        # Up 2: d1(512) + s2(256) -> è¾“å‡º c2(256)
        self.up2 = Up_PHD(c3, c2, bilinear, skip_channels=c2, use_dcn=use_dcn)
        
        # Up 3: d2(256) + s1(128) -> è¾“å‡º c1(128)
        self.up3 = Up_PHD(c2, c1, bilinear, skip_channels=c1, use_dcn=use_dcn)
        
        self.final_up = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)
        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)

        # --- [æ–°å¢] è¾¹ç¼˜é¢„æµ‹å¤´ (Edge Head) ---
        # åˆ©ç”¨å³è·¯ç¬¬ä¸€å±‚(f1)ç‰¹å¾é¢„æµ‹è¾¹ç¼˜ï¼Œç”¨äºè¾…åŠ© Loss
        self.edge_head = nn.Sequential(
            nn.Conv2d(f_dims[0], 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1)
        )

    def forward(self, x):
        # === Encoder ===
        s_feats = list(self.spatial_encoder(x))
        
        f_feats = []
        f_curr = self.freq_stem(x)
        f_feats.append(f_curr)
        for layer in self.freq_layers:
            f_curr = layer(f_curr)
            f_feats.append(f_curr)
        f_feats[-1] = self.freq_stage4(f_feats[-1])

        # === Interaction (FGF) ===
        s_clean = []
        for i in range(4):
            s_out = self.fgf_modules[i](s_feats[i], f_feats[i])
            s_clean.append(s_out)
        s1, s2, s3, x4 = s_clean

        # === Neck (MFAM) ===
        if self.use_mfam:  # <--- ğŸ”¥ [æ–°å¢] 4. åŠ åˆ¤æ–­
            f4_aligned = self.neck_freq_align(f_feats[3])
            x4_enhanced = self.neck_mfam(x4, f4_aligned)
        else:
            # å¦‚æœä¸ä½¿ç”¨ MFAMï¼Œç›´æ¥è·³è¿‡ï¼ŒæŠŠ x4 åŸå°ä¸åŠ¨ä¼ ç»™åé¢
            x4_enhanced = x4

        # === Decoder (ä½¿ç”¨ Up_PHD æ¥å£) ===
        # Up_PHD.forward(x1, x2) -> x1æ˜¯æ·±å±‚(x4), x2æ˜¯æµ…å±‚Skip(s3)
        d1 = self.up1(x4_enhanced, s3)
        d2 = self.up2(d1, s2)
        d3 = self.up3(d2, s1)
        
        d4 = self.final_up(d3)
        logits = self.outc(d4)
        
        # === è¿”å›é€»è¾‘ ===
        if self.training:
            # è®¡ç®—è¾¹ç¼˜è¾…åŠ©è¾“å‡º
            # å°† f1 (1/4åˆ†è¾¨ç‡) é¢„æµ‹ä¸ºè¾¹ç¼˜ï¼Œå†ä¸Šé‡‡æ ·å›åŸå›¾
            edge_logits_small = self.edge_head(f_feats[0])
            edge_logits = F.interpolate(edge_logits_small, size=logits.shape[2:], mode='bilinear', align_corners=True)
            
            # è¿”å›åŒç»“æœï¼šä¸»åˆ†å‰² + è¾¹ç¼˜
            return logits, edge_logits
            
        return logits