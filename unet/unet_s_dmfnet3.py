"""
unet/unet_s_dmfnet.py
[S-DMFNet Pro] Enhanced Dual-Stream Mutual-Guided Frequency-Aware Network
ç‰ˆæœ¬ç‰¹æ€§:
1. é›†æˆ Bi-FGF (åŒå‘äº’å¯¼) æ¨¡å—
2. ç§»é™¤ MFAM ç“¶é¢ˆå±‚ï¼Œé‡‡ç”¨è½»é‡åŒ–èåˆ
3. Edge Head ä½¿ç”¨è¯­ä¹‰æ¸…æ´—åçš„é¢‘ç‡ç‰¹å¾
4. å®Œå…¨å¤åˆ» Up_PHD æ¥å£
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import sys
from pathlib import Path

# ================================================================
# 0. åŠ¨æ€å¯¼å…¥ä¾èµ– (ä¿æŒåŸæœ‰ç›®å½•ç»“æ„çš„å…¼å®¹æ€§)
# ================================================================

# å°è¯•å¯¼å…¥ PHD è§£ç å™¨æ ¸å¿ƒå—
try: 
    from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError: 
    try: 
        from unet.hybrid_decoder import PHD_DecoderBlock
    except ImportError: 
        PHD_DecoderBlock = None
        print("Warning: PHD_DecoderBlock import failed.")

# å°è¯•å¯¼å…¥ Mamba (ç”¨äºå³è·¯)
try: 
    from decoder.mamba_helper import MambaLayer2D
except ImportError: 
    try: 
        from unet.mamba_helper import MambaLayer2D
    except ImportError: 
        MambaLayer2D = None
        print("Warning: MambaLayer2D import failed, using Identity.")

# ================================================================
# 1. åŸºç¡€å·¥å…·ç±» (Haar å°æ³¢) - ä¿æŒä¸å˜
# ================================================================

class HaarWaveletTransform(nn.Module):
    def __init__(self):
        super().__init__()
        ll = torch.tensor([[0.5, 0.5], [0.5, 0.5]])
        lh = torch.tensor([[-0.5, -0.5], [0.5, 0.5]])
        hl = torch.tensor([[-0.5, 0.5], [-0.5, 0.5]])
        hh = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1))

    def dwt(self, x):
        B, C, H, W = x.shape
        # å¶æ•°å¡«å……å¤„ç†
        if H % 2 != 0 or W % 2 != 0:
            x = F.pad(x, (0, W % 2, 0, H % 2), mode='reflect')
        filters = self.filters.repeat(C, 1, 1, 1)
        output = F.conv2d(x, filters, stride=2, groups=C)
        output = output.view(B, C, 4, output.shape[2], output.shape[3])
        return output[:, :, 0], output[:, :, 1], output[:, :, 2], output[:, :, 3]
    

class InverseHaarWaveletTransform(nn.Module):
    """
    å°æ³¢é€†å˜æ¢ (IDWT)
    å°† LL, LH, HL, HH å››ä¸ªåˆ†é‡è¿˜åŸå›ç©ºé—´å›¾åƒå°ºå¯¸ (2x)
    """
    def __init__(self):
        super().__init__()
        # å®šä¹‰é€†å˜æ¢çš„å·ç§¯æ ¸ (åŸºäº Haar å°æ³¢å®šä¹‰)
        # è¿™é‡Œçš„æƒé‡æ˜¯ä¸ºäº†é…åˆ Forward çš„ 0.5 ç³»æ•°è¿›è¡Œè¿˜åŸ
        ll = torch.tensor([[1.0, 1.0], [1.0, 1.0]])
        lh = torch.tensor([[-1.0, -1.0], [1.0, 1.0]])
        hl = torch.tensor([[-1.0, 1.0], [-1.0, 1.0]])
        hh = torch.tensor([[1.0, -1.0], [-1.0, 1.0]])
        
        # ä½¿ç”¨ Transposed Conv æ¥å®ç°ä¸Šé‡‡æ ·+æ±‚å’Œ
        self.register_buffer('filters', torch.stack([ll, lh, hl, hh]).unsqueeze(1) / 2.0)

    def idwt(self, ll, lh, hl, hh):
        # è¾“å…¥: [B, C, H, W] * 4
        # è¾“å‡º: [B, C, 2H, 2W]
        B, C, H, W = ll.shape
        # å°† 4 ä¸ªåˆ†é‡æ‹¼æ¥ä¸º [B, 4C, H, W]
        x = torch.cat([ll, lh, hl, hh], dim=1)
        # ä½¿ç”¨ Group ConvTranspose2d è¿›è¡Œç‹¬ç«‹é€šé“çš„é€†å˜æ¢
        # groups=C ä¿è¯æ¯ä¸ªé€šé“ç‹¬ç«‹è¿˜åŸ
        out = F.conv_transpose2d(
            x, 
            self.filters.repeat(C, 1, 1, 1), 
            stride=2, 
            groups=C
        )
        return out
# ================================================================
# 2. å³è·¯æ ¸å¿ƒæ¨¡å— (WaveletMamba) - ä¿æŒä¸å˜
# ================================================================

class WaveletMambaBlock(nn.Module):
    """ 
    [Re-designed] WaveletMamba Block V3 (Baseline)
    é€»è¾‘:
    1. Low Freq (LL) -> Mamba (è´Ÿè´£å…¨å±€è¯­ä¹‰)
    2. High Freq (H) -> Standard 3x3 Conv (è´Ÿè´£å±€éƒ¨è¾¹ç¼˜ - ä½ æŒ‡å®šçš„ä»£ç )
    3. Output 1 (Next Layer): Concat(LL, H) -> Conv (ä¿æŒé¢‘åŸŸ)
    4. Output 2 (Interaction): IDWT(LL, H_split) -> Interaction (è½¬å›ç©ºåŸŸ)
    """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.dwt = HaarWaveletTransform()
        self.idwt = InverseHaarWaveletTransform()
        
        # --- A. ä½é¢‘å¤„ç† (å…¨å±€) ---
        # ä¿æŒä½ çš„è¦æ±‚: ä½é¢‘è¿› Mamba
        self.low_process = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            MambaLayer2D(dim=out_channels) if MambaLayer2D else nn.Identity()
        )
        
        # --- B. é«˜é¢‘å¤„ç† (å±€éƒ¨) ---
        # ğŸ”¥ [ä¿®æ”¹] è¿™é‡Œæ¢æˆäº†ä½ æŒ‡å®šçš„ "æ ‡å‡† 3x3 å·ç§¯"
        # è¾“å…¥æ˜¯ 3 ä¸ªé«˜é¢‘åˆ†é‡æ‹¼æ¥ (in_channels * 3)
        self.high_process = nn.Sequential(
            nn.Conv2d(in_channels * 3, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # --- C. è·¯å¾„åˆ†æ”¯å¤„ç† ---
        
        # Path 1: å‡†å¤‡å»äº¤äº’ (Spatial Domain)
        # 1. æŠŠå·ç§¯èåˆåçš„é«˜é¢‘ (1C) æ‹†å› 3ä¸ªåˆ†é‡ (3C) ä»¥ä¾¿åš IDWT
        self.high_restore = nn.Conv2d(out_channels, out_channels * 3, 1)
        
        # 2. IDWT åå°ºå¯¸å˜å¤§ (2x)ï¼Œéœ€è¦ä¸‹é‡‡æ ·å›åŸå°ºå¯¸ä»¥ä¾¿å’Œå·¦è·¯äº¤äº’
        self.inter_downsample = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # Path 2: å‡†å¤‡å»ä¸‹ä¸€å±‚ (Frequency Domain)
        # 3. ç›´æ¥èåˆ LL å’Œ Highï¼Œä¿æŒåœ¨é¢‘åŸŸä¸‹æ½œ
        self.fusion_next = nn.Sequential(
            nn.Conv2d(out_channels * 2, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # 1. DWT åˆ†è§£
        ll, lh, hl, hh = self.dwt.dwt(x)
        
        # 2. åˆ†åˆ«å¤„ç†
        # LL -> Mamba
        ll_feat = self.low_process(ll)
        
        # High -> Standard Conv
        high_cat = torch.cat([lh, hl, hh], dim=1)
        high_feat = self.high_process(high_cat) # [B, C, H/2, W/2]
        
        # === Output 1: ä¼ ç»™ä¸‹ä¸€å±‚ (Frequency Domain) ===
        # æ‹¼æ¥ LL å’Œ Highï¼Œä¸é€†å˜æ¢ï¼Œç›´æ¥å»ä¸‹ä¸€å±‚åˆ†è§£
        out_next = self.fusion_next(torch.cat([ll_feat, high_feat], dim=1))
        
        # === Output 2: ä¼ ç»™äº¤äº’æ¨¡å— (Spatial Domain) ===
        # A. æ˜ å°„å› 3 ä¸ªåˆ†é‡
        high_restored = self.high_restore(high_feat)
        lh_rec, hl_rec, hh_rec = torch.chunk(high_restored, 3, dim=1)
        
        # B. IDWT é€†å˜æ¢ (H/2 -> H)
        # æ­¤æ—¶è·å¾—çš„æ˜¯å…·å¤‡ Mamba è¯­ä¹‰ + Conv è¾¹ç¼˜çš„å®Œæ•´å›¾åƒç‰¹å¾
        out_spatial_large = self.idwt.idwt(ll_feat, lh_rec, hl_rec, hh_rec)
        
        # C. å†æ¬¡ä¸‹é‡‡æ · (H -> H/2)
        # è°ƒæ•´å°ºå¯¸ä»¥åŒ¹é…åŒå±‚çº§çš„ ConvNeXt ç‰¹å¾
        out_inter = self.inter_downsample(out_spatial_large)
        
        # è¿”å›: (å»ä¸‹ä¸€å±‚, å»äº¤äº’)
        return out_next, out_inter
# ================================================================
# 3. [ğŸ”¥æ ¸å¿ƒå‡çº§] Bi-FGF åŒå‘äº’å¯¼æ¨¡å—
#    å­¦æœ¯å¯¹æ ‡: RSBuilding (2024)
# ================================================================

class Cross_GL_FGF(nn.Module):
    """
    [SOTAçº§äº¤äº’] Cross Global-Local Frequency-Guided Fusion
    è®ºæ–‡å›¾ç¤ºï¼šX-Structure (Serial)
    é€»è¾‘ï¼šGlobal Channel Gating (Denoise) -> Local Spatial Gating (Align) -> Injection (Fusion)
    """
    def __init__(self, s_channels, f_channels, reduction=16):
        super().__init__()
        
        # å®‰å…¨è®¡ç®—éšè—å±‚ç»´åº¦
        s_mid = max(s_channels // reduction, 4)
        f_mid = max(f_channels // reduction, 4)

        # --- Stage 1: Global Channel Interaction (å®è§‚å»å™ª) ---
        self.gap = nn.AdaptiveAvgPool2d(1)
        
        # S -> F (è¯­ä¹‰æŒ‡å¯¼é¢‘ç‡ï¼šå»å™ª)
        self.mlp_s2f = nn.Sequential(
            nn.Linear(s_channels, f_mid, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(f_mid, f_channels, bias=False),
            nn.Sigmoid()
        )
        # F -> S (é¢‘ç‡æŒ‡å¯¼è¯­ä¹‰ï¼šå…³æ³¨ç»†èŠ‚)
        self.mlp_f2s = nn.Sequential(
            nn.Linear(f_channels, s_mid, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(s_mid, s_channels, bias=False),
            nn.Sigmoid()
        )

        # --- Stage 2: Local Spatial Interaction (å¾®è§‚ç²¾ä¿®) ---
        self.spatial_conv_s2f = nn.Sequential(
            nn.Conv2d(s_channels, 1, kernel_size=7, padding=3, bias=False),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        self.spatial_conv_f2s = nn.Sequential(
            nn.Conv2d(f_channels, 1, kernel_size=7, padding=3, bias=False),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )

        # --- Stage 3: Feature Injection (ç‰¹å¾èåˆ) ---
        self.s_align = nn.Conv2d(s_channels, f_channels, 1)
        self.f_align = nn.Conv2d(f_channels, s_channels, 1)
        
        # Zero-Init: ä¿è¯è®­ç»ƒåˆæœŸäº’ä¸å¹²æ‰°
        nn.init.constant_(self.s_align.weight, 0)
        nn.init.constant_(self.s_align.bias, 0)
        nn.init.constant_(self.f_align.weight, 0)
        nn.init.constant_(self.f_align.bias, 0)
        
        # æœ€ç»ˆèåˆå·ç§¯ (Concatenate -> Conv)
        self.fusion_conv = nn.Sequential(
            nn.Conv2d(s_channels * 2, s_channels, 1),
            nn.BatchNorm2d(s_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x_s, x_f):
        B, Cs, H, W = x_s.shape
        _, Cf, _, _ = x_f.shape
        
        # å°ºå¯¸å¯¹é½
        if x_f.shape[2:] != x_s.shape[2:]:
            x_f = F.interpolate(x_f, size=(H, W), mode='bilinear', align_corners=False)

        # 1. å…¨å±€å»å™ª (Channel Gating)
        s_vec = self.gap(x_s).view(B, Cs)
        f_vec = self.gap(x_f).view(B, Cf)
        w_s2f = self.mlp_s2f(s_vec).view(B, Cf, 1, 1) 
        w_f2s = self.mlp_f2s(f_vec).view(B, Cs, 1, 1) 
        f_clean = x_f * w_s2f
        s_clean = x_s * w_f2s
        
        # 2. å±€éƒ¨ç²¾ä¿® (Spatial Attention)
        m_s2f = self.spatial_conv_s2f(s_clean) 
        m_f2s = self.spatial_conv_f2s(f_clean)
        f_refined = f_clean * m_s2f + f_clean
        s_refined = s_clean * m_f2s + s_clean

        # 3. äº¤å‰èåˆ (Fusion for Skip)
        # å°† F å¯¹é½å¹¶æ³¨å…¥
        f_injected = self.f_align(f_refined)
        # æ‹¼æ¥ + å·ç§¯èåˆ (ç”Ÿæˆè·³è·ƒè¿æ¥ç‰¹å¾)
        out = self.fusion_conv(torch.cat([s_refined, f_injected], dim=1))
        
        # è¿”å›: (è·³è·ƒè¿æ¥ç‰¹å¾, å¢å¼ºåçš„é¢‘ç‡ç‰¹å¾)
        return out, f_refined
# ================================================================
# ğŸ”¥ [æ–°å¢] SK-Fusion: æ¶¨ç‚¹ç¥å™¨
# ================================================================
class SK_Fusion(nn.Module):
    """
    Selective Kernel Fusion (SK-Fusion)
    ä½œç”¨: åŠ¨æ€å­¦ä¹  Semanticæµ å’Œ Frequencyæµ çš„èåˆæƒé‡
    è¾“å…¥: ä¸¤ä¸ªç»´åº¦ç›¸åŒçš„ç‰¹å¾å›¾ x_s, x_f
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.d = max(channels // reduction, 32)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, self.d),
            nn.BatchNorm1d(self.d),
            nn.ReLU(inplace=True)
        )
        self.fc_selection = nn.Linear(self.d, channels * 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x_s, x_f):
        B, C, H, W = x_s.shape
        # 1. åˆå§‹å åŠ 
        U = x_s + x_f
        # 2. å…¨å±€æè¿°ç¬¦
        s = self.avg_pool(U).view(B, C)
        # 3. å‹ç¼©æ¿€åŠ±
        z = self.fc(s)
        # 4. ç”Ÿæˆç«äº‰æƒé‡
        weights = self.fc_selection(z).view(B, 2, C)
        weights = self.softmax(weights)
        # 5. åŠ æƒèåˆ
        w_s = weights[:, 0, :].view(B, C, 1, 1)
        w_f = weights[:, 1, :].view(B, C, 1, 1)
        return (x_s * w_s) + (x_f * w_f)
# ================================================================
# 4. [é€‚é…å™¨] Up_PHD - å®Œå…¨å¤åˆ»åŸä»£ç 
# ================================================================

class Up_PHD(nn.Module):
    """
    è´Ÿè´£ï¼šä¸Šé‡‡æ · -> Paddingå¯¹é½ -> æ‹¼æ¥ -> è°ƒç”¨ PHD_DecoderBlock
    """
    def __init__(self, in_channels, out_channels, bilinear=True, skip_channels=0, 
                 use_dcn=False, use_dubm=False, use_strg=False):
        super().__init__()
        
        # 1. å®šä¹‰ä¸Šé‡‡æ ·
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            conv_in_channels = in_channels + skip_channels
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            conv_in_channels = (in_channels // 2) + skip_channels

        # 2. æ ¸å¿ƒï¼šè°ƒç”¨ PHD_DecoderBlock
        self.conv = PHD_DecoderBlock(in_channels=conv_in_channels, out_channels=out_channels, 
                                     use_dcn=use_dcn, use_dubm=use_dubm)

    def forward(self, x1, x2=None, edge_prior=None):
        # x1: æ·±å±‚ç‰¹å¾ (éœ€è¦ä¸Šé‡‡æ ·)
        # x2: æµ…å±‚ Skip ç‰¹å¾ (éœ€è¦æ‹¼æ¥)
        
        x1 = self.up(x1)
        
        if x2 is not None:
            # Padding å¯¹é½
            diffY = x2.size()[2] - x1.size()[2]
            diffX = x2.size()[3] - x1.size()[3]
            if diffX != 0 or diffY != 0:
                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])
            
            # æ‹¼æ¥
            x = torch.cat([x2, x1], dim=1)
        else:
            x = x1
        
        # è°ƒç”¨ PHD Block
        return self.conv(x, edge_prior=edge_prior)

# ================================================================
# 5. S_DMFNet ä¸»æ¨¡å‹ (Refined)
# ================================================================

class S_DMFNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True, 
                 encoder_name='cnextv2', cnext_type='convnextv2_base',
                 decoder_name='phd', use_dcn=True,
                 # å…¼å®¹å‚æ•°
                 use_dsis=False, use_dual_stream=False, use_wavelet_denoise=False, 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, 
                 use_dubm=False, use_strg=False, **kwargs):
        super(S_DMFNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        
        print(f"ğŸš€ [S-DMFNet Pro] Fixed Version | Encoder: {cnext_type}")

        # --- 1. å·¦è·¯: Spatial Encoder ---
        self.spatial_encoder = timm.create_model(cnext_type, pretrained=True, features_only=True, out_indices=(0, 1, 2, 3), drop_path_rate=0.0)
        s_dims = self.spatial_encoder.feature_info.channels() 
        # e.g., [128, 256, 512, 1024]

        # --- 2. å³è·¯: Frequency Encoder ---
        f_dims = [c // 4 for c in s_dims] 
        # e.g., [32, 64, 128, 256]

        # Stem: äº§ç”Ÿ f1
        self.freq_stem = nn.Sequential(
            nn.Conv2d(3, f_dims[0], 4, stride=4, padding=0),
            nn.BatchNorm2d(f_dims[0]),
            nn.ReLU(inplace=True)
        )
        
        # Layers: äº§ç”Ÿ f2, f3, f4
        # æ³¨æ„ï¼šè¿™é‡Œåªéœ€è¦ 3 ä¸ª Block å°±èƒ½å¤„ç†å®Œå‰©ä¸‹çš„å±‚çº§
        self.freq_layers = nn.ModuleList()
        for i in range(3):
            # Block 0: 32 -> 64
            # Block 1: 64 -> 128
            # Block 2: 128 -> 256
            self.freq_layers.append(WaveletMambaBlock(f_dims[i], f_dims[i+1]))

        # --- 3. äº¤äº’ ---
        self.bi_fgf_modules = nn.ModuleList([Cross_GL_FGF(s_dims[i], f_dims[i]) for i in range(4)])

        # --- 5. è§£ç å™¨ ---
        c1, c2, c3, c4 = s_dims
        self.up1 = Up_PHD(c4, c3, bilinear, skip_channels=c3, use_dcn=use_dcn, use_dubm=use_dubm)
        self.up2 = Up_PHD(c3, c2, bilinear, skip_channels=c2, use_dcn=use_dcn, use_dubm=use_dubm)
        self.up3 = Up_PHD(c2, c1, bilinear, skip_channels=c1, use_dcn=use_dcn, use_dubm=use_dubm)
        
        self.final_up = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)
        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)

        # --- 6. è¾¹ç¼˜å¤´ ---
        self.edge_head = nn.Sequential(
            nn.Conv2d(f_dims[0], 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1)
        )

    def forward(self, x):
        # === Encoder ===
        s_feats = list(self.spatial_encoder(x))
        # s_feats: [s1(H/4), s2(H/8), s3(H/16), s4(H/32)]
        
        f_feats = []
        
        # 1. Stem -> f1 (H/4)
        f_curr = self.freq_stem(x) 
        f_feats.append(f_curr) 
        
        # 2. Layers -> f2, f3, f4
        for layer in self.freq_layers:
            # layer è¾“å‡º:
            # f_next: å»ä¸‹ä¸€å±‚çš„é¢‘åŸŸç‰¹å¾ (H/2n)
            # f_inter: å»äº¤äº’çš„ç©ºåŸŸç‰¹å¾ (H/2n)
            f_next, f_inter = layer(f_curr)
            
            f_feats.append(f_inter) # æ”¶é›†ç”¨äºäº¤äº’
            f_curr = f_next         # ç»§ç»­å‘ä¸‹ä¼ é€’
            
        # ğŸ”¥ [ä¿®å¤] æ­¤æ—¶ f_feats å·²ç»åŒ…å«äº† [f1, f2, f3, f4]ï¼Œé•¿åº¦ä¸º 4ï¼Œä¸ s_feats å®Œç¾å¯¹åº”ã€‚
        # ä¸éœ€è¦å†ç”»è›‡æ·»è¶³åœ°å¤„ç† stage4 äº†ã€‚

        # === Interaction (Cross-GL-FGF) ===
        skips = []      
        f_enhanced = [] 
        
        for i in range(4):
            # è¿™é‡Œçš„ s_feats[i] å’Œ f_feats[i] å°ºå¯¸ç°åœ¨æ˜¯å®Œå…¨å¯¹é½çš„
            fusion_out, f_out = self.bi_fgf_modules[i](s_feats[i], f_feats[i])
            skips.append(fusion_out)
            f_enhanced.append(f_out)

        s1_fused, s2_fused, s3_fused, s4_fused = skips

        # === Decoder ===
        d1 = self.up1(s4_fused, s3_fused)
        d2 = self.up2(d1, s2_fused)
        d3 = self.up3(d2, s1_fused)
        
        d4 = self.final_up(d3)
        logits = self.outc(d4)
        
        # === Auxiliary Output ===
        if self.training:
            # ä½¿ç”¨æ¸…æ´—åçš„ f1
            edge_logits_small = self.edge_head(f_enhanced[0])
            edge_logits = F.interpolate(edge_logits_small, size=logits.shape[2:], mode='bilinear', align_corners=True)
            return logits, edge_logits
            
        return logits