"""
unet_model_unified.py (Channel Fix Version)
ä¿®å¤ï¼š
1. ä¿®æ­£äº† self.outc çš„è¾“å…¥é€šé“æ•°é”™è¯¯ (ä» 32 æ”¹ä¸º 64)ï¼Œè§£å†³äº† RuntimeErrorã€‚
2. ä¿æŒäº†ä¹‹å‰æ‰€æœ‰çš„åŒæµæ¶æ„ã€STRGã€WGN ç­‰é€»è¾‘ã€‚
"""

from .unet_parts import *
import sys
from pathlib import Path
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm 

sys.path.insert(0, str(Path(__file__).parent.parent))

# ================================================================
# 1. åŠ¨æ€å¯¼å…¥æ‰€æœ‰å¯é€‰æ¨¡å—
# ================================================================

# PHD è§£ç å™¨æ ¸å¿ƒå—
try: from decoder.hybrid_decoder import PHD_DecoderBlock
except ImportError: PHD_DecoderBlock = None

# åŒæµå¢å¼ºæ¨¡å— (STRG)
try: from .dual_enhance import STRG_Block
except ImportError: STRG_Block = None

# æ˜¾å¼è¾¹ç•Œæµ (Boundary Stream)
try: from .boundary_stream import BoundaryStream
except ImportError: BoundaryStream = None

# WGN (Wavelet Group Norm) - ğŸ”¥ ä¿ç•™ç”¨äº Encoder å¢å¼º
try: from .wgn_module import WGN
except ImportError: WGN = None

# CAFM (Content-Aware Feature Modulation)
try: from .cafm_module import CAFM
except ImportError: CAFM = None


# ================================================================
# 2. é€‚é…å™¨ï¼šUp_PHD
# ================================================================
class Up_PHD(nn.Module):
    def __init__(self, in_channels, out_channels, bilinear=True, skip_channels=0, 
                 use_dcn=False, use_dubm=False, use_strg=False):
        super().__init__()
        
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            conv_in_channels = in_channels + skip_channels
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            conv_in_channels = (in_channels // 2) + skip_channels

        # STRG æ¨¡å—
        self.use_strg = use_strg and (STRG_Block is not None)
        if self.use_strg and skip_channels > 0:
            self.strg_enhance = STRG_Block(skip_channels=skip_channels, deep_channels=in_channels)

        self.conv = PHD_DecoderBlock(in_channels=conv_in_channels, out_channels=out_channels, use_dcn=use_dcn, use_dubm=use_dubm)

    def forward(self, x1, x2=None, edge_prior=None):
        x1 = self.up(x1)
        
        if x2 is not None:
            diffY = x2.size()[2] - x1.size()[2]
            diffX = x2.size()[3] - x1.size()[3]
            if diffX != 0 or diffY != 0:
                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])
            
            if self.use_strg:
                x2 = self.strg_enhance(x_skip=x2, x_deep=x1)
            
            x = torch.cat([x2, x1], dim=1)
        else:
            x = x1
        
        return self.conv(x, edge_prior=edge_prior)


# ================================================================
# 3. ç»Ÿä¸€ä¸»æ¨¡å‹ UNet
# ================================================================
class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True, 
                 encoder_name='resnet', decoder_name='phd', cnext_type='convnextv2_tiny', 
                 use_wgn_enhancement=False, use_cafm=False, use_edge_loss=False, wgn_orders=None,
                 use_dcn_in_phd=False, use_dubm=False, use_strg=False,
                 use_dual_stream=False):
        
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        self.encoder_name = encoder_name
        self.decoder_name = decoder_name
        
        self.use_cafm = use_cafm and (CAFM is not None)
        self.use_dual_stream = use_dual_stream and (BoundaryStream is not None)

        # --------------------------------------------------------
        # A. Encoder åˆå§‹åŒ–
        # --------------------------------------------------------
        self.channels = [] 
        if encoder_name == 'resnet':
            from torchvision.models import resnet50, ResNet50_Weights
            resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
            self.enc_stem = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)
            self.layer1 = resnet.layer1
            self.layer2 = resnet.layer2
            self.layer3 = resnet.layer3
            self.layer4 = resnet.layer4
            self.channels = [256, 512, 1024, 2048]
            
        elif encoder_name == 'cnextv2':
            self.enc_model = timm.create_model(cnext_type, pretrained=True, features_only=True, out_indices=[0, 1, 2, 3], in_chans=n_channels)
            self.channels = self.enc_model.feature_info.channels()
            
        else:
            self.inc = DoubleConv(n_channels, 64)
            self.down1 = Down(64, 128)
            self.down2 = Down(128, 256)
            self.down3 = Down(256, 512)
            factor = 2 if bilinear else 1
            self.down4 = Down(512, 1024 // factor)
            self.channels = [128, 256, 512, 1024 // factor]

        c1, c2, c3, c4 = self.channels

        # --------------------------------------------------------
        # B. WGN åˆå§‹åŒ– (Encoder å¢å¼ºä¿ç•™)
        # --------------------------------------------------------
        if use_wgn_enhancement and wgn_orders is not None and WGN is not None:
            print("   âœ¨ Applying WGN Enhancement (Encoder)...")
            
            def replace_bn_with_wgn(module, order):
                for name, child in module.named_children():
                    if isinstance(child, (nn.BatchNorm2d, nn.GroupNorm)):
                        num_features = child.num_features if isinstance(child, nn.BatchNorm2d) else child.num_channels
                        setattr(module, name, WGN(num_features, order=order))
                    else:
                        replace_bn_with_wgn(child, order)

            if encoder_name == 'resnet':
                replace_bn_with_wgn(self.layer1, wgn_orders['layer1'][0])
                replace_bn_with_wgn(self.layer2, wgn_orders['layer2'][0])
                replace_bn_with_wgn(self.layer3, wgn_orders['layer3'][0])

        # --------------------------------------------------------
        # C. CAFM åˆå§‹åŒ–
        # --------------------------------------------------------
        if self.use_cafm:
            print("   âœ¨ Applying CAFM...")
            self.cafm1 = CAFM(c1)
            self.cafm2 = CAFM(c2)
            self.cafm3 = CAFM(c3)
            self.cafm4 = CAFM(c4)

        # --------------------------------------------------------
        # D. åŒæµæ¶æ„ï¼šè¾¹ç•Œæµåˆå§‹åŒ–
        # --------------------------------------------------------
        if self.use_dual_stream:
            print("   ğŸŒŠ [Dual-Stream] Initializing Boundary Stream (Explicit Edge)...")
            self.boundary_stream = BoundaryStream(in_channels=c1)

        # --------------------------------------------------------
        # E. Decoder åˆå§‹åŒ–
        # --------------------------------------------------------
        UpBlock = Up_PHD if decoder_name == 'phd' else Up
        
        if decoder_name == 'phd':
            self.up1 = UpBlock(c4, c3, bilinear, skip_channels=c3, use_dcn=use_dcn_in_phd, use_dubm=use_dubm, use_strg=use_strg)
            self.up2 = UpBlock(c3, c2, bilinear, skip_channels=c2, use_dcn=use_dcn_in_phd, use_dubm=use_dubm, use_strg=use_strg)
            self.up3 = UpBlock(c2, c1, bilinear, skip_channels=c1, use_dcn=use_dcn_in_phd, use_dubm=use_dubm, use_strg=use_strg)
        else:
            self.up1 = UpBlock(c4, c3, bilinear, skip_channels=c3)
            self.up2 = UpBlock(c3, c2, bilinear, skip_channels=c2)
            self.up3 = UpBlock(c2, c1, bilinear, skip_channels=c1)

        # æœ€åä¸€å±‚ä¸Šé‡‡æ ·ï¼šè¿™é‡Œè¾“å‡ºäº† 64 é€šé“
        if bilinear:
            self.up4 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), DoubleConv(c1, 64))
        else:
            self.up4 = nn.Sequential(nn.ConvTranspose2d(c1, c1 // 2, kernel_size=2, stride=2), DoubleConv(c1 // 2, 64))
        
        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ [ä¿®æ­£] æ— è®ºæ˜¯ä»€ä¹ˆ Decoderï¼Œup4 éƒ½è¾“å‡ºäº† 64 é€šé“ï¼Œæ‰€ä»¥è¿™é‡Œç»Ÿä¸€ä¸º 64
        self.outc = OutConv(64, n_classes) 

    def forward(self, x):
        # 1. Encoder
        if self.encoder_name == 'cnextv2':
            feats = self.enc_model(x)
            s1, s2, s3, x4 = feats[0], feats[1], feats[2], feats[3]
        elif self.encoder_name == 'resnet':
            x0 = self.enc_stem(x)
            s1 = self.layer1(x0)
            s2 = self.layer2(s1)
            s3 = self.layer3(s2)
            x4 = self.layer4(s3)
        else:
            x1 = self.inc(x)
            s1 = self.down1(x1)
            s2 = self.down2(s1)
            s3 = self.down3(s2)
            x4 = self.down4(s3)

        # 2. CAFM
        if self.use_cafm:
            s1 = self.cafm1(s1)
            s2 = self.cafm2(s2)
            s3 = self.cafm3(s3)
            x4 = self.cafm4(x4)

        # 3. åŒæµæ¶æ„
        boundary_logits = None
        if self.use_dual_stream:
            boundary_logits = self.boundary_stream(s1)
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæˆªæ–­æ¢¯åº¦ ğŸ”¥ğŸ”¥ğŸ”¥
            # æˆ‘ä»¬ä¼ ç»™ Decoder çš„æ—¶å€™ï¼ŒåŠ ä¸Š .detach()
            # è¿™æ · Decoder çš„æ¢¯åº¦å°±ä¸ä¼šå›ä¼ ç»™ boundary_stream
            # boundary_stream åªä¾é æœ€åçš„ edge_loss æ¥æ›´æ–°è‡ªå·±
            edge_prior_for_dubm = boundary_logits.detach()
        # 4. Decoder
        if self.decoder_name == 'phd':
            d1 = self.up1(x4, s3, edge_prior=boundary_logits)
            d2 = self.up2(d1, s2, edge_prior=boundary_logits)
            d3 = self.up3(d2, s1, edge_prior=boundary_logits)
        else:
            d1 = self.up1(x4, s3)
            d2 = self.up2(d1, s2)
            d3 = self.up3(d2, s1)
            
        d4 = self.up4(d3)
        d5 = self.final_up(d4)
        
        logits = self.outc(d5)

        # 5. è¿”å›é€»è¾‘
        if self.training and self.use_dual_stream:
            return logits, boundary_logits
        else:
            return logits